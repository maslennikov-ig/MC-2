{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел предоставляет концептуальные основы нейронных сетей с практическими примерами. Студенты изучат математические принципы работы искусственных нейронов, архитектуру многослойных перцептронов и алгоритмы обучения. Особое внимание уделено визуализации процессов прямого и обратного распространения ошибки на конкретных вычислительных примерах.",
  "learning_objectives": [
    "Рассчитывать выходное значение искусственного нейрона при заданных весах и функции активации",
    "Строить схему многослойного перцептрона для решения задач бинарной классификации",
    "Применять алгоритм обратного распространения ошибки для обновления весов в сети",
    "Выбирать подходящую функцию активации на основе типа решаемой задачи",
    "Анализировать влияние коэффициента обучения на скорость сходимости процесса обучения"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Математическая модель искусственного нейрона",
      "lesson_objective": "Студенты смогут вычислять выходное значение нейрона для заданных входных данных и весов, используя различные функции активации.",
      "key_topics": [
        "Биологическая аналогия и математическая абстракция",
        "Взвешенная сумма входов с учетом bias-коэффициента",
        "Пороговая функция активации и ее ограничения",
        "Сигмоида и ReLU: сравнение свойств и областей применения"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона с ReLU",
          "exercise_instructions": "Даны входы [1.2, -0.5, 0.8] и веса [0.4, -0.3, 0.7]. Свободный член (bias) равен -0.2. Рассчитайте выходное значение нейрона, используя ReLU функцию активации. Продемонстрируйте все этапы вычисления."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Прямое распространение в многослойных перцептронах",
      "lesson_objective": "Студенты смогут выполнять пошаговый расчет выходных значений для сети с одним скрытым слоем при заданных входных данных.",
      "key_topics": [
        "Организация слоев: входной, скрытый, выходной",
        "Матричное представление операций векторизации",
        "Функция потерь MSE для регрессионных задач",
        "Визуализация потока данных на примере классификации цветков",
        "Влияние количества нейронов в скрытом слое на сложность модели"
      ],
      "exercises": [
        {
          "exercise_title": "Прямое распространение в сети 2-3-1",
          "exercise_instructions": "Постройте многослойный перцептрон с 2 входами, 3 нейронами в скрытом слое (ReLU) и 1 выходом (сигмоида). Используя предоставленные матрицы весов и входные данные [0.6, -0.3], выполните прямое распространение и вычислите окончательный прогноз сети. Представьте результат с точностью до 3 знаков."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обратное распространение ошибки и градиентный спуск",
      "lesson_objective": "Студенты смогут вычислять градиенты и обновлять веса сети для заданного примера обучения с использованием алгоритма обратного распространения.",
      "key_topics": [
        "Цепное правило дифференцирования в контексте нейросетей",
        "Расчет локальных градиентов для скрытых слоев",
        "Влияние коэффициента обучения на обновление весов",
        "Проблема затухающих градиентов и методы ее решения",
        "Сравнение пакетного и стохастического градиентного спуска"
      ],
      "exercises": [
        {
          "exercise_title": "Шаг обратного распространения",
          "exercise_instructions": "Для сети с одним скрытым нейроном (ReLU) и выходным нейроном (сигмоида) выполните обратное распространение ошибки. Даны: вход 0.4, целевое значение 1.0, текущие веса [0.5, -0.2], bias скрытого слоя 0.1. Рассчитайте обновленные веса после одного шага обучения с коэффициентом скорости 0.3. Продемонстрируйте вычисление всех частных производных."
        }
      ]
    }
  ]
}