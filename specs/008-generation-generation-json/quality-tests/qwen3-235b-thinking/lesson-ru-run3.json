{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Концептуальный теоретический раздел, раскрывающий принципы работы нейронных сетей через практические примеры. Изучаются архитектуры, алгоритмы обучения и ключевые математические основы с иллюстрацией на задачах классификации и регрессии.",
  "learning_objectives": [
    "объяснять биологические аналогии в архитектуре искусственных нейронов",
    "рассчитывать выходные значения персептрона для заданных весов и входных данных",
    "применять алгоритм обратного распространения ошибки в двухслойной сети",
    "выбирать оптимальную функцию активации для конкретной задачи машинного обучения",
    "интерпретировать результаты обучения на примере классификации MNIST"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Математическая модель биологического нейрона",
      "lesson_objective": "рассчитывать взвешенную сумму входных сигналов и применять пороговую функцию активации для заданного набора данных",
      "key_topics": [
        "сравнение биологического и искусственного нейрона",
        "формула взвешенной суммы с математической нотацией",
        "пороговая функция Хевисайда в задаче бинарной классификации",
        "ошибка классификации на примере разделения точек на плоскости"
      ],
      "exercises": [
        {
          "exercise_title": "Моделирование решета для линейно разделимых данных",
          "exercise_instructions": "Для набора точек [(2,3), (4,1), (1,5)] с метками [1, -1, 1] и весами [0.5, -0.2] рассчитайте выход персептрона при пороге 0.3. Постройте график разделительной линии."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Алгоритм обратного распространения в двухслойных сетях",
      "lesson_objective": "реализовывать шаг коррекции весов методом градиентного спуска для скрытого слоя многослойного персептрона",
      "key_topics": [
        "цепное правило дифференцирования для вычисления градиентов",
        "дельта-правило обучения с квадратичной функцией потерь",
        "пример распространения ошибки от выходного к скрытому слою",
        "проблема затухающих градиентов в глубоких сетях"
      ],
      "exercises": [
        {
          "exercise_title": "Ручной расчет обновления весов",
          "exercise_instructions": "Для сети с 2 входами, 3 нейронами в скрытом слое и 1 выходом рассчитайте поправку весов скрытого слоя при известных градиентах выходного слоя. Используйте скорость обучения 0.1 и сигмоидальную активацию."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Сравнение функций активации в практических задачах",
      "lesson_objective": "определять оптимальную функцию активации по графикам потерь и скорости сходимости для регрессионной задачи",
      "key_topics": [
        "свойства ReLU, сигмоида и гиперболического тангенса",
        "анализ графиков потерь при разных функциях активации",
        "проблема насыщения в глубоких сетях",
        "выбор функции для задачи регрессии цены недвижимости"
      ],
      "exercises": [
        {
          "exercise_title": "Анализ влияния активации на обучение",
          "exercise_instructions": "На основе предоставленных графиков потерь для ReLU и сигмоида определите, какая функция быстрее достигает минимума при обучении на данных Boston Housing. Обоснуйте выбор для задачи прогнозирования."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Практическое построение сети для распознавания цифр",
      "lesson_objective": "интерпретировать матрицу ошибок и визуализировать активацию слоев на примере датасета MNIST",
      "key_topics": [
        "архитектура сети для обработки изображений 28x28",
        "нормализация входных данных пикселей",
        "визуализация карт признаков сверточного слоя",
        "анализ ложных срабатываний через матрицу ошибок"
      ],
      "exercises": [
        {
          "exercise_title": "Диагностика ошибок классификации",
          "exercise_instructions": "По матрице ошибок для цифр 3 и 8 определите наиболее частые ошибки. Визуализируйте активацию первого скрытого слоя для образца, классифицированного как 8 вместо 3, и объясните причину ошибки."
        }
      ]
    }
  ]
}