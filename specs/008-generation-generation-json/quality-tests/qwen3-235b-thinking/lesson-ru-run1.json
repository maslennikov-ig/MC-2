{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел предоставляет концептуальное введение в архитектуру и работу нейронных сетей. Студенты изучат математические основы обработки информации в искусственных нейронах, особенности многослойных структур и принципы вычисления ошибок. Практические примеры иллюстрируют применение теоретических концепций в задачах классификации и регрессии.",
  "learning_objectives": [
    "Вычислять выходные значения искусственного нейрона для заданных весов и входных данных",
    "Обосновывать выбор функции активации в зависимости от типа задачи машинного обучения",
    "Выполнять пошаговый расчет прямого распространения в многослойной сети",
    "Оценивать качество модели через вычисление значений функций потерь"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Математическая модель искусственного нейрона",
      "lesson_objective": "Студенты смогут рассчитывать взвешенную сумму входов и применять пороговую функцию для определения выхода нейрона",
      "key_topics": [
        "Веса связей и коэффициент смещения",
        "Линейная комбинация входных сигналов",
        "Пороговые функции активации Хевисайда",
        "Геометрическая интерпретация разделяющей гиперплоскости"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона для логического И",
          "exercise_instructions": "Для входных значений [1, 0] вычислите выход персептрона с весами [0.6, 0.6] и порогом 1.0. Используйте пороговую функцию Хевисайда. Обоснуйте результат с точки зрения логической операции."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации в многослойных сетях",
      "lesson_objective": "Студенты смогут сравнивать производные сигмоиды, ReLU и гиперболического тангенса для анализа обучения глубоких сетей",
      "key_topics": [
        "Нелинейные преобразования в скрытых слоях",
        "Свойства гладкости и дифференцируемости",
        "Проблема насыщения градиентов",
        "Выбор функции для регрессии и классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение градиентов активации",
          "exercise_instructions": "Для входного значения -2.0 вычислите производные сигмоиды и ReLU. Объясните, как результат влияет на скорость обучения нейрона в глубокой сети. Приведите два примера задач, где предпочтительна каждая функция."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Прямое распространение в многослойном персептроне",
      "lesson_objective": "Студенты смогут последовательно вычислять выходы всех слоев сети для заданного входного вектора",
      "key_topics": [
        "Послойная обработка сигналов",
        "Матричное умножение весов и активаций",
        "Векторизация вычислений",
        "Конфигурация входного и выходного слоев"
      ],
      "exercises": [
        {
          "exercise_title": "Построение выхода MLP для XOR",
          "exercise_instructions": "Для сети с 2 входами, 2 нейронами скрытого слоя (веса [[1,1],[-1,-1]], смещения [0,1]) и 1 выходным нейроном (веса [1,1], смещение -0.5) вычислите выход при входе [0,1]. Используйте ReLU в скрытом слое. Проверьте соответствие логической операции XOR."
        }
      ]
    }
  ]
}