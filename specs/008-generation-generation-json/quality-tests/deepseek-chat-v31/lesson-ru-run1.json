{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с фундаментальными концепциями искусственных нейронных сетей. Студенты изучат базовое строение нейрона, принципы его работы, различные архитектуры сетей и процесс их обучения на примерах.",
  "learning_objectives": [
    "Объяснить структуру и функцию искусственного нейрона",
    "Построить простую нейронную сеть с использованием библиотеки TensorFlow или PyTorch",
    "Обучить нейронную сеть на заданном наборе данных, настроив гиперпараметры",
    "Проанализировать различные архитектуры нейронных сетей и их применение"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон: строительный блок интеллекта",
      "lesson_objective": "Студенты смогут описать математическую модель искусственного нейрона и вычислить его выходной сигнал для заданных входных данных и весов.",
      "key_topics": [
        "Биологический прототип и его искусственная модель",
        "Математическая формула вычисления взвешенной суммы",
        "Роль и виды функций активации (сигмоида, ReLU)",
        "Понятие смещения (bias)"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона вручную",
          "exercise_instructions": "Даны входные значения [2, 3, 1], веса [0.5, -0.2, 0.8] и смещение 1.0. Рассчитайте взвешенную сумму и примените функцию активации ReLU для получения окончательного выхода."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектуры нейронных сетей: от перцептрона до многослойных структур",
      "lesson_objective": "Студенты смогут визуально отличить и схематично изобразить полносвязную, сверточную и рекуррентную архитектуры нейронных сетей, указав их основные компоненты.",
      "key_topics": [
        "Однослойный перцептрон и его ограничения",
        "Многослойные сети (MLP): входной, скрытые и выходной слои",
        "Принцип прямого распространения сигнала (Feedforward)",
        "Краткий обзор специализированных архитектур: CNN и RNN"
      ],
      "exercises": [
        {
          "exercise_title": "Создание схемы нейронной сети",
          "exercise_instructions": "Нарисуйте схему полносвязной нейронной сети с тремя входными нейронами, одним скрытым слоем из четырех нейронов и выходным слоем из двух нейронов. Подпишите все слои и соединения."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение нейронной сети: алгоритм обратного распространения ошибки",
      "lesson_objective": "Студенты смогут описать шаги алгоритма обратного распространения ошибки и объяснить роль функции потерь и оптимизатора в процессе обучения.",
      "key_topics": [
        "Функция потерь: количественная оценка ошибки предсказания",
        "Градиентный спуск: принцип минимизации функции потерь",
        "Цепное правило для вычисления градиентов",
        "Обновление весов с помощью оптимизатора (например, SGD)"
      ],
      "exercises": [
        {
          "exercise_title": "Трассировка одного шага обратного распространения",
          "exercise_instructions": "Для упрощенной сети с одним нейроном и функцией потерь MSE опишите последовательность шагов для одного цикла: прямое распространение, вычисление ошибки, расчет градиентов и обновление весов."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Практическая реализация нейронной сети на Python",
      "lesson_objective": "Студенты смогут написать код для создания, компиляции и обучения простой полносвязной нейронной сети на стандартном наборе данных, таком как MNIST или Iris.",
      "key_topics": [
        "Выбор фреймворка: краткое сравнение TensorFlow/Keras и PyTorch",
        "Создание модели через Sequential API или класс Module",
        "Задание гиперпараметров: оптимизатор, функция потерь, метрики",
        "Запуск обучения с использованием метода .fit() или цикла обучения"
      ],
      "exercises": [
        {
          "exercise_title": "Создание сети для классификации ирисов Фишера",
          "exercise_instructions": "Используя выбранный фреймворк, создайте нейронную сеть для классификации датасета Iris. Сеть должна иметь как минимум один скрытый слой. Обучите модель на тренировочных данных и оцените ее точность на тестовых данных."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Переобучение и методы регуляризации",
      "lesson_objective": "Студенты смогут диагностировать переобучение на графиках обучения и применить как минимум два метода регуляризации (например, Dropout, L2) для улучшения обобщающей способности модели.",
      "key_topics": [
        "Диагностика переобучения: анализ графиков точности и потерь",
        "Метод Dropout: случайное отключение нейронов во время обучения",
        "L1 и L2 регуляризация: добавление штрафа к функции потерь",
        "Ранняя остановка (Early Stopping) как метод регуляризации"
      ],
      "exercises": [
        {
          "exercise_title": "Борьба с переобучением на практике",
          "exercise_instructions": "Возьмите модель из предыдущего урока и добейтесь переобучения (продемонстрируйте растущий разрыв между тренировочной и валидационной точностью). Затем модифицируйте модель, добавив слой Dropout и L2-регуляризацию, и покажите улучшение ее работы на валидационном наборе."
        }
      ]
    }
  ]
}