{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Раздел охватывает фундаментальные концепции нейронных сетей: от биологического прототипа до математической модели, включая механизмы обучения и практические примеры построения простейших сетей.",
  "learning_objectives": [
    "Объяснять биологическую архитектуру нейрона и формализовать её в виде математической модели",
    "Вычислять выходное значение искусственного нейрона при заданных весах и функции активации",
    "Различать архитектуры полносвязных, свёрточных и рекуррентных сетей",
    "Запускать процесс обучения перцептрона на синтетическом наборе данных",
    "Оценивать влияние функций активации на скорость сходимости сети"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "От биологического нейрона к формальному нейрону МакКаллока-Питтса",
      "lesson_objective": "Построить математическую модель биологического нейрона и вычислить её выход при заданных синаптических весах",
      "key_topics": ["Дендриты, сома, аксон и синапсы", "Пороговый механизм возбуждения", "Взвешенная сумма входов", "Функция Хевисайда"],
      "exercises": [
        {
          "exercise_title": "Калькулятор формального нейрона",
          "exercise_instructions": "Задайте вектор входов x=[1,0,1,1], веса w=[0.5,-0.3,0.8,0.2] и порог θ=0.7. Вычислите выход нейрона МакКаллока-Питтса вручную и проверьте результат через Python-функцию"
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации: от пороговой до гиперболического тангенса",
      "lesson_objective": "Построить графики четырёх типов функций активации и выбрать оптимальную для задачи бинарной классификации",
      "key_topics": ["Производная сигмоиды и проблема затухающего градиента", "ReLU и «мёртвые» нейроны", "Гиперболический тангенс и нормализация выходов", "Сравнение производительности на идентичном наборе данных"],
      "exercises": [
        {
          "exercise_title": "Визуальный анализ градиентов",
          "exercise_instructions": "Сгенерируйте 100 точек в диапазоне [-5,5]. Постройте на одном графике sigmoid(x), tanh(x), ReLU(x) и их производные. Определите интервалы, где градиент наиболее устойчив"
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Архитектура многослойного перцептрона: прямое распространение сигнала",
      "lesson_objective": "Рассчитать выход трёхслойного перцептрона для изображения 28×28 пикселей и оценить вычислительную сложность",
      "key_topics": ["Матрица весов между слоями", "Векторизация входного изображения", "Каскадное применение функций активации", "Сложность O(n·m) для полносвязного слоя"],
      "exercises": [
        {
          "exercise_title": "Прямой проход вручную",
          "exercise_instructions": "Дано: входной вектор 4×4=16 пикселей, скрытый слой 10 нейронов, выходной слой 3 класса. Заполните веса случайными значениями из N(0,0.1) и вычислите финальные вероятности софтмакс"
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Обратное распространение ошибки: цепное правило на практике",
      "lesson_objective": "Выполнить один шаг обновления весов для нейронной сети с двумя скрытыми слоями и вычислить величину градиента",
      "key_topics": ["Градиент loss-функции по выходному слою", "Рекуррентное вычисление δ^k", "Правило обновления w_{ij} := w_{ij} - η·δ_j·x_i", "Момент и адаптивные скорости обучения"],
      "exercises": [
        {
          "exercise_title": "Отладка градиента",
          "exercise_instructions": "Реализуйте численное дифференцирование для одного веса с ε=1e-5. Сравните результат с аналитическим градиентом, полученным через backprop. Убедитесь, что отклонение <0.001"
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Регуляризация и инициализация: как избежать переобучения и парализации сети",
      "lesson_objective": "Снизить ошибку на валидационной выборке с 15% до 5% за счёт подбора коэффициента L2-регуляризации и метода инициализации весов",
      "key_topics": ["Xavier / He инициализация", "Dropout с вероятностью 0.5", "L1 и L2 штрафы на веса", "Раннее остановка обучения по валидационной кривой"],
      "exercises": [
        {
          "exercise_title": "Сравнительный эксперимент",
          "exercise_instructions": "Обучите одну и ту же сеть на CIFAR-10 с тремя конфигурациями: (а) без регуляризации, (б) dropout=0.3, (в) L2=0.001. Постройте кривые loss и accuracy, зафиксируйте лучшую эпоху"
        }
      ]
    }
  ]
}