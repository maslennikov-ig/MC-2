{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Раздел посвящён теоретическим основам нейронных сетей: от математических принципов и функций активации до построения многослойных моделей и их применения в задачах классификации. Включены практические примеры реализации простых сетей на Python.",
  "learning_objectives": [
    "Студент сможет описать математические принципы работы нейронных сетей",
    "Студент сможет сравнить различные функции активации и их влияние на обучение",
    "Студент сможет построить многослойную нейронную сеть и выполнить её обучение",
    "Студент сможет оценить качество модели на реальном наборе данных"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Математические основы нейронных сетей",
      "lesson_objective": "Студент сможет объяснить роль линейных преобразований и функций активации в нейронных сетях",
      "key_topics": [
        "Линейные модели и их представление в виде матричных операций",
        "Функции активации: сигмоида, tanh, ReLU, Leaky ReLU",
        "Перцептрон как базовый элемент сети",
        "Градиентный спуск и вычисление производных"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация функции сигмоиды",
          "exercise_instructions": "Напишите функцию на Python, которая принимает массив чисел и возвращает их преобразование с помощью сигмоидной функции. Проверьте результаты на наборе тестовых значений."
        },
        {
          "exercise_title": "Ручной расчет выхода простого перцептрона",
          "exercise_instructions": "Даны веса w = [0.2, -0.5, 0.1] и порог b = 0.3. Рассчитайте выход перцептрона для входного вектора x = [1, 0, 1] с использованием функции активации ReLU."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектуры многослойных нейронных сетей",
      "lesson_objective": "Студент сможет построить и визуализировать многослойный перцептрон (MLP) с несколькими скрытыми слоями",
      "key_topics": [
        "Многослойный перцептрон: вход, скрытые и выходные слои",
        "Инициализация весов и смещений",
        "Обратное распространение ошибки (backpropagation)",
        "Визуализация архитектуры с помощью графов"
      ],
      "exercises": [
        {
          "exercise_title": "Создание MLP в PyTorch",
          "exercise_instructions": "С помощью библиотеки PyTorch реализуйте модель MLP с двумя скрытыми слоями (по 64 и 32 нейрона) и функцией активации ReLU. Инициализируйте веса случайным образом и выведите структуру модели."
        },
        {
          "exercise_title": "Схема сети на бумаге",
          "exercise_instructions": "Нарисуйте схематическое изображение построенной в предыдущем упражнении сети, указав количество нейронов в каждом слое и типы функций активации."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Применение нейронных сетей к задачам классификации",
      "lesson_objective": "Студент сможет обучить нейронную сеть на реальном наборе данных и оценить её точность",
      "key_topics": [
        "Подготовка и нормализация данных (MNIST)",
        "Функция потерь кросс-энтропия для классификации",
        "Метрика точности и матрица ошибок",
        "Тестирование модели на отложенной выборке"
      ],
      "exercises": [
        {
          "exercise_title": "Обучение сети на наборе MNIST",
          "exercise_instructions": "С помощью ранее созданного MLP обучите модель на датасете MNIST (28x28 изображений цифр). Используйте кросс-энтропию в качестве функции потерь и оптимизатор Adam. Обучите модель минимум 5 эпох."
        },
        {
          "exercise_title": "Оценка точности на тестовой выборке",
          "exercise_instructions": "После обучения вычислите точность модели на тестовой части MNIST. Сформируйте таблицу с показателями точности, полноты и F1-score для каждой цифры."
        }
      ]
    }
  ]
}