{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Раздел посвящён фундаментальным понятиям нейронных сетей: математическим основам, типам архитектур, процессу обучения и методам борьбы с переобучением. В каждом уроке представлены теоретические материалы, практические примеры и упражнения для закрепления знаний.",
  "learning_objectives": [
    "Студенты смогут описать математические принципы работы нейронных сетей",
    "Студенты смогут классифицировать основные типы нейронных сетей и их области применения",
    "Студенты смогут построить и обучить простую нейронную сеть на реальном наборе данных",
    "Студенты смогут применять методы регуляризации для улучшения обобщающей способности модели"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Математические основы нейронных сетей",
      "lesson_objective": "Студенты смогут объяснить роль линейных преобразований, функций активации и градиентного спуска в нейронных сетях",
      "key_topics": [
        "Линейные модели и взвешенные суммы",
        "Функции активации: сигмоида, ReLU, tanh",
        "Функция потерь и её градиент",
        "Алгоритм градиентного спуска"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация функции активации ReLU",
          "exercise_instructions": "Напишите на Python функцию relu(x), которая возвращает max(0, x) для скалярного или массивного входа. Проверьте работу функции на наборе тестовых значений."
        },
        {
          "exercise_title": "Вычисление градиента функции потерь",
          "exercise_instructions": "Для функции потерь L = (y_pred - y_true)^2 вычислите вручную её производную по y_pred и реализуйте в коде функцию, принимающую y_pred и y_true и возвращающую градиент."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Структура и типы нейронных сетей",
      "lesson_objective": "Студенты смогут различать архитектуры полносвязных, сверточных и рекуррентных нейронных сетей и определить их применение",
      "key_topics": [
        "Перцептрон и многослойный перцептрон (MLP)",
        "Сверточные нейронные сети (CNN): свёртки, пулинг",
        "Рекуррентные нейронные сети (RNN): скрытые состояния, LSTM",
        "Сравнение количества параметров в разных архитектурах"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнительный анализ параметров MLP и CNN",
          "exercise_instructions": "Рассчитайте количество обучаемых параметров для MLP с 2 скрытыми слоями (по 128 нейронов) и для простой CNN с одним сверточным слоем (32 фильтра, размер ядра 3x3) на входе 28x28 пикселей. Оформите результаты в таблице."
        },
        {
          "exercise_title": "Визуализация свёрток",
          "exercise_instructions": "С помощью библиотеки PyTorch создайте случайные фильтры 3x3 и визуализируйте их как изображения. Опишите, как разные фильтры могут выделять различные признаки."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение нейронных сетей на практике",
      "lesson_objective": "Студенты смогут построить и обучить простую MLP на наборе данных MNIST, оценить её точность и проанализировать результаты",
      "key_topics": [
        "Подготовка данных MNIST: нормализация и разбиение",
        "Инициализация весов и смещения",
        "Эпохи, батчи и оптимизатор Adam",
        "Метрики качества: точность, кросс-энтропия"
      ],
      "exercises": [
        {
          "exercise_title": "Создание и обучение MLP в Keras",
          "exercise_instructions": "Напишите скрипт на Python, использующий TensorFlow/Keras, который загружает MNIST, создает MLP с двумя скрытыми слоями (128 и 64 нейрона) и обучает её 10 эпох. Выведите окончательную точность на тестовом наборе."
        },
        {
          "exercise_title": "Анализ ошибок классификации",
          "exercise_instructions": "После обучения модели построьте матрицу ошибок и отобразите 5 примеров, где модель ошиблась, указав предсказанный и истинный классы."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Проблемы переобучения и методы регуляризации",
      "lesson_objective": "Студенты смогут применять техники регуляризации (Dropout, L1/L2) и ранней остановки для снижения переобучения модели",
      "key_topics": [
        "Переобучение: признаки и последствия",
        "Dropout: принцип работы и настройка",
        "L1 и L2 регуляризация: штрафные члены",
        "Ранняя остановка (early stopping) и контроль валидационной ошибки"
      ],
      "exercises": [
        {
          "exercise_title": "Эксперимент с Dropout в MLP",
          "exercise_instructions": "Модифицируйте модель из урока 3, добавив слой Dropout с вероятностью 0.5 после каждого скрытого слоя. Обучите модель и сравните точность с базовой моделью без Dropout."
        },
        {
          "exercise_title": "Применение L2 регуляризации",
          "exercise_instructions": "Добавьте к весам модели L2 штраф с коэффициентом 0.01 и обучите модель. Зафиксируйте изменения в функции потерь и точности на тренировочном и валидационном наборах."
        }
      ]
    }
  ]
}