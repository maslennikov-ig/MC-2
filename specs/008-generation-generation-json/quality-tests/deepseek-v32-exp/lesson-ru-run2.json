{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с фундаментальными концепциями и архитектурой нейронных сетей. Студенты изучат базовые принципы работы искусственных нейронов, структуру различных типов сетей и процесс их обучения через алгоритм обратного распространения ошибки. Раздел закладывает теоретическую основу для понимания более сложных моделей глубокого обучения.",
  "learning_objectives": [
    "Объяснить принцип работы искусственного нейрона и его компонентов",
    "Сравнить архитектуры полносвязных, сверточных и рекуррентных сетей",
    "Рассчитать выходное значение нейрона по заданным входным сигналам и весам",
    "Опиcать этапы алгоритма обратного распространения ошибки",
    "Проанализировать влияние функции активации на выход нейронной сети"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон: кирпичик интеллекта",
      "lesson_objective": "Студенты смогут рассчитать выходное значение искусственного нейрона, зная его входные сигналы, веса и функцию активации.",
      "key_topics": [
        "Модель искусственного нейрона: входы, веса, сумматор, смещение",
        "Пороговая функция активации и ее ограничения",
        "Линейная и сигмоидная функции активации",
        "Практический расчет выхода нейрона на численном примере"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Даны три входных сигнала: [0.5, 1.5, -0.8], веса связей: [0.7, -0.4, 1.2] и смещение +0.5. Рассчитайте взвешенную сумму и примените сигмоидную функцию активации для определения итогового выхода нейрона."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура нейронных сетей: от перцептрона до глубины",
      "lesson_objective": "Студенты смогут графически изобразить и описать различия между полносвязной, сверточной и рекуррентной архитектурами нейронных сетей.",
      "key_topics": [
        "Однослойный перцептрон и его ограничения",
        "Многослойные сети: входной, скрытые и выходной слои",
        "Принцип полносвязной архитектуры (Fully Connected)",
        "Особенности архитектуры сверточных сетей для обработки изображений",
        "Принцип работы рекуррентных сетей с обратными связями"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение архитектур",
          "exercise_instructions": "Нарисуйте схематичное представление трех различных архитектур: полносвязной сети с одним скрытым слоем (3 нейрона), простой сверточной сети и рекуррентной ячейки. Подпишите ключевые элементы и укажите, для решения каких типов задач предпочтительна каждая архитектура."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение сети: алгоритм обратного распространения ошибки",
      "lesson_objective": "Студенты смогут последовательно описать все этапы одного цикла алгоритма обратного распространения ошибки для простой сети.",
      "key_topics": [
        "Функция потерь как мера ошибки сети",
        "Прямой проход: расчет выхода сети",
        "Принцип градиентного спуска для минимизации ошибки",
        "Обратный проход: вычисление градиентов и обновление весов",
        "Роль скорости обучения в процессе обновления параметров"
      ],
      "exercises": [
        {
          "exercise_title": "Проход по алгоритму обучения",
          "exercise_instructions": "Опишите шаг за шагом один полный цикл обучения (эпоху) для сети с одним скрытым слоем. Начните с прямого прохода, затем рассчитайте ошибку и детально опишите процесс обратного распространения для обновления весов. Используйте схему сети для наглядности."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Функции активации: от линейности к нелинейности",
      "lesson_objective": "Студенты смогут сравнить и выбрать подходящую функцию активации для заданного сценария, обосновав свой выбор.",
      "key_topics": [
        "Проблема линейности и необходимость нелинейных функций",
        "Сравнительный анализ Sigmoid, Tanh и ReLU",
        "Преимущества и недостатки функции ReLU",
        "Проблема «умирающего ReLU» и современные альтернативы (Leaky ReLU, ELU)",
        "Функции активации для выходного слоя в задачах классификации и регрессии"
      ],
      "exercises": [
        {
          "exercise_title": "Выбор функции активации",
          "exercise_instructions": "Даны три сценария: 1) Выходной слой для бинарной классификации. 2) Скрытый слой глубокой сети. 3) Задача предсказания вещественного числа (регрессия). Для каждого сценария выберите наиболее подходящую функцию активации и кратко обоснуйте свой выбор, указав на ее сильные стороны в данном контексте."
        }
      ]
    }
  ]
}