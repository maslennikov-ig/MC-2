{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с фундаментальными концепциями нейронных сетей. Слушатели изучат базовые математические принципы, лежащие в основе их работы, архитектуру различных типов сетей и процесс их обучения. Раздел содержит теоретические объяснения и практические примеры для закрепления материала.",
  "learning_objectives": [
    "Объяснять структуру и функцию искусственного нейрона",
    "Сравнивать различные архитектуры нейронных сетей и их применение",
    "Описать процесс прямого и обратного распространения ошибки",
    "Анализировать влияние функции активации на выход сети",
    "Решать типовые задачи с использованием простых нейронных сетей"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон: строительный блок интеллекта",
      "lesson_objective": "Студенты смогут вычислить выход искусственного нейрона для заданных входных данных, весов и функции активации.",
      "key_topics": [
        "Математическая модель искусственного нейрона: входы, веса, смещение",
        "Функция суммирования и вычисление взвешенной суммы",
        "Обзор функций активации: сигмоида, ReLU, гиперболический тангенс",
        "Практический пример расчета выхода нейрона для задачи классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Даны три входных сигнала, соответствующие веса и смещение. Рассчитайте взвешенную сумму и примените функцию активации ReLU для определения конечного выхода нейрона."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектуры нейронных сетей: от перцептрона до многослойных структур",
      "lesson_objective": "Студенты смогут схематично изобразить и описать различия между полносвязной, сверточной и рекуррентной архитектурами.",
      "key_topics": [
        "Однослойный перцептрон: возможности и ограничения",
        "Многослойные сети (MLP): скрытые слои и повышение выразительной силы",
        "Введение в сверточные сети (CNN) для обработки изображений",
        "Введение в рекуррентные сети (RNN) для последовательностей данных"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение архитектур",
          "exercise_instructions": "Для трех предложенных задач (распознавание рукописных цифр, прогнозирование временных рядов, анализ тональности текста) выберите наиболее подходящий тип архитектуры нейронной сети и обоснуйте свой выбор."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение сети: алгоритм обратного распространения ошибки",
      "lesson_objective": "Студенты смогут описать один полный шаг алгоритма обратного распространения для простой сети, включая расчет градиентов.",
      "key_topics": [
        "Функция потерь: количественная оценка ошибки сети",
        "Градиентный спуск: принцип минимизации функции потерь",
        "Цепное правило для вычисления градиентов в сложных функциях",
        "Пошаговый разбор алгоритма обратного распространения на примере сети с одним скрытым слоем"
      ],
      "exercises": [
        {
          "exercise_title": "Трассировка обратного распространения",
          "exercise_instructions": "Для заданной простой сети с известными весами, входными данными и целевым значением рассчитайте ошибку на выходе и выполните один шаг обратного распространения, чтобы определить, как нужно изменить один из весов."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Функции активации: придание нелинейности сети",
      "lesson_objective": "Студенты смогут сравнить графики и свойства трех основных функций активации и выбрать подходящую для конкретного сценария.",
      "key_topics": [
        "Сравнительный анализ Sigmoid, Tanh и ReLU: формула, график, производная",
        "Проблема затухающих градиентов в сигмоидальных функциях",
        "Преимущества ReLU и его модификации (Leaky ReLU)",
        "Влияние функции активации на скорость обучения и конечную точность модели"
      ],
      "exercises": [
        {
          "exercise_title": "Выбор функции активации",
          "exercise_instructions": "Проанализируйте задачу бинарной классификации с потенциальной проблемой затухающих градиентов. Объясните, почему в данном случае предпочтительнее использовать Tanh вместо Sigmoid, и аргументируйте, могла ли бы здесь работать ReLU."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Практикум: построение и обучение простой нейросети для логических операций",
      "lesson_objective": "Студенты смогут вручную настроить веса и смещение в однослойной сети для реализации логической функции ИЛИ.",
      "key_topics": [
        "Формулировка задачи классификации для логических операций",
        "Определение пороговых значений для функции активации",
        "Подбор весовых коэффициентов для разделения классов",
        "Визуализация принятия решений на двумерной плоскости"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация логического ИЛИ",
          "exercise_instructions": "Используя перцептрон с пороговой функцией активации, подберите значения весов и смещения так, чтобы сеть корректно воспроизводила таблицу истинности для логической операции ИЛИ. Изобразите полученную разделяющую линию на графике."
        }
      ]
    }
  ]
}