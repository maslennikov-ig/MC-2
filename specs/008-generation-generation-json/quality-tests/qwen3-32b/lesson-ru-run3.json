```json
{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с базовыми концепциями и теорией нейронных сетей, включая структуру, принципы работы, типы и примеры применения. Студенты научатся проектировать простые сети, анализировать их обучение и оптимизировать производительность.",
  "learning_objectives": [
    "Описать структуру и компоненты нейронных сетей.",
    "Рассчитывать выходы нейронов с использованием функций активации.",
    "Объяснить алгоритм обратного распространения ошибки.",
    "Сравнить разные типы нейронных сетей и их сценарии применения.",
    "Применять методы регуляризации для предотвращения переобучения."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Структура и функционирование нейронной сети",
      "lesson_objective": "Студенты смогут объяснить базовую архитектуру нейронной сети и роль функций активации.",
      "key_topics": [
        "Составные части нейронной сети: нейроны, слои, синапсы",
        "Типы слоев (входной, скрытый, выходной)",
        "Функции активации (ReLU, сигмоида, гиперболический тангенс)",
        "Пример: реализация простой однослойной сети"
      ],
      "exercises": [
        {
          "exercise_title": "Проектирование архитектуры сети",
          "exercise_instructions": "Рисуйте схему нейронной сети с 3 входными, 2 скрытыми и 1 выходным слоем. Укажите типы функций активации для каждого слоя."
        },
        {
          "exercise_title": "Вычисление выхода нейрона",
          "exercise_instructions": "Для заданных входных данных (x1=2, x2=3) и весов (w1=0.5, w2=-1) рассчитайте выход нейрона с помощью функции ReLU."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Обучение нейронных сетей: обратное распространение ошибки",
      "lesson_objective": "Студенты научатся применять алгоритм обратного распространения для корректировки весов сети.",
      "key_topics": [
        "Функция потерь (MSE, кросс-энтропия)",
        "Алгоритм обратного распространения ошибки (backpropagation)",
        "Градиентный спуск и его роль в обучении",
        "Пример: ручной расчет градиентов для однослойной сети"
      ],
      "exercises": [
        {
          "exercise_title": "Шаг обратного распространения",
          "exercise_instructions": "Для сети с одним нейроном (вход x=1, вес w=0.5, смещение b=0.1) рассчитайте градиенты по весам и смещению при ошибке 0.3 и функции потерь MSE."
        },
        {
          "exercise_title": "Оптимизация весов",
          "exercise_instructions": "Используя изученный градиентный спуск, обновите веса и смещение нейрона из предыдущего задания, установите скорость обучения 0.1."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Сравнение типов нейронных сетей",
      "lesson_objective": "Студенты смогут анализировать подходы, в которых различные типы сетей (CNN, RNN) наиболее эффективны.",
      "key_topics": [
        "Полносвязные сети (FCN) и их ограничения",
        "Сверточные сети (CNN) и их применение в обработке изображений",
        "Рекуррентные сети (RNN) и обработка временных данных",
        "Выбор архитектуры в зависимости от задачи"
      ],
      "exercises": [
        {
          "exercise_title": "Классификация задач",
          "exercise_instructions": "Назовите, какие типы нейронных сетей подходят для классификации текстов, обнаружения объектов на изображениях и прогнозирования временных рядов. Обоснуйте выбор."
        },
        {
          "exercise_title": "Анализ архитектуры",
          "exercise_instructions": "Опишите, почему сверточные сети лучше справляются с визуальными данными, чем полносвязные. Укажите минимум 3 причины."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Оптимизация и инициализация весов",
      "lesson_objective": "Студенты научатся применять методы инициализации весов и оптимизации для улучшения сходимости.",
      "key_topics": [
        "Методы инициализации весов (Xavier, He)",
        "Алгоритмы оптимизации (SGD, Adam)",
        "Регулировка скорости обучения (learning rate)",
        "Пример: сравнение сходимости при разных инициализациях"
      ],
      "exercises": [
        {
          "exercise_title": "Выбор оптимизатора",
          "exercise_instructions": "Для задачи классификации изображений определите, какой оптимизатор (SGD или Adam) предпочтительнее, и объясните преимущества."
        },
        {
          "exercise_title": "Инициализация весов",
          "exercise_instructions": "Реализуйте инициализацию весов методом He для слоя с 100 нейронами. Рассчитайте стандартное отклонение для случайного распределения."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Решение проблемы переобучения",
      "lesson_objective": "Студенты будут уметь диагностировать переобучение и применять методы регуляризации.",
      "key_topics": [
        "Причины и признаки переобучения",
        "Методы регуляризации (L1, L2, dropout)",
        "Ранняя остановка (early stopping)",
        "Пример: сеть с dropout для классификации текстов"
      ],
      "exercises": [
        {
          "exercise_title": "Диагностика переобучения",
          "exercise_instructions": "На графике обучения сети укажите участки, где наблюдается переобучение. Объясните, как изменить архитектуру для его снижения."
        },
        {
          "exercise_title": "Применение dropout",
          "exercise_instructions": "Добавьте слой dropout (коэффициент 0.5) к существующей модели. Поясните, как он влияет на обобщение сети."
        }
      ]
    }
  ]
}
```