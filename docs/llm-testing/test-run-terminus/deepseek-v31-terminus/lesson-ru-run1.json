{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с фундаментальными концепциями нейронных сетей. Слушатели изучат базовые принципы работы искусственных нейронов, архитектуру простейших сетей, процесс обучения на примерах и ключевые математические понятия, такие как функция активации и градиентный спуск. Теория подкрепляется понятными аналогиями и практическими упражнениями для закрепления материала.",
  "learning_objectives": [
    "Объяснить принцип работы искусственного нейрона и его компоненты",
    "Сравнить различные функции активации и их влияние на выход сети",
    "Опиcать процесс прямого распространения сигнала в нейронной сети",
    "Вычислить ошибку прогноза с использованием функции потерь",
    "Применить принцип градиентного спуска для обновления весов на простом примере"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон: строительный блок интеллекта",
      "lesson_objective": "Студенты смогут вычислить выходное значение искусственного нейрона, задав входные данные, веса и функцию активации.",
      "key_topics": [
        "Биологический прототип и его искусственная модель",
        "Структура нейрона: входы, веса, сумматор, функция активации",
        "Пороговая функция активации (шаговая функция)",
        "Линейная функция активации и ее ограничения",
        "Практический пример: нейрон как классификатор"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Даны три входа (x1=1, x2=0, x3=1) и соответствующие веса (w1=0.5, w2=-0.3, w3=0.8). Смещение (bias) равно 0.2. Рассчитайте взвешенную сумму и примените пороговую функцию активации (выход = 1, если сумма >= 0, иначе 0). Определите итоговый выход нейрона."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Нелинейность: почему важны функции активации",
      "lesson_objective": "Студенты смогут выбрать и обосновать применение конкретной функции активации (сигмоида, ReLU, гиперболический тангенс) для заданного сценария.",
      "key_topics": [
        "Ограничения линейных моделей",
        "Сигмоидальная функция: свойства и область значений",
        "Гиперболический тангенс: сравнение с сигмоидой",
        "Функция ReLU (Rectified Linear Unit) и ее преимущества",
        "Влияние функции активации на способность сети обучаться"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "Для заданного значения взвешенной суммы (z = 2.5) рассчитайте выходное значение, используя три функции: сигмоиду, гиперболический тангенс и ReLU. Проанализируйте полученные результаты и предложите, какая функция лучше подойдет для выходного слона в задаче бинарной классификации."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "От нейрона к сети: архитектура полносвязного слоя",
      "lesson_objective": "Студенты смогут визуализировать и описать процесс прямого распространения (forward propagation) для однослойной нейронной сети с несколькими выходами.",
      "key_topics": [
        "Построение сети из множества нейронов",
        "Понятие входного, скрытого и выходного слоев",
        "Матричное представление весов и вычислений",
        "Алгоритм прямого распространения сигнала по слоям",
        "Пример: простая сеть для распознавания рукописных цифр"
      ],
      "exercises": [
        {
          "exercise_title": "Прямое распространение в двухслойной сети",
          "exercise_instructions": "Дана небольшая сеть: входной слой (2 нейрона), один скрытый слой (3 нейрона с функцией активации ReLU), выходной слой (1 нейрон с сигмоидой). Заданы матрицы весов и смещений. Подайте на вход вектор [0.5, -1.0] и рассчитайте выходное значение сети, выполнив последовательные вычисления для каждого слоя."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Ошибка прогноза: измеряем неточность с помощью функций потерь",
      "lesson_objective": "Студенты смогут вычислить значение функции потерь (среднеквадратичная ошибка и кросс-энтропия) для заданного прогноза сети и истинного значения.",
      "key_topics": [
        "Цель функции потерь (loss function)",
        "Среднеквадратичная ошибка (MSE) для задач регрессии",
        "Кросс-энтропия (Cross-Entropy) для задач классификации",
        "Интерпретация значения ошибки",
        "Зависимость функции потерь от весов сети"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет функции потерь",
          "exercise_instructions": "Сеть предсказала вероятность принадлежности объекта к классу '1' как 0.7. Истинная метка объекта равна 1. Рассчитайте значение кросс-энтропийной потери для этого примера. Затем предположите, что истинная метка равна 0, и выполните расчет снова. Сравните результаты."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Принцип обучения: градиентный спуск для минимизации ошибки",
      "lesson_objective": "Студенты смогут выполнить одну итерацию градиентного спуска для обновления одного веса нейрона, зная значение градиента функции потерь.",
      "key_topics": [
        "Задача оптимизации: поиск минимальной ошибки",
        "Интуитивное понимание градиента как направления наискорейшего роста",
        "Алгоритм градиентного спуска: шаг обучения (learning rate)",
        "Формула обновления веса: новый_вес = старый_вес - скорость_обучения * градиент",
        "Аналогия с движением вниз по холму"
      ],
      "exercises": [
        {
          "exercise_title": "Обновление веса методом градиентного спуска",
          "exercise_instructions": "Дан вес w = 1.5. Градиент функции потерь по этому весу равен 0.8. Скорость обучения (alpha) установлена в 0.1. Рассчитайте новое значение веса после одной итерации градиентного спуска. Объясните, почему вес уменьшился."
        }
      ]
    }
  ]
}