{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Данная секция знакомит с фундаментальными принципами работы нейронных сетей, которые являются ключевой технологией современного машинного обучения. Вы изучите базовую архитектуру, процесс обучения и научитесь реализовывать простую нейросеть.",
  "learning_objectives": [
    "Понимать и объяснять архитектуру перцептрона и многослойного перцептрона (MLP).",
    "Реализовать прямой проход (forward pass) для вычисления выхода нейронной сети.",
    "Понимать принцип работы функции потерь и алгоритма обратного распространения ошибки (backpropagation).",
    "Обучить простую нейронную сеть для решения задачи бинарной классификации с использованием библиотеки NumPy."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Введение в нейроны и архитектуры сетей",
      "lesson_objective": "Создать и вычислить выход искусственного нейрона и описать структуру многослойного перцептрона.",
      "key_topics": [
        "Биологический нейрон vs. Искусственный нейрон",
        "Модель перцептрона: веса, смещение, функция активации",
        "Обзор функций активации: сигмоида, ReLU, гиперболический тангенс",
        "Многослойный перцептрон (MLP): входной, скрытый и выходной слои",
        "Представление сети в виде вычислительного графа"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода искусственного нейрона",
          "exercise_instructions": "1. Задайте входной вектор X = [1.5, 2.0, 0.5]. 2. Задайте вектор весов W = [0.8, -0.4, 1.0] и смещение b = 0.5. 3. Рассчитайте взвешенную сумму z = (X1*W1 + X2*W2 + X3*W3) + b. 4. Примените функцию активации sigmoid(z) = 1 / (1 + e^{-z}) к полученной сумме. 5. Запишите итоговое значение выхода нейрона."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Прямое распространение (Forward Propagation)",
      "lesson_objective": "Реализовать алгоритм прямого распространения для простой трехслойной нейронной сети.",
      "key_topics": [
        "Цель прямого распространения: от входов к выходу",
        "Матричное представление вычислений для полносвязного слоя",
        "Последовательное применение весов, смещений и функций активации",
        "Преимущества векторных операций для эффективности",
        "Интерпретация выхода сети"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация прямого прохода на NumPy",
          "exercise_instructions": "1. Импортируйте библиотеку NumPy. 2. Создайте массив входных данных X размером (1, 3). 3. Определите матрицы весов W1 (3x4) и W2 (4x1) и векторы смещений b1 (1x4), b2 (1x1), инициализированные случайными значениями. 4. Рассчитайте выход первого слоя: A1 = sigmoid(X @ W1 + b1). 5. Рассчитайте выход сети (второй слой): A2 = sigmoid(A1 @ W2 + b2). 6. Выведите финальное предсказание A2."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение сети: Функция потерь и обратное распространение",
      "lesson_objective": "Рассчитать функцию потерь и градиенты для обновления весов с помощью алгоритма обратного распространения ошибки.",
      "key_topics": [
        "Функции потерь (Loss Functions): MSE, бинарная кросс-энтропия",
        "Интуиция behind обратного распространения ошибки (backpropagation)",
        "Цепное правило для вычисления градиентов",
        "Обновление весов с использованием градиентного спуска",
        "Гиперпараметр скорость обучения (learning rate)"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет градиентов вручную для одного примера",
          "exercise_instructions": "1. Для упрощенной сети (1 вход, 1 выход, без смещения) задайте истинное значение y_true=1. 2. Выполните прямой проход, получите предсказание y_pred. 3. Рассчитайте значение функции потерь бинарной кросс-энтропии. 4. Используя цепное правило, вычислите градиент функции потерь по весу ∂L/∂w. 5. Предположив learning rate = 0.1, рассчитайте новое значение веса w_new = w_old - learning_rate * ∂L/∂w."
        },
        {
          "exercise_title": "Полный цикл обучения на одном примере",
          "exercise_instructions": "1. Объедините упражнения из Урока 2 и 3. 2. Выполните прямой проход для одного тренировочного примера. 3. Рассчитайте функцию потерь. 4. Реализуйте обратный проход, вычислив градиенты для всех весов и смещений. 5. Обновите все параметры сети, используя градиентный спуск. 6. Зафиксируйте, как изменилось значение функции потерь после одной итерации."
        }
      ]
    }
  ]
}