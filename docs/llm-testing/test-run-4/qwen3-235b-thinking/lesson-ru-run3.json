{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Эта секция познакомит вас с архитектурой и принципами работы искусственных нейронных сетей. Вы изучите ключевые компоненты, процессы обучения и практическое применение базовых моделей. К концу секции вы сможете самостоятельно проектировать и тренировать простые нейронные сети.",
  "learning_objectives": [
    "Объяснять структуру искусственного нейрона и роль функций активации",
    "Строить и обучать однослойную нейронную сеть для задач классификации",
    "Применять метод обратного распространения ошибки для настройки весов",
    "Анализировать влияние гиперпараметров на процесс обучения",
    "Реализовывать базовые нейронные сети с использованием фреймворков Python"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Архитектура нейронных сетей: от нейрона к слоям",
      "lesson_objective": "Построить математическую модель искусственного нейрона и проанализировать компоненты многослойной архитектуры",
      "key_topics": [
        "Биологические аналоги и искусственные нейроны",
        "Веса, смещения и линейная комбинация",
        "Функции активации (ReLU, sigmoid, tanh)",
        "Входные, скрытые и выходные слои",
        "Прямое распространение сигнала"
      ],
      "exercises": [
        {
          "exercise_title": "Визуализация архитектуры",
          "exercise_instructions": "Нарисуйте схему нейронной сети с 2 входами, 1 скрытым слоем (3 нейрона) и выходным слоем. Подпишите все компоненты: веса, функции активации, входные/выходные значения."
        },
        {
          "exercise_title": "Ручной расчет выхода нейрона",
          "exercise_instructions": "Для нейрона с входами [0.5, -1.2], весами [0.8, -0.3] и смещением 0.5 вычислите выходное значение, используя функцию активации sigmoid. Продемонстрируйте все этапы вычислений."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Процесс обучения: функции потерь и оптимизация",
      "lesson_objective": "Реализовать вычисление градиентов и обновление весов с использованием метода обратного распространения",
      "key_topics": [
        "Функции потерь (MSE, категориальная кросс-энтропия)",
        "Градиентный спуск и его модификации",
        "Механизм обратного распространения ошибки",
        "Выбор скорости обучения",
        "Проблемы переобучения и регуляризация"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет функции потерь",
          "exercise_instructions": "Для задачи бинарной классификации с истинными метками [1, 0, 1] и предсказанными вероятностями [0.7, 0.4, 0.9] вычислите значение категориальной кросс-энтропии. Приведите формулу и пошаговые вычисления."
        },
        {
          "exercise_title": "Обратное распространение вручную",
          "exercise_instructions": "Для простой сети с 1 нейроном (входы: [2, 3], веса: [0.1, -0.2], смещение: 0.5, функция активации sigmoid) и реальным выходом 0.8, вычислите градиенты для весов при значении функции потерь MSE. Выполните один шаг обновления весов с lr=0.01."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Практическая реализация с использованием фреймворков",
      "lesson_objective": "Создать и обучить нейронную сеть для распознавания изображений, используя библиотеку Keras",
      "key_topics": [
        "Работа с TensorFlow/Keras API",
        "Подготовка данных для обучения",
        "Компиляция модели и выбор оптимизатора",
        "Анализ метрик качества обучения",
        "Настройка гиперпараметров через эксперименты"
      ],
      "exercises": [
        {
          "exercise_title": "Построение сети для MNIST",
          "exercise_instructions": "Используя набор данных MNIST, создайте нейронную сеть с 1 скрытым слоем (128 нейронов, ReLU) и выходным слоем (10 нейронов, softmax). Обучите модель на 5 эпохах, сохраните график потерь и точности. Определите эпоху с наилучшим результатом."
        },
        {
          "exercise_title": "Эксперимент с гиперпараметрами",
          "exercise_instructions": "Модифицируйте предыдущую модель: измените количество нейронов в скрытом слое (64 и 256), протестируйте разные оптимизаторы (SGD, Adam). Сравните результаты по метрике accuracy и объясните различия в поведении обучения."
        }
      ]
    }
  ]
}