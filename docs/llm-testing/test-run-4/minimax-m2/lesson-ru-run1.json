{"section_number": 1, "section_title": "Основы нейронных сетей", "section_description": "В этой секции вы изучите фундаментальные идеи нейронных сетей и примените их на практике. Начнёте с персептрона и пошагово освоите обратное распространение ошибки, обучение и регуляризацию. Завершите мини-проектом классификации изображений с PyTorch и построением кривых обучения.", "learning_objectives": ["Реализовать персептрон и простейшую сеть с нуля на NumPy для двоичной классификации и объяснить влияние скорости обучения.", "Объяснить работу обратного распространения ошибки и обучить 2-слойный MLP на малой выборке, оценив точность и F1.", "Провести эксперименты с гиперпараметрами и регуляризацией (L2, dropout) и интерпретировать кривые обучения/валидации.", "Построить и обучить CNN в PyTorch для классификации малого датасета изображений, достигнув не менее 70% точности на валидации.", "Понимать и различать основные функции активации (sigmoid, tanh, ReLU) и подбирать их под тип задачи."], "lessons": [{"lesson_number": 1, "lesson_title": "Персептрон: от идеи до реализации", "lesson_objective": "Реализовать персептрон на чистом NumPy и научиться классифицировать линейно разделимые данные, оценивая влияние скорости обучения.", "key_topics": ["Модель нейрона и линейная модель", "Алгоритм обучения персептрона", "Скорость обучения и его влияние", "Простая визуализация границы решения", "Оценка точности на отложенной выборке"], "exercises": [{"exercise_title": "Персептрон на синтетических данных", "exercise_instructions": "Сгенерируйте линейно разделимый синтетический набор (например, make_classification в scikit-learn с 2 классами и 2 признаками). Реализуйте персептрон на чистом NumPy с обновлением весов по правилу персептрона. Обучите 3 модели со скоростями обучения 0.01, 0.1 и 1.0. Разбейте данные на обучение/валидацию (80/20) и постройте график точности по эпохам для каждой скорости. Сохраните финальные значения точности на валидации."}]}, {"lesson_number": 2, "lesson_title": "Многослойные сети и обратное распространение ошибки", "lesson_objective": "Объяснить и применить алгоритм обратного распространения ошибки для обучения двухслойной сети на малой классификационной задаче и интерпретировать метрики.", "key_topics": ["Функции активации (sigmoid, tanh, ReLU) и их производные", "Функции потерь для классификации (кросс-энтропия)", "Обратное распространение ошибки: прямая и обратная фазы", "Обучение двухслойного MLP на синтетическом наборе", "Метрики: accuracy, precision, recall, F1"], "exercises": [{"exercise_title": "MLP для двоичной классификации на Iris (линейно разделимый случай)", "exercise_instructions": "Загрузите набор Iris, возьмите классы 0 (setosa) и 1 (versicolor) и признаки sepal_length и petal_length. Реализуйте двухслойный MLP (1 скрытый слой 8 нейронов, ReLU; выходной sigmoid) на чистом NumPy с кросс-энтропией. Обучите 200 эпох с шагом градиентного спуска 0.1 и мини-батчами по 16. Разбейте 80/20 на обучение/валидацию. Выведите accuracy, precision, recall и F1 на валидации. Опишите, почему точность велика на этом поднаборе (линейная разделимость)."}, {"exercise_title": "MLP через scikit-learn и сравнение с логистической регрессией", "exercise_instructions": "Используя весь набор Iris (3 класса), обучите модель MLPClassifier (скрытый слой: (10,), activation='relu', solver='lbfgs', max_iter=1000) и логистическую регрессию. Разбейте 80/20. Сравните accuracy на валидации и обсудите разницу, если она есть. Объясните, где нелинейность MLP могла дать преимущество."}]}, {"lesson_number": 3, "lesson_title": "Динамика обучения и регуляризация", "lesson_objective": "Провести эксперименты с гиперпараметрами и применить регуляризацию (L2 и dropout), чтобы контролировать переобучение и интерпретировать кривые обучения.", "key_topics": ["Инициализация весов и её влияние", "Градиентный спуск vs стохастический градиент", "L2-регуляризация (weight decay)", "Dropout как метод регуляризации", "Кривые обучения и валидации, переобучение"], "exercises": [{"exercise_title": "Эксперимент с шагом обучения и мини-батчами", "exercise_instructions": "На синтетическом наборе (например, two moons) обучите двухслойный MLP с ReLU. Сравните 4 конфигурации: шаг обучения 0.01/0.1 и размер мини-батча 16/128. Для каждой конфигурации постройте кривые потерь на обучении и валидации (200 эпох). Выберите лучшую по стабильности и финальной потере на валидации и объясните свой выбор."}, {"exercise_title": "L2 и dropout на более сложной задаче", "exercise_instructions": "На наборе с потенциалом к переобучению (например, MNIST mini 28x28, отфильтровать до 2 классов: 4 и 9) обучите MLP без регуляризации и с L2=0.001, а также с dropout 0.2 и 0.5. Разбейте 80/20. Постройте кривые точности на обучении и валидации. Объясните, какая настройка дала наименьший разрыв между точностью на обучении и валидации."}]}, {"lesson_number": 4, "lesson_title": "Практика с PyTorch: мини-проект классификации изображений", "lesson_objective": "Построить и обучить простую CNN в PyTorch для классификации малого датасета изображений, достигнув не менее 70% точности на валидации и построив кривые обучения.", "key_topics": ["Базовые тензорные операции в PyTorch", "Dataset/DataLoader и трансформации", "Определение CNN (Conv2d, MaxPool2d, Flatten, Linear)", "Функции потерь и оптимизатор (CrossEntropyLoss, Adam)", "Обучение по эпохам, сохранение чекпоинта", "Кривые обучения/валидации и отчёт о метриках"], "exercises": [{"exercise_title": "CNN на CIFAR-10mini (2 класса)", "exercise_instructions": "Используя CIFAR-10, отфильтруйте 2 класса, например, «cat» (3) и «dog» (5). Реализуйте CNN: Conv(32, 3x3) → ReLU → MaxPool → Conv(64, 3x3) → ReLU → MaxPool → Flatten → Linear(64*8*8, 128) → ReLU → Linear(128, 2). Обучите 10 эпох с Adam(lr=1e-3) и batch_size=64, используя аугментации: RandomHorizontalFlip и RandomCrop (с паддингом 4). Разделите на 80/20. Постройте графики потерь и точности по эпохам. Сохраните финальную точность на валидации и опишите, достигнут ли 70%."}, {"exercise_title": "Сохраняем лучший чекпоинт и отчёт", "exercise_instructions": "Дополнительно к предыдущему заданию: реализуйте раннюю остановку по точности на валидации (patience=3), сохраняйте лучший чекпоинт модели (state_dict) и по окончании обучения выведите финальный classification_report (accuracy, precision, macro avg, weighted avg). Приложите ссылку или путь к сохранённому чекпоинту и короткое резюме эксперимента (скорость обучения, лучшая эпоха, метрики)."}]}]}