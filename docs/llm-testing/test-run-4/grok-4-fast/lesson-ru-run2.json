{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "В этой секции вы изучите фундаментальные принципы нейронных сетей, включая их структуру и механизмы обучения. Мы разберем, как работают искусственные нейроны, слои и процессы распространения сигнала. К концу секции вы сможете самостоятельно реализовать простую нейронную сеть для базовых задач.",
  "learning_objectives": [
    "Понять структуру и компоненты искусственного нейрона.",
    "Описать процесс прямого и обратного распространения в нейронной сети.",
    "Реализовать простую многослойную персептронную сеть на Python.",
    "Выбрать и применить подходящие функции активации для разных задач.",
    "Объяснить базовые алгоритмы обучения, такие как градиентный спуск."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Введение в нейронные сети",
      "lesson_objective": "Определить ключевые понятия нейронных сетей и их биологическую аналогию.",
      "key_topics": [
        "Определение нейронной сети",
        "История развития",
        "Биологическая основа",
        "Искусственный нейрон: входы, веса, смещение",
        "Простые примеры применения"
      ],
      "exercises": [
        {
          "exercise_title": "Опишите компоненты искусственного нейрона",
          "exercise_instructions": "1. Перечислите три основных компонента искусственного нейрона (входы, веса, функция активации). 2. Нарисуйте схему простого нейрона с двумя входами. 3. Объясните роль весов в обработке сигнала."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура многослойных сетей",
      "lesson_objective": "Построить и описать структуру многослойной персептронной сети (MLP).",
      "key_topics": [
        "Слои: входной, скрытые, выходной",
        "Веса и смещения в слоях",
        "Прямое распространение сигнала",
        "Примеры архитектур для классификации",
        "Визуализация сети",
        "Преимущества многослойных сетей"
      ],
      "exercises": [
        {
          "exercise_title": "Создайте схему MLP",
          "exercise_instructions": "1. Нарисуйте схему сети с одним скрытым слоем (3 нейрона во входе, 2 в скрытом, 1 на выходе). 2. Укажите связи между слоями. 3. Опишите, как сигнал проходит от входа к выходу."
        },
        {
          "exercise_title": "Рассчитайте прямое распространение",
          "exercise_instructions": "1. Возьмите входные данные [1, 0]. 2. Укажите веса для первого нейрона скрытого слоя: [0.5, -0.3], смещение 0.1. 3. Вычислите выход нейрона без функции активации."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Функции активации и нелинейность",
      "lesson_objective": "Выбрать и реализовать функции активации для улучшения модели.",
      "key_topics": [
        "Роль нелинейных функций",
        "Sigmoid и логистическая функция",
        "ReLU и ее варианты",
        "Tanh и softmax",
        "Сравнение функций",
        "Влияние на обучение",
        "Проблемы vanishing gradient"
      ],
      "exercises": [
        {
          "exercise_title": "Реализуйте sigmoid в Python",
          "exercise_instructions": "1. Напишите функцию sigmoid(x) = 1 / (1 + exp(-x)) с использованием numpy. 2. Протестируйте на значениях [-2, 0, 2]. 3. Постройте график функции с помощью matplotlib."
        },
        {
          "exercise_title": "Сравните ReLU и sigmoid",
          "exercise_instructions": "1. Реализуйте ReLU(x) = max(0, x). 2. Примените обе функции к массиву [-1, 0, 1, 2]. 3. Объясните, почему ReLU предпочтительна для глубоких сетей."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Основы обучения нейронных сетей",
      "lesson_objective": "Реализовать базовый алгоритм обучения с использованием градиентного спуска.",
      "key_topics": [
        "Функция потерь (MSE, cross-entropy)",
        "Обратное распространение ошибки",
        "Градиентный спуск и его варианты",
        "Обновление весов",
        "Эпохи обучения и батчи",
        "Переобучение и регуляризация"
      ],
      "exercises": [
        {
          "exercise_title": "Реализуйте простой градиентный спуск",
          "exercise_instructions": "1. Создайте простую сеть с одним нейроном для регрессии (y = 2x + 1). 2. Используйте MSE как функцию потерь. 3. Обучите на данных: x=[1,2,3], y=[3,5,7] за 100 итераций, шаг обучения 0.01."
        },
        {
          "exercise_title": "Анализ обучения",
          "exercise_instructions": "1. В коде из предыдущего упражнения выведите потери после каждой эпохи. 2. Постройте график потерь. 3. Обсудите, как изменить шаг обучения для лучшей сходимости."
        },
        {
          "exercise_title": "Примените к классификации",
          "exercise_instructions": "1. Создайте сеть с sigmoid для бинарной классификации. 2. Обучите на простом датасете (например, XOR). 3. Оцените точность на тестовых данных."
        }
      ]
    }
  ]
}