{
  "section_number": 1,
  "section_title": "Введение в нейронные сети",
  "section_description": "Эта секция знакомит с базовыми принципами работы нейронных сетей, их компонентами и процессами обучения. Вы узнаете, как проектировать простые архитектуры и применять их к задачам классификации и регрессии.",
  "learning_objectives": [
    "Описать структуру и функции нейронных сетей, включая нейроны, слои и активационные функции.",
    "Реализовать простую нейронную сеть на Python с использованием библиотеки NumPy.",
    "Объяснить этапы обучения сети, такие как градиентный спуск и обратное распространение ошибки.",
    "Сравнить эффективность разных архитектур нейросетей на примере задач.",
    "Применить нейронные сети к реальным наборам данных для решения практических задач."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Структура нейронных сетей",
      "lesson_objective": "Изучить базовые элементы нейронных сетей и их взаимодействие.",
      "key_topics": [
        "Нейрон как функциональный элемент",
        "Слои и их типы (входной, скрытый, выходной)",
        "Активационные функции (ReLU, сигмоида, softmax)"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация одного нейрона",
          "exercise_instructions": "Напишите код на Python, имитирующий работу одного нейрона с весами [0.5, -0.2], смещением 0.1 и сигмоидной активационной функцией. Тестируйте его на входных данных [1, 2]."
        },
        {
          "exercise_title": "Симуляция слоя",
          "exercise_instructions": "Создайте класс в Python, моделирующий слой из 3 нейронов. Каждый нейрон должен использовать ReLU. Протестируйте слой на случайных входных данных."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Процесс обучения нейронных сетей",
      "lesson_objective": "Усвоить методы оптимизации и алгоритмы обучения для настройки параметров сети.",
      "key_topics": [
        "Функции потерь (MSE, кросс-энтропия)",
        "Градиентный спуск и его модификации",
        "Обратное распространение ошибки (backpropagation)"
      ],
      "exercises": [
        {
          "exercise_title": "Ручной расчет градиентного спуска",
          "exercise_instructions": "Для функции потерь MSE вычислите градиенты вручную на примере сети с одним нейроном и входными данными [x1, x2]."
        },
        {
          "exercise_title": "Имплементация backpropagation",
          "exercise_instructions": "Напишите программу, реализующую обратное распространение ошибки для сети с одним скрытым слоем. Используйте данные из файла и минимизируйте MSE."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Архитектуры нейросетей",
      "lesson_objective": "Ознакомиться с распространёнными типами архитектур и их особенностями.",
      "key_topics": [
        "Перцептрон многослойный (MLP)",
        "Сверточные нейронные сети (CNN)",
        "Рекуррентные нейронные сети (RNN)"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение архитектур",
          "exercise_instructions": "Объясните в текстовом документе, как MLP, CNN и RNN подходят для задач классификации текста, изображений и временных рядов соответственно."
        },
        {
          "exercise_title": "Выбор архитектуры для задачи",
          "exercise_instructions": "Для заданной задачи (например, распознавание рукописных цифр) опишите, почему CNN предпочтительнее MLP. Подкрепите выводы расчетами сложности."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Практика: Обучение простой сети",
      "lesson_objective": "Построить и обучить простую нейросеть для задачи классификации.",
      "key_topics": [
        "Подготовка данных для обучения",
        "Настройка гиперпараметров",
        "Оценка качества модели"
      ],
      "exercises": [
        {
          "exercise_title": "Классификация цветных изображений",
          "exercise_instructions": "Используя библиотеку TensorFlow/Keras, обучите сеть с одним скрытым слоем на наборе данных CIFAR-10. Оцените точность и визуализируйте потери."
        },
        {
          "exercise_title": "Тонкая настройка гиперпараметров",
          "exercise_instructions": "Сравните производительность модели при разных значениях learning rate (0.001, 0.01, 0.1) и количестве нейронов в скрытом слое (32, 64, 128)."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Улучшение производительности",
      "lesson_objective": "Изучить техники регуляризации и оптимизации для предотвращения переобучения.",
      "key_topics": [
        "Регуляризация L1/L2 и dropout",
        "Оптимизаторы (Adam, SGD)",
        "Валидация и кросс-валидация"
      ],
      "exercises": [
        {
          "exercise_title": "Применение dropout",
          "exercise_instructions": "Добавьте слой dropout в сеть из предыдущего урока. Обучите модель на том же наборе данных и сравните точность на тестовой выборке."
        },
        {
          "exercise_title": "Выбор оптимизатора",
          "exercise_instructions": "Замените SGD на Adam в вашей модели. Оцените, как это влияет на скорость сходимости и итоговую точность."
        }
      ]
    }
  ]
}