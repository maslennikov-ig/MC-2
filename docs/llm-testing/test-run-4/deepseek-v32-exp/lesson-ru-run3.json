{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "В этой секции вы познакомитесь с архитектурой и фундаментальными принципами работы нейронных сетей. Вы изучите основные компоненты, процесс обучения и создадите свою первую простую модель.",
  "learning_objectives": [
    "Объяснить структуру и функцию искусственного нейрона и слоев нейронной сети.",
    "Реализовать прямую передачу (forward propagation) для вычисления выхода сети.",
    "Рассчитать функцию потерь для оценки производительности модели.",
    "Применить алгоритм обратного распространения ошибки (backpropagation) для обновления весов на простом примере.",
    "Построить и обучить простую полносвязную нейронную сеть с использованием библиотеки высокого уровня (например, Keras)."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Введение в искусственные нейроны и архитектуру сетей",
      "lesson_objective": "Построить схему искусственного нейрона, объяснить его компоненты и описать структуру многослойного перцептрона (MLP).",
      "key_topics": [
        "Биологический нейрон vs. Искусственный нейрон",
        "Структура искусственного нейрона: входы, веса, сумматор, функция активации",
        "Обзор функций активации: сигмоида, tanh, ReLU",
        "Понятие слоев: входной, скрытый, выходной",
        "Архитектура полносвязной сети (многослойный перцептрон)"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "1. Даны три входа: x1=0.5, x2=-1.2, x3=0.8. 2. Даны соответствующие веса: w1=0.7, w2=-0.3, w3=0.9. 3. Рассчитайте взвешенную сумму. 4. Примените сигмоидную функцию активации к полученной сумме. 5. Запишите итоговый выход нейрона."
        },
        {
          "exercise_title": "Создание схемы сети",
          "exercise_instructions": "1. Нарисуйте схему полносвязной нейронной сети с 3 входными нейронами, одним скрытым слоем из 4 нейронов и выходным слоем из 2 нейронов. 2. Подпишите все слои. 3. Обозначьте веса на соединениях между одним нейроном скрытого слоя и всеми нейронами входного слоя."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Прямое распространение и функции потерь",
      "lesson_objective": "Вычислить выход многослойной сети с помощью прямого распространения и рассчитать значение функции потерь.",
      "key_topics": [
        "Алгоритм прямого распространения (Forward Propagation)",
        "Матричное представление вычислений для ускорения расчетов",
        "Назначение и виды функций потерь (Loss Functions)",
        "Функция среднеквадратичной ошибки (MSE) для регрессии",
        "Функция перекрестной энтропии (Cross-Entropy) для классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Прямое распространение в мини-сети",
          "exercise_instructions": "1. Дана сеть: 2 входа, скрытый слой с 2 нейронами (функция активации ReLU), выходной слой с 1 нейроном (функция активации сигмоида). 2. Заданы конкретные значения весов и смещений. 3. Для входного вектора [1, 0.5] выполните шаги прямого распространения, последовательно вычисляя выход каждого слоя. 4. Запишите итоговый выход сети."
        },
        {
          "exercise_title": "Расчет функции потерь",
          "exercise_instructions": "1. Предположим, истинное значение (целевое) для задачи регрессии равно 4. 2. Ваша модель на трех разных примерах предсказала значения: 3.5, 4.2, 5.0. 3. Рассчитайте среднеквадратичную ошибку (MSE) для этих трех предсказаний."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение сети: Градиентный спуск и обратное распространение",
      "lesson_objective": "Применить алгоритм обратного распространения ошибки для расчета градиентов и обновить веса сети на одну итерацию с помощью градиентного спуска.",
      "key_topics": [
        "Принцип градиентного спуска (Gradient Descent) для минимизации потерь",
        "Интуитивное понимание обратного распространения (Backpropagation) как правила цепочки",
        "Расчет градиентов функции потерь по параметрам сети (весам и смещениям)",
        "Понятие скорости обучения (Learning Rate)",
        "Обновление весов по формуле: w_new = w_old - learning_rate * gradient"
      ],
      "exercises": [
        {
          "exercise_title": "Шаг градиентного спуска",
          "exercise_instructions": "1. Даны: текущий вес w = 2.5, вычисленный градиент функции потерь по этому весу dw = 0.8, скорость обучения lr = 0.1. 2. Рассчитайте новое значение веса после одной итерации градиентного спуска. 3. Объясните, почему вес уменьшился."
        },
        {
          "exercise_title": "Упрощенный расчет градиента (цепное правило)",
          "exercise_instructions": "1. Дана упрощенная функция: L = (y_pred - y_true)^2, где y_pred = sigmoid(z), а z = w * x + b. 2. Примите, что x=1, w=0.5, b=0.1, y_true=1. 3. Вычислите y_pred и L. 4. Используя цепное правило, мысленно проследите путь вычисления dL/dw (как L зависит от y_pred, как y_pred зависит от z, как z зависит от w)."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Практика: Построение и обучение первой нейронной сети",
      "lesson_objective": "Используя библиотеку Keras (TensorFlow), создать, скомпилировать и обучить полносвязную нейронную сеть для решения задачи бинарной классификации.",
      "key_topics": [
        "Обзор высокоуровневых API (Keras) для быстрого прототипирования",
        "Создание последовательной модели (Sequential model)",
        "Добавление полносвязных слоев (Dense layers)",
        "Компиляция модели: выбор оптимизатора, функции потерь и метрик",
        "Обучение модели на данных с использованием метода .fit()",
        "Интерпретация процесса обучения по графику потерь и точности"
      ],
      "exercises": [
        {
          "exercise_title": "Создание модели для классификации",
          "exercise_instructions": "1. Импортируйте необходимые модули из библиотеки Keras (TensorFlow). 2. Создайте модель Sequential. 3. Добавьте скрытый Dense-слой с 16 нейронами и функцией активации 'relu', получив на вход 8 признаков. 4. Добавьте выходной Dense-слой с 1 нейроном и функцией активации 'sigmoid' для бинарной классификации. 5. Выведите summary модели."
        },
        {
          "exercise_title": "Компиляция и обучение модели",
          "exercise_instructions": "1. Скомпилируйте созданную модель, указав оптимизатор 'adam', функцию потерь 'binary_crossentropy' и метрику 'accuracy'. 2. Загрузите или сгенерируйте простой синтетический набор данных для бинарной классификации (например, с помощью make_classification из sklearn). 3. Разделите данные на обучающую и тестовую выборки. 4. Обучите модель на обучающих данных в течение 20 эпох, используя 10% данных как валидационную выборку. 5. Постройте графики потерь и точности на обучающей и валидационной выборках."
        }
      ]
    }
  ]
}