{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел знакомит с фундаментальными концепциями нейронных сетей, от биологической аналогии до базовых математических принципов. Вы изучите основные архитектуры, поймете процесс обучения и научитесь строить простейшие модели.",
  "learning_objectives": [
    "Сформулировать ключевые отличия искусственных нейронов от биологических",
    "Разработать и визуализировать архитектуру простой полносвязной сети для конкретной задачи",
    "Объяснить роль функции потерь и алгоритма обратного распространения ошибки в обучении сети",
    "Сравнить и выбрать подходящую функцию активации для заданного типа данных",
    "Построить и обучить простую нейронную сеть с использованием фреймворка для решения базовой задачи классификации"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "От нейрона к искусственной сети: базовые строительные блоки",
      "lesson_objective": "Сконструировать модель искусственного нейрона и объяснить функцию каждого его компонента на примере задачи распознавания рукописных цифр.",
      "key_topics": [
        "Биологический нейрон как источник вдохновения",
        "Математическая модель искусственного нейрона: входы, веса, смещение, сумматор",
        "Пороговые и сигмоидальные функции активации",
        "Пример: нейрон для распознавания черты цифры '5'"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Даны три входных сигнала, соответствующие веса и значение смещения. Рассчитайте взвешенную сумму и примените пороговую функцию активации, чтобы определить, будет ли нейрон 'активирован'."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура сети: объединение нейронов в слои",
      "lesson_objective": "Спроектировать схему многослойной полносвязной сети (MLP) с заданным количеством входов, скрытых слоев и выходов для задачи классификации изображений.",
      "key_topics": [
        "Понятие слоев: входной, скрытые, выходной",
        "Принцип полносвязной архитектуры (Fully Connected)",
        "Прямое распространение сигнала (Feedforward)",
        "Визуализация архитектуры сети в виде графа"
      ],
      "exercises": [
        {
          "exercise_title": "Проектирование архитектуры сети",
          "exercise_instructions": "Для задачи классификации изображений размером 28x28 пикселей на 10 классов нарисуйте схему сети MLP. Укажите количество нейронов во входном, двух скрытых (по 64 нейрона) и выходном слоях."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Как сеть учится: функция потерь и градиентный спуск",
      "lesson_objective": "Вычислить значение функции потерь (к примеру, MSE) для заданного набора предсказаний сети и правильных ответов, и объяснить, как полученная ошибка используется для обновления весов.",
      "key_topics": [
        "Функция потерь как мера ошибки сети (на примере MSE и Cross-Entropy)",
        "Минимизация функции потерь: интуиция градиентного спуска",
        "Понятие learning rate (скорости обучения)",
        "Связь между ошибкой на выходе и корректировкой весов"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет градиента для простой функции",
          "exercise_instructions": "Дана простая квадратичная функция потерь от одного веса. Рассчитайте значение градиента в указанной точке и определите направление обновления веса при заданной скорости обучения."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Обратное распространение ошибки: алгоритм обучения",
      "lesson_objective": "Проследить на упрощенном примере с двумя слоями, как ошибка с выхода сети распространяется назад для расчета поправок к весам скрытого слоя.",
      "key_topics": [
        "Цепное правило для вычисления производных в сложных функциях",
        "Алгоритм обратного распространения ошибки (Backpropagation)",
        "Расчет градиентов для весов скрытых слоев",
        "Обновление весов с использованием рассчитанных градиентов"
      ],
      "exercises": [
        {
          "exercise_title": "Шаг обратного распространения",
          "exercise_instructions": "Для мини-сети с одним скрытым и одним выходным нейроном, зная ошибку на выходе и производную функции активации, рассчитайте величину корректировки для одного из весов скрытого слоя."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Функции активации: от сигмоиды до ReLU",
      "lesson_objective": "Сравнить характеристики и выбрать наиболее подходящую функцию активации (сигмоида, tanh, ReLU) для скрытых и выходных слоев в задачах бинарной и многоклассовой классификации.",
      "key_topics": [
        "Сравнение сигмоиды, гиперболического тангенса (tanh) и ReLU",
        "Проблема затухающих градиентов у сигмоиды и tanh",
        "Преимущества ReLU для глубоких сетей",
        "Softmax-функция для выходного слоя в многоклассовой классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Анализ градиентов функций активации",
          "exercise_instructions": "Для заданных значений выходного сигнала нейрона (используя сигмоиду и ReLU) рассчитайте значение производной функции активации. Сравните результаты и сделайте вывод о скорости обучения."
        }
      ]
    }
  ]
}