{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Теоретический раздел, раскрывающий концептуальные основы нейронных сетей с практическими примерами для углубленного понимания",
  "learning_objectives": [
    "Объяснять структуру и функции искусственного нейрона",
    "Рассчитывать выходные значения однослойного персептрона",
    "Сравнивать типы функций активации и их применение",
    "Применять алгоритм обратного распространения ошибки для обучения сети",
    "Анализировать проблемы переобучения и методы регуляризации"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Архитектура искусственного нейрона",
      "lesson_objective": "Объяснять компоненты искусственного нейрона и рассчитывать выходное значение",
      "key_topics": [
        "Биологические аналоги нейронов",
        "Взвешенная сумма входов",
        "Функции активации (пороговая, линейная)",
        "Примеры вычисления выхода нейрона"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выходного значения нейрона",
          "exercise_instructions": "Рассчитайте выходное значение нейрона с тремя входами [0.5, -1.2, 0.8], весами [0.3, 0.7, -0.5], порогом 0.2 и сигмоидальной функцией активации"
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура персептрона",
      "lesson_objective": "Описывать компоненты персептрона и реализовывать алгоритм его обучения",
      "key_topics": [
        "Входные, скрытые и выходные слои",
        "Алгоритм обучения персептрона",
        "Пороговые функции активации",
        "Примеры классификации с использованием персептрона"
      ],
      "exercises": [
        {
          "exercise_title": "Классификация с персептроном",
          "exercise_instructions": "Реализуйте персептрон для разделения двух классов на плоскости с координатами [(1,1), (2,2), (3,3)] и [(1,3), (2,4), (3,5)]"
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Функции активации и их свойства",
      "lesson_objective": "Сравнивать математические свойства функций активации и применять их в вычислениях",
      "key_topics": [
        "Sigmoid и ее производная",
        "ReLU и варианты (Leaky ReLU, ELU)",
        "Tanh и сравнение с сигмоидой",
        "Влияние функций активации на обучение сети"
      ],
      "exercises": [
        {
          "exercise_title": "Построение графиков функций активации",
          "exercise_instructions": "Постройте графики Sigmoid, ReLU и Tanh в диапазоне [-5, 5] и сравните их градиенты"
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Алгоритм обратного распространения",
      "lesson_objective": "Объяснять этапы алгоритма обратного распространения и вычислять градиенты",
      "key_topics": [
        "Цепное правило дифференцирования",
        "Вычисление дельта-ошибок",
        "Обновление весов сети",
        "Примеры трассировки градиентов"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация обратного распространения",
          "exercise_instructions": "Вычислите обновленные веса сети после обратного распространения для сети с 2 входами, 3 нейронами в скрытом слое и 1 выходом"
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Регуляризация и предотвращение переобучения",
      "lesson_objective": "Применять методы регуляризации для повышения обобщающей способности сетей",
      "key_topics": [
        "Проблема переобучения",
        "Dropout и его реализация",
        "L2-регуляризация весов",
        "Early stopping и критерии остановки"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение моделей с регуляризацией",
          "exercise_instructions": "Обучите две сети на наборе данных MNIST: с L2-регуляризацией и без нее. Сравните точность на тестовой выборке"
        }
      ]
    }
  ]
}