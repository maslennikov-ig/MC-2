{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Теоретический раздел изучает фундаментальные принципы построения и функционирования искусственных нейронных сетей. Рассматриваются основные компоненты нейронов, механизмы активации, процессы обучения через градиентный спуск и принципы архитектурного проектирования сетей. Все темы сопровождаются практическими примерами и заданиями для закрепления материала.",
  "learning_objectives": [
    "Определить структуру искусственного нейрона и его математическую модель",
    "Сравнить различные функции активации и их применимость в задачах",
    "Объяснить процесс обратного распространения ошибки в многослойных сетях",
    "Спроектировать архитектуру нейронной сети для конкретной задачи классификации",
    "Реализовать простой персептрон с нуля на Python"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Биологический нейрон и математическая модель персептрона",
      "lesson_objective": "Студенты смогут описать структуру биологического нейрона и реализовать математическую модель искусственного нейрона с весами, сумматором и функцией активации",
      "key_topics": [
        "Строение биологического нейрона: дендриты, аксон, синапсы",
        "Искусственный нейрон: входы, веса, сумматор, функция активации",
        "Персептрон Розенблатта: формула выхода и архитектура",
        "Линейная разделимость и ограничения персептрона",
        "Реализация персептрона на Python с нуля"
      ],
      "exercises": [
        {
          "exercise_title": "Создание класса персептрона",
          "exercise_instructions": "Реализуйте класс Perceptron с методами __init__(self, input_size), predict(self, inputs) и train(self, training_data, epochs). Используйте пороговую функцию активации. Протестируйте на простом наборе данных для логической операции AND."
        },
        {
          "exercise_title": "Визуализация решения персептрона",
          "exercise_instructions": "Для обученного персептрона постройте график с точками данных разных классов и линией, показывающей границу принятия решений. Убедитесь, что персептрон корректно разделяет линейно разделимые данные."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации и их производные",
      "lesson_objective": "Студенты смогут выбрать подходящую функцию активации для конкретной задачи и вычислить её производную для обратного распространения ошибки",
      "key_topics": [
        "Ступенчатая функция: применение и ограничения",
        "Сигмоидальная функция: логистическая и гиперболический тангенс",
        "ReLU и её модификации: Leaky ReLU, ELU, Swish",
        "Выбор функции активации по типу задачи и слою",
        "Градиентные проблемы: исчезающие и взрывающиеся градиенты"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "Создайте функции для sigmoid, tanh, ReLU, LeakyReLU и их производных. Постройте графики самих функций и их производных на интервале [-5, 5]. Сравните их поведение и диапазон значений."
        },
        {
          "exercise_title": "Исследование исчезающего градиента",
          "exercise_instructions": "Обучите идентичные нейронные сети с разными функциями активации на задаче классификации с глубокой архитектурой (5+ слоев). Сравните скорость обучения и точность для каждой функции активации."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Алгоритм обратного распространения ошибки",
      "lesson_objective": "Студенты смогут объяснить математические основы обратного распространения и реализовать алгоритм обучения для многослойной нейронной сети",
      "key_topics": [
        "Цепочечное правило для производных сложных функций",
        "Прямое распространение: вычисление выходов слоёв",
        "Обратное распространение: вычисление градиентов по слоям",
        "Функции потерь: MSE, кросс-энтропия, их производные",
        "Алгоритм градиентного спуска для обучения весов"
      ],
      "exercises": [
        {
          "exercise_title": "Реализация многослойного персептрона",
          "exercise_instructions": "Реализуйте класс MultiLayerPerceptron с архитектурой input-hidden-output. Включите прямой проход, обратное распространение и обучение. Используйте сигмоидальную функцию активации и MSE в качестве функции потерь."
        },
        {
          "exercise_title": "Анализ градиентов по слоям",
          "exercise_instructions": "Добавьте в реализованную сеть возможность отслеживать величины градиентов на каждом слое во время обучения. Визуализируйте изменение градиентов по эпохам и объясните наблюдаемые закономерности."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Архитектуры нейронных сетей и их применение",
      "lesson_objective": "Студенты смогут спроектировать подходящую архитектуру нейронной сети для различных типов задач и обосновать выбор количества слоёв и нейронов",
      "key_topics": [
        "Полносвязные сети: принципы построения и ограничения",
        "Проблема переобучения: регуляризация и dropout",
        "Инициализация весов: Xavier, He и их влияние на обучение",
        "Выбор количества скрытых слоёв и нейронов по эмпирическим правилам",
        "Архитектуры для разных задач: классификация, регрессия, прогнозирование"
      ],
      "exercises": [
        {
          "exercise_title": "Эксперимент с архитектурой сети",
          "exercise_instructions": "Создайте сети с разным количеством скрытых слоёв (1, 2, 3) и нейронов в каждом слое (10, 50, 100). Обучите все сети на одном наборе данных для классификации и сравните точность, скорость обучения и время обучения."
        },
        {
          "exercise_title": "Исследование регуляризации",
          "exercise_instructions": "Реализуйте dropout-слой и примените L2-регуляризацию к весам. Сравните обучение сети с регуляризацией и без неё на зашумлённом наборе данных. Проанализируйте влияние на переобучение."
        }
      ]
    },
    {
      "lesson_number": 5,
      "lesson_title": "Практическое применение: распознавание рукописных цифр",
      "lesson_objective": "Студенты смогут применить полученные знания для создания нейронной сети, решающей задачу классификации изображений, и проанализировать её производительность",
      "key_topics": [
        "Предобработка изображений: нормализация и векторизация",
        "Архитектура сети для классификации изображений",
        "Метрики качества: точность, precision, recall, F1-score",
        "Анализ ошибок: матрица ошибок и визуализация неправильно классифицированных примеров",
        "Улучшение модели: изменение архитектуры, гиперпараметров и методов оптимизации"
      ],
      "exercises": [
        {
          "exercise_title": "Создание сети для распознавания цифр",
          "exercise_instructions": "Используя датасет MNIST или аналогичный, создайте и обучите нейронную сеть для классификации рукописных цифр. Реализуйте весь пайплайн от загрузки данных до финальной оценки модели."
        },
        {
          "exercise_title": "Анализ результатов и улучшение",
          "exercise_instructions": "Проанализируйте матрицу ошибок обученной модели, найдите наиболее часто путаемые цифры. Визуализируйте примеры неправильно классифицированных изображений. Предложите и реализуйте улучшения архитектуры или процесса обучения."
        }
      ]
    }
  ]
}