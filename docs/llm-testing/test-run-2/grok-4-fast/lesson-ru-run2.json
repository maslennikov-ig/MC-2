{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Этот раздел посвящен концептуальной теории основ нейронных сетей, включая фундаментальные понятия, такие как структура нейронов, слои сетей и процессы обучения, с практическими примерами для лучшего понимания.",
  "learning_objectives": [
    "Объяснить структуру и функционирование искусственного нейрона.",
    "Описать типы слоев в нейронных сетях и их роли.",
    "Проанализировать процесс прямого и обратного распространения ошибки.",
    "Применить базовые примеры для иллюстрации обучения нейронных сетей."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон как базовый элемент",
      "lesson_objective": "Студенты смогут разобрать компоненты искусственного нейрона и рассчитать его выход для простого примера.",
      "key_topics": [
        "Входные сигналы и веса связей",
        "Функция суммирования и смещение",
        "Типы функций активации: сигмоида и ReLU"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Дано: входы x1=1, x2=2, веса w1=0.5, w2=0.3, смещение b=-0.1, функция активации - сигмоида. Вычислите выход нейрона шаг за шагом."
        },
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "Сравните поведение сигмоиды и ReLU на входах от -2 до 2, нарисуйте графики и объясните различия."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура многослойных персептронов",
      "lesson_objective": "Студенты смогут описать структуру многослойного персептрона и объяснить роль скрытых слоев в обработке данных.",
      "key_topics": [
        "Входной, скрытый и выходной слои",
        "Полносвязные связи между слоями",
        "Примеры простых сетей для классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Построение схемы персептрона",
          "exercise_instructions": "Нарисуйте схему многослойного персептрона с 2 входами, одним скрытым слоем (3 нейрона) и 1 выходом, укажите связи."
        },
        {
          "exercise_title": "Анализ роли слоев",
          "exercise_instructions": "Объясните, почему скрытый слой необходим для нелинейной задачи классификации XOR, приведя пример."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Прямое распространение сигнала",
      "lesson_objective": "Студенты смогут проследить прямое распространение сигнала через сеть и вычислить выход для заданных входов.",
      "key_topics": [
        "Шаги вычисления в каждом слое",
        "Матричное представление связей",
        "Пример с числовыми данными для двухслойной сети"
      ],
      "exercises": [
        {
          "exercise_title": "Вычисление прямого прохода",
          "exercise_instructions": "Для сети с входами [1, 0], весами первого слоя [[0.1, 0.2], [0.3, 0.4]], второго [[0.5], [0.6]], b1=[0,0], b2=0, активация ReLU. Вычислите выход."
        },
        {
          "exercise_title": "Визуализация распространения",
          "exercise_instructions": "Опишите, как сигнал распространяется от входа к выходу в трехслойной сети, используя простой пример с изображением."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Обратное распространение ошибки и градиентный спуск",
      "lesson_objective": "Студенты смогут объяснить механизм обратного распространения и применить градиентный спуск для обновления весов.",
      "key_topics": [
        "Функция потерь и производные",
        "Расчет градиентов по слоям",
        "Алгоритм градиентного спуска с примером итерации"
      ],
      "exercises": [
        {
          "exercise_title": "Обновление весов",
          "exercise_instructions": "Дано: простая сеть с одним нейроном, целевой выход 1, фактический 0.7, learning rate 0.1. Вычислите новое значение веса."
        },
        {
          "exercise_title": "Анализ градиентного спуска",
          "exercise_instructions": "Опишите шаги обратного распространения для двухслойной сети и объясните, как градиентный спуск минимизирует ошибку."
        }
      ]
    }
  ]
}