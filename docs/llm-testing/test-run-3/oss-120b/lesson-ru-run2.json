{
  "section_number": 1,
  "section_title": "Основы нейронных сетей: фундаментальные принципы",
  "section_description": "В этом разделе рассматриваются базовые понятия нейронных сетей, их архитектура, функции активации и процесс обучения с иллюстративными примерами.",
  "learning_objectives": [
    "Определить основные компоненты нейронной сети",
    "Объяснить роль функций активации",
    "Сравнить типы архитектур (перцептрон, MLP, CNN)",
    "Показать процесс прямого и обратного распространения на простом примере",
    "Интерпретировать результаты обучения модели на синтетических данных"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Структура нейрона и сеть: от биологии к математике",
      "lesson_objective": "Идентифицировать элементы искусственного нейрона и описать их математическое представление",
      "key_topics": [
        "Искусственный нейрон",
        "Взвешенные входы",
        "Смещение (bias)",
        "Активационная функция",
        "Выход нейрона"
      ],
      "exercises": [
        {
          "exercise_title": "Рисование схемы нейрона",
          "exercise_instructions": "Нарисуйте схему искусственного нейрона, обозначив входы, веса, смещение, функцию активации и выход, используя заданный шаблон."
        },
        {
          "exercise_title": "Вычисление выхода нейрона",
          "exercise_instructions": "Для заданных входных значений и весов вычислите суммарный взвешенный сигнал, примените функцию активации ReLU и запишите полученный выход нейрона."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации: типы и свойства",
      "lesson_objective": "Сравнить основные функции активации, определить их диапазоны и влияние на обучение нейронных сетей",
      "key_topics": [
        "Сигмоида",
        "Гиперболический тангенс",
        "ReLU",
        "Leaky ReLU",
        "Softmax",
        "Выбор функции в зависимости от задачи"
      ],
      "exercises": [
        {
          "exercise_title": "Графическое построение функций",
          "exercise_instructions": "Постройте графики сигмоида, tanh и ReLU на интервале от -5 до 5, отметив ключевые точки и обсудив различия в их поведении."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Прямое распространение и вычисление выхода сети",
      "lesson_objective": "Выполнить пошаговый расчёт выхода многослойного перцептрона на конкретных числовых данных",
      "key_topics": [
        "Прямое распространение",
        "Взвешенные суммы",
        "Последовательные слои",
        "Векторные операции",
        "Выходные значения"
      ],
      "exercises": [
        {
          "exercise_title": "Расчёт для 2‑слойной сети",
          "exercise_instructions": "Используя заданные веса и смещения, вычислите выход сети с двумя скрытыми слоями для входного вектора [0.5, -1.2, 0.3]."
        },
        {
          "exercise_title": "Анализ влияния активации",
          "exercise_instructions": "Повторите расчёт, заменив функцию активации скрытого слоя на ReLU, и сравните полученные результаты."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Обратное распространение: основы градиентного спуска",
      "lesson_objective": "Продемонстрировать процесс обратного распространения ошибки и обновления весов в простой сети",
      "key_topics": [
        "Обратное распространение",
        "Функция потерь",
        "Градиент",
        "Обновление весов",
        "Learning rate",
        "Проблема исчезающего градиента"
      ],
      "exercises": [
        {
          "exercise_title": "Ручной шаг градиентного спуска",
          "exercise_instructions": "Для однослойного нейрона с квадратной ошибкой вычислите градиент по весу и смещению, затем обновите параметры с шагом обучения 0.1."
        }
      ]
    }
  ]
}