{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Концептуальный теоретический раздел, знакомящий с базовыми принципами устройства и функционирования искусственных нейронных сетей на основе биологических аналогий и математических моделей",
  "learning_objectives": [
    "Объяснять структуру биологического нейрона и её соответствие компонентам искусственного нейрона",
    "Рассчитывать выходные сигналы нейрона для основных функций активации",
    "Различать архитектуры нейронных сетей и обосновывать их применение для разных задач",
    "Описывать механизм обратного распространения ошибки и градиентного спуска",
    "Анализировать влияние гиперпараметров на процесс обучения нейронной сети"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "От биологического нейрона к искусственной модели",
      "lesson_objective": "Сформировать понимание структуры биологического нейрона и научиться строить простейшую математическую модель искусственного нейрона",
      "key_topics": [
        "Биологический нейрон: дендриты, аксон, синапсы и потенциал действия",
        "Искусственный нейрон как упрощенная вычислительная модель",
        "Математическая модель нейрона Мак-Каллока-Питтса",
        "Взвешенные суммы и пороговые функции",
        "Параллели между биологическими и искусственными системами"
      ],
      "exercises": [
        {
          "exercise_title": "Сопоставление биологических и искусственных компонентов",
          "exercise_instructions": "Сопоставьте каждую часть биологического нейрона (дендрит, аксон, синапс) с соответствующим элементом искусственной модели (вход, выход, вес). Запишите ответы в таблице."
        },
        {
          "exercise_title": "Расчет выхода нейрона Мак-Каллока-Питтса",
          "exercise_instructions": "Даны три входных сигнала: x1=1, x2=0, x3=1 с весами w1=0.5, w2=-0.3, w3=0.8. Порог θ=0.7. Рассчитайте взвешенную сумму и определите выход нейрона с пороговой функцией активации."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации и вычисления нейрона",
      "lesson_objective": "Научиться рассчитывать выходные значения нейрона с использованием различных функций активации и обосновывать их применение в разных сценариях",
      "key_topics": [
        "Взвешенная сумма входных сигналов и смещения",
        "Пороговая и линейная функции активации",
        "Нелинейные функции: сигмоида и гиперболический тангенс",
        "ReLU и её модификации (Leaky ReLU, PReLU)",
        "Критерии выбора функции активации для задач классификации и регрессии"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода с разными функциями активации",
          "exercise_instructions": "Для взвешенной суммы z=2.5 рассчитайте выход нейрона при использовании сигмоиды, гиперболического тангенса и ReLU. Приведите промежуточные вычисления."
        },
        {
          "exercise_title": "Графический анализ функций активации",
          "exercise_instructions": "Постройте на бумаге или с помощью инструментов графики функции сигмоиды и ReLU в диапазоне входных значений от -5 до 5. Сравните их формы и определите преимущества каждой."
        },
        {
          "exercise_title": "Выбор функции активации для задачи",
          "exercise_instructions": "Для задач бинарной классификации, мультиклассовой классификации и регрессии выберите наиболее подходящую функцию активации. Обоснуйте свой выбор в 2-3 предложениях."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Архитектуры нейронных сетей и их применение",
      "lesson_objective": "Развить навыки анализа различных архитектур нейронных сетей и обоснования их применимости для решения конкретных задач машинного обучения",
      "key_topics": [
        "Однослойный перцептрон и его ограничения",
        "Многослойный перцептрон (MLP) как универсальный аппроксиматор",
        "Принцип прямого распространения сигнала (Feedforward)",
        "Полносвязные, сверточные и рекуррентные архитектуры",
        "Введение в глубокое обучение и глубокие сети"
      ],
      "exercises": [
        {
          "exercise_title": "Проектирование MLP для классификации изображений",
          "exercise_instructions": "Спроектируйте архитектуру многослойного перцептрона для классификации 28x28 пиксельных изображений на 10 классов. Укажите количество нейронов в каждом слое и общее число параметров."
        },
        {
          "exercise_title": "Анализ ограничений однослойного перцептрона",
          "exercise_instructions": "Исследуйте, почему однослойный перцептрон не может решить задачу XOR. Постройте таблицу истинности и покажите, что линейная разделимость невозможна."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Механизмы обучения: градиентный спуск и backpropagation",
      "lesson_objective": "Понять и применять на практике основные алгоритмы обучения нейронных сетей, включая градиентный спуск и метод обратного распространения ошибки",
      "key_topics": [
        "Функции потерь: MSE, кросс-энтропия и их математические свойства",
        "Градиентный спуск: стохастический, мини-пакетный и полный варианты",
        "Алгоритм обратного распространения ошибки (backpropagation)",
        "Скорость обучения, момент и методы адаптивной оптимизации",
        "Проблемы обучения: переобучение, недообучение и ванишинг градиенты"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет градиента функции потерь",
          "exercise_instructions": "Для функции потерь MSE = (y_pred - y_true)² вычислите частную производную по y_pred. Покажите шаги дифференцирования и запишите финальное выражение градиента."
        },
        {
          "exercise_title": "Исследование влияния скорости обучения",
          "exercise_instructions": "Опишите, что произойдет с процессом обучения при слишком большой (η=1.0) и слишком маленькой (η=0.001) скорости обучения. Нарисуйте графики сходимости для обоих случаев."
        }
      ]
    }
  ]
}