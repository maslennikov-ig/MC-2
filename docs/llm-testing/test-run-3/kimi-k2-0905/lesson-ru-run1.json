{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Вводный теоретический раздел, раскрывающий биологическое вдохновение, математические модели и ключевые принципы обучения нейросетей на примерах из повседневной жизни.",
  "learning_objectives": [
    "Объяснить биологическую архитектуру нейрона и её математическую абстракцию",
    "Вычислить выход линейного и нелинейного нейрона вручную",
    "Различать типичные функции активации и выбирать подходящую под задачу",
    "Описать шаги обучения перцептрона и оценить его ограничения",
    "Сравнить структуру MLP с другими архитектурами и обосновать выбор"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "От биологического нейрона к искусственному",
      "lesson_objective": "Сформулировать биологические принципы, лежащие в основе модели искусственного нейрона, и вычислить его выход при заданных весах.",
      "key_topics": [
        "Строение биологического нейрона: dendrite, soma, axon",
        "Модель МакКаллока-Питтса: суммирование взвешенных сигналов",
        "Функция активации как аналог генерации потенциала действия",
        "Геометрическая интерпретация: гиперплоскость решений",
        "Параметры нейрона: веса, смещение, порог"
      ],
      "exercises": [
        {
          "exercise_title": "Расчёт выхода нейрона вручную",
          "exercise_instructions": "Даны входы x=[1,0,1], веса w=[0.3,-0.8,0.5], смещение b=-0.2. Вычислите сумму и примените пороговую функцию активации с порогом 0. Укажите выход (0 или 1) и запишите промежуточные шаги."
        },
        {
          "exercise_title": "Сопоставление биологических и математических терминов",
          "exercise_instructions": "Соедините стрелками пары: дендрит — взвешенное суммирование, сома — функция активации, аксон — выходное значение. Поясните каждое соответствие одним предложением."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации и нелинейность",
      "lesson_objective": "Проанализировать графики и уравнения четырёх основных функций активации и выбрать подходящую под задачу бинарной классификации.",
      "key_topics": [
        "Проблема линейной разделимости XOR",
        "Сигмоида: гладкий S-образный переход",
        "ReLU: простота и проблема «мёртвых» нейронов",
        "Гиперболический тангенс и его масштаб",
        "Сравнение производных: скорость обучения"
      ],
      "exercises": [
        {
          "exercise_title": "Построение графиков активаций",
          "exercise_instructions": "В Excel/Python постройте на одном графике sigmoid, tanh и ReLU на интервале [-3,3]. Отметьте точки, где производная становится меньше 0.1, и сделайте вывод о «затухании» градиента."
        },
        {
          "exercise_title": "Выбор функции под задачу",
          "exercise_instructions": "Задача: вероятность оттока клиента (0-1). Обоснуйте выбор между сигмоидом и ReLU для выходного слоя; напишите два предложения аргументации."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Перцептрон и правило обучения",
      "lesson_objective": "Реализовать одну эпоху обучения перцептрона вручную и показать, как изменяются веса при каждом входном примере.",
      "key_topics": [
        "Алгоритм обучения с учителем: инициализация, предсказание, коррекция",
        "Правило Хэбба и правило дельта (Widrow-Hoff)",
        "Коэффициент скорости обучения и сходимость",
        "Эпохи, ошибка и критерий остановки",
        "Линейная разделимость и ограничение XOR"
      ],
      "exercises": [
        {
          "exercise_title": "Ручной проход обучения перцептрона",
          "exercise_instructions": "Даны два 2D-объекта: A(2,1,класс 1), B(1,2,класс 0). Начальные веса w=[0,0], b=0, η=0.5. Проведите одну эпоху: для каждого объекта вычислите выход, ошибку и обновите веса. Приведите таблицу шагов."
        },
        {
          "exercise_title": "Поиск коэффициента обучения",
          "exercise_instructions": "Экспериментально подберите наибольшее значение η, при котором перцептрон всё ещё сходится на задаче AND. Запишите найденное η и число эпох до сходимости."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Многослойный перцептрон (MLP)",
      "lesson_objective": "Описать, как комбинация линейных преобразований и нелинейных активаций в скрытых слоях позволяет аппроксимировать любую непрерывную функцию.",
      "key_topics": [
        "Скрытые слои как извлечение признаков",
        "Универсальная теорема аппроксимации",
        "Прямое распространение (forward pass)",
        "Размерность весовых матриц: вход×скрытый×выход",
        "Интерпретация скрытых представлений: визуализация 2D-эмбеддингов"
      ],
      "exercises": [
        {
          "exercise_title": "Подсчёт параметров сети",
          "exercise_instructions": "Сеть: 4 входа, 3 скрытых нейрона, 2 выхода. Посчитайте общее количество обучаемых параметров, включая смещения. Укажите формулу и ответ."
        },
        {
          "exercise_title": "Визуализация решающих границ",
          "exercise_instructions": "Используя playground.tensorflow.org, обучите MLP с 2 скрытыми слоями по 3 нейрона на спиральных данных. Экспортируйте изображение решающих границ и опишите, как изменилась форма при добавлении второго слоя."
        }
      ]
    }
  ]
}