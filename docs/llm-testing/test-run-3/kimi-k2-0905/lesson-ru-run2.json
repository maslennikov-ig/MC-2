{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Введение в архитектуру, принципы обучения и применение искусственных нейронных сетей на простых практических примерах.",
  "learning_objectives": [
    "Объяснить устройство и работу искусственного нейрона",
    "Различать архитектуры feed-forward, recurrent и convolutional сетей",
    "Производить ручной forward-pass для сети из 3-5 нейронов",
    "Выбирать функцию активации под задачу классификации или регрессии",
    "Оценивать качество модели с помощью loss-функций и метрик точности"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Биологическая и математическая модель нейрона",
      "lesson_objective": "Сформировать у студента чёткое представление о структуре искусственного нейрона и умение вычислять его выход вручную.",
      "key_topics": [
        "История McCulloch-Pitts нейрона",
        "Веса, смещение, сумматор",
        "Функции активации: пороговая, сигмоида, ReLU",
        "Геометрическая интерпретация в 2D и 3D",
        "Нейрон как линейный классификатор"
      ],
      "exercises": [
        {
          "exercise_title": "Ручной forward-pass нейрона",
          "exercise_instructions": "Даны веса w=[0.5,-1.2,0.8], смещение b=0.3, вход x=[1,0,2]. Вычислите выход нейрона с сигмоидной активацией, округлите до 3 знаков."
        },
        {
          "exercise_title": "Подбор функции активации",
          "exercise_instructions": "Для задач бинарной классификации, регрессии температуры и многоклассового распознавания цифр выберите подходящую функцию активации и обоснуйте выбор."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура многослойного перцептрона",
      "lesson_objective": "Научить студента собирать полносвязную сеть заданной глубины и вычислять forward-pass по слоям.",
      "key_topics": [
        "Слои input, hidden, output",
        "Матричное представление вычислений",
        "Размерность весовых матриц",
        "Поток данных в прямом направлении",
        "Параметры vs гиперпараметры"
      ],
      "exercises": [
        {
          "exercise_title": "Подсчёт параметров сети",
          "exercise_instructions": "Сеть имеет 4 входа, 2 скрытых слоя по 5 нейронов и 3 выходных нейрона. Вычислите общее количество обучаемых параметров."
        },
        {
          "exercise_title": "Пошаговый forward-pass",
          "exercise_instructions": "Для сети 2×3×1 с заданными весами выполните forward-pass для входного вектора [−1,2] и запишите выход каждого слоя."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Функции потерь и метрики качества",
      "lesson_objective": "Научить студента подбирать функцию потерь под задачу и оценивать качество обучения на валидационной выборке.",
      "key_topics": [
        "MSE и MAE для регрессии",
        "Cross-entropy для классификации",
        "Accuracy, precision, recall, F1",
        "Overfitting и underfitting",
        "Обучающая vs валидационная ошибка"
      ],
      "exercises": [
        {
          "exercise_title": "Выбор loss-функции",
          "exercise_instructions": "Для задач прогноза цены дома, диагностики заболевания и ранжирования товаров выберите подходящую функцию потерь и объясните, почему она подходит."
        },
        {
          "exercise_title": "Расчёт метрик классификации",
          "exercise_instructions": "Для бинарной классификации известно: TP=80, FP=20, FN=30, TN=70. Вычислите accuracy, precision, recall и F1-score."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Градиентный спуск и обратное распространение",
      "lesson_objective": "Дать студенту интуитивное понимание обучения через минимизацию потерь и показать механизм обновления весов.",
      "key_topics": [
        "Локальный и глобальный минимумы",
        "Learning rate и сходимость",
        "Цепное правило дифференцирования",
        "Алгоритм backpropagation на одном нейроне",
        "Понятие эпохи и батча"
      ],
      "exercises": [
        {
          "exercise_title": "Градиентный шаг вручную",
          "exercise_instructions": "Для функции потерь MSE=(y−ŷ)² вычислите градиенты dL/dw и dL/db, затем обновите веса при rate=0.1 для одного примера."
        },
        {
          "exercise_title": "Влияние скорости обучения",
          "exercise_instructions": "Запустите 3 версии градиентного спуска с learning rate 0.001, 0.1 и 10. Опишите, как поведение алгоритма отличается в каждом случае."
        }
      ]
    }
  ]
}