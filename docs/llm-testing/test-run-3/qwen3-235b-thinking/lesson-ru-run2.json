{
  "section_number": 1,
  "section_title": "Введение в архитектуру нейронных сетей: от персептрона к глубокому обучению",
  "section_description": "Изучение базовых концепций нейронных сетей, их структуры и принципов работы на практических примерах.",
  "learning_objectives": [
    "Объяснить принцип работы искусственного нейрона с использованием математических формул",
    "Описать этапы обучения нейронной сети через метод обратного распространения ошибки",
    "Применить функцию активации в синтетическом примере вычисления выходного сигнала",
    "Различать типы нейронных сетей по архитектуре и области применения",
    "Анализировать зависимость точности модели от количества слоёв и нейронов"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Архитектура искусственного нейрона: компоненты и математическая модель",
      "lesson_objective": "Построить математическую модель искусственного нейрона и рассчитать выходной сигнал для заданных входных данных",
      "key_topics": [
        "Биологические аналогии в устройстве нейрона",
        "Весовые коэффициенты и смещение (bias)",
        "Линейная комбинация входов",
        "Функции активации: sigmoid, ReLU, tanh",
        "Пример вычисления для пороговой функции"
      ],
      "exercises": [
        {
          "exercise_title": "Схема нейрона",
          "exercise_instructions": "Нарисуйте схему искусственного нейрона с 3 входами, обозначьте веса, смещение и функцию активации"
        },
        {
          "exercise_title": "Расчёт выходного сигнала",
          "exercise_instructions": "Вычислите выходной сигнал нейрона с входами [0.5, -1.2, 0.8], весами [0.6, -0.3, 1.1] и смещением 0.5, используя ReLU"
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Процесс обучения: функция потерь и обратное распространение",
      "lesson_objective": "Продемонстрировать работу алгоритма обратного распространения на примере однослойной сети с квадратичной функцией потерь",
      "key_topics": [
        "Определение функции потерь (MSE, cross-entropy)",
        "Градиентный спуск и скорость обучения",
        "Цепное правило дифференцирования",
        "Обратное распространение ошибки по слоям",
        "Пример обновления весов для двухнейронной сети"
      ],
      "exercises": [
        {
          "exercise_title": "Вычисление градиента",
          "exercise_instructions": "Найдите частную производную функции потерь MSE по весу w1 для сети с 1 нейроном и линейной активацией"
        },
        {
          "exercise_title": "Шаг обучения",
          "exercise_instructions": "Рассчитайте новые значения весов после одного шага градиентного спуска с lr=0.01 для заданных градиентов"
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Архитектуры нейронных сетей: сравнение и выбор модели",
      "lesson_objective": "Сопоставить типы нейронных сетей с решаемыми задачами и определить оптимальную архитектуру для конкретного кейса",
      "key_topics": [
        "Однослойные персептроны и их ограничения",
        "Многослойные персептроны (MLP)",
        "Свёрточные сети (CNN) для обработки изображений",
        "Рекуррентные сети (RNN) для последовательных данных",
        "Трансформеры и механизмы внимания",
        "Примеры задач: классификация, генерация, прогнозирование"
      ],
      "exercises": [
        {
          "exercise_title": "Классификация задач",
          "exercise_instructions": "Определите подходящую архитектуру сети для распознавания рукописных цифр и предсказания временных рядов"
        },
        {
          "exercise_title": "Анализ архитектуры",
          "exercise_instructions": "Сравните CNN и RNN по количеству параметров и скорости обучения на примере задачи анализа текста"
        }
      ]
    }
  ]
}