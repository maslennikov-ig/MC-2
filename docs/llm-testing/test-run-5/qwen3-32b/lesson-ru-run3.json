{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Эта секция знакомит с базовыми концепциями нейронных сетей, их архитектурой и процессами обучения. Студенты изучат, как работают искусственные нейроны, функции активации и алгоритмы оптимизации, а также научатся применять простые модели для решения задач.",
  "learning_objectives": [
    "Объяснить структуру и работу искусственного нейрона",
    "Реализовать простую нейронную сеть с использованием Python",
    "Выбрать подходящую функцию активации для конкретной задачи",
    "Обучить и оценить производительность нейронной сети на данных",
    "Применить градиентный спуск и обратное распространение ошибки для оптимизации модели"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Структура нейронной сети",
      "lesson_objective": "Научиться определять компоненты нейронной сети и их взаимодействие",
      "key_topics": ["Нейрон как базовый элемент", "Синаптические веса и порог активации", "Слои нейронов", "Полносвязные сети", "Математическое представление"],
      "exercises": [
        {
          "exercise_title": "Создание одиночного нейрона",
          "exercise_instructions": "Реализуйте нейрон на Python, используя массив весов, пороговое значение и входные данные. Вычислите выходной сигнал через сигмоидную функцию активации."
        },
        {
          "exercise_title": "Построение архитектуры сети",
          "exercise_instructions": "Нарисуйте схему сети с 1 входным слоем (3 нейрона), 1 скрытым слоем (2 нейрона) и 1 выходным слоем (1 нейрон). Определите матрицу весов между слоями."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации",
      "lesson_objective": "Изучить типы функций активации и их влияние на обучение сети",
      "key_topics": ["Сигмоида и её ограничения", "ReLU и его варианты", "Гиперболический тангенс", "Линейные и нелинейные функции", "Выбор функций в зависимости от задачи"],
      "exercises": [
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "Постройте графики для сигмоиды, ReLU и гиперболического тангенса. Оцените их поведение на различных входных значениях."
        },
        {
          "exercise_title": "Эксперимент с выбором функции",
          "exercise_instructions": "Создайте простую модель классификации и замените функцию активации в скрытом слое на ReLU. Сравните результаты с использованием сигмоиды."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение модели",
      "lesson_objective": "Научиться применять градиентный спуск и обратное распространение для обучения сети",
      "key_topics": ["Градиентный спуск и его типы", "Функция потерь (MSE, cross-entropy)", "Обратное распространение ошибки", "Обновление весов", "Скорость обучения и эпохи"],
      "exercises": [
        {
          "exercise_title": "Ручное вычисление градиентов",
          "exercise_instructions": "Для простой сети с 2 нейронами в скрытом слое вычислите градиенты по весам после одного шага обратного распространения на примере с 1 обучающим примером."
        },
        {
          "exercise_title": "Обучение на регрессии",
          "exercise_instructions": "Реализуйте модель для предсказания цен на жилье. Используйте градиентный спуск с шагом 10 эпох и оцените уменьшение функции потерь (MSE)."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Первый проект: классификация рукописных цифр",
      "lesson_objective": "Создать и обучить полносвязную сеть для задачи MNIST",
      "key_topics": ["Набор данных MNIST", "Предобработка данных", "Создание модели в Keras", "Компиляция и обучение", "Оценка точности"],
      "exercises": [
        {
          "exercise_title": "Загрузка и визуализация данных",
          "exercise_instructions": "Используя библиотеку TensorFlow, загрузите данные MNIST и отобразите 5 случайных изображений с их метками."
        },
        {
          "exercise_title": "Обучение модели",
          "exercise_instructions": "Постройте модель с двумя скрытыми слоями. Компилируйте с функцией потерь cross-entropy и оптимизатором Adam. Обучите на 3 эпохи и сохраните метрики."
        }
      ]
    }
  ]
}