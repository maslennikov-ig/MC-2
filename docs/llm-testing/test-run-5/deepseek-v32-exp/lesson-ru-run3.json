{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "В этой секции вы познакомитесь с фундаментальными концепциями искусственных нейронных сетей. Вы узнаете, из каких базовых элементов они состоят и как эти элементы взаимодействуют для решения задач. Мы рассмотрим процесс обучения сети на примерах данных.",
  "learning_objectives": [
    "Объяснить структуру и функции искусственного нейрона, включая входы, веса, функцию активации и выход.",
    "Построить архитектуру простой полносвязной нейронной сети, определив входной, скрытый и выходной слои.",
    "Реализовать алгоритм прямого распространения (forward propagation) для получения предсказания по входным данным.",
    "Вычислить ошибку предсказания с помощью функции потерь и описать интуицию, стоящую за алгоритмом обратного распространения ошибки (backpropagation)."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон: строительный блок ИИ",
      "lesson_objective": "Построить математическую модель искусственного нейрона и вычислить его выход для заданных входов и весов.",
      "key_topics": [
        "Биологический прототип: нейрон мозга.",
        "Математическая модель искусственного нейрона: входы, веса, суммирующая функция.",
        "Порог и смещение (bias).",
        "Функции активации: сигмоида, гиперболический тангенс (tanh), ReLU.",
        "Роль функции активации в добавлении нелинейности."
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "Даны три входа: x1=0.5, x2=-1.2, x3=0.8. Соответствующие веса: w1=0.7, w2=-0.3, w3=0.9. Смещение (bias) b=0.5. Рассчитайте взвешенную сумму. Примените функцию активации ReLU (f(z) = max(0, z)) к полученной сумме, чтобы определить окончательный выход нейрона. Запишите все шаги вычислений."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура нейронных сетей: от нейрона к сети",
      "lesson_objective": "Спроектировать схему полносвязной нейронной сети с указанием количества нейронов в каждом слое.",
      "key_topics": [
        "Слои нейронной сети: входной, скрытые, выходной.",
        "Полносвязные (Dense) слои.",
        "Выбор количества слоев и нейронов в них.",
        "Интерпретация выходного слоя (регрессия vs. классификация).",
        "Примеры архитектур для простых задач."
      ],
      "exercises": [
        {
          "exercise_title": "Проектирование сети для классификации изображений",
          "exercise_instructions": "Спроектируйте архитектуру нейронной сети для классификации изображений рукописных цифр (28x28 пикселей) на 10 классов (цифры 0-9). Изобразите схему сети. Укажите: 1) Количество нейронов во входном слое. 2) Количество скрытых слоев и нейронов в каждом (предложите один скрытый слой со 128 нейронами). 3) Количество нейронов в выходном слое и предложите подходящую функцию активации для него."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Прямое распространение: как сеть \"думает\"",
      "lesson_objective": "Выполнить пошаговый расчет прямого распространения сигнала через нейронную сеть с двумя слоями.",
      "key_topics": [
        "Алгоритм прямого распространения (Forward Propagation).",
        "Матричное представление вычислений для эффективности.",
        "Последовательное вычисление выходов каждого слоя.",
        "Применение функций активации на каждом слое.",
        "Получение итогового предсказания сети."
      ],
      "exercises": [
        {
          "exercise_title": "Прямое распространение на практике",
          "exercise_instructions": "Рассмотрим сеть с архитектурой 2-3-1. Входной вектор: [1.0, -0.5]. Веса от входного слоя к скрытому: W1 = [[0.5, -0.2], [0.1, 0.8], [-0.3, 0.4]], смещение b1 = [0.1, -0.1, 0.2]. Веса от скрытого слоя к выходному: W2 = [0.7, -1.2, 0.5], смещение b2 = [0.3]. На скрытом слое используется функция активации tanh, на выходном - сигмоида. Выполните прямой проход и найдите итоговый выход сети. Выполните расчеты для каждого слоя по порядку."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Обучение сети: Функция потерь и обратное распространение",
      "lesson_objective": "Вычислить ошибку предсказания сети, используя функцию потерь, и описать цель алгоритма обратного распространения.",
      "key_topics": [
        "Необходимость обучения: настройка весов.",
        "Функции потерь (Loss Functions): среднеквадратичная ошибка (MSE) для регрессии, перекрестная энтропия (Cross-Entropy) для классификации.",
        "Минимизация функции потерь.",
        "Интуиция градиентного спуска.",
        "Концепция обратного распространения ошибки (Backpropagation) как способ эффективного вычисления градиентов."
      ],
      "exercises": [
        {
          "exercise_title": "Вычисление ошибки предсказания",
          "exercise_instructions": "Нейронная сеть выдала предсказание y_pred = 0.85 для задачи бинарной классификации. Истинная метка y_true = 1. Вычислите значение функции потерь бинарной перекрестной энтропии (Binary Cross-Entropy): L = -[y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred)]. Объясните, что означает полученное значение с точки зрения точности предсказания."
        },
        {
          "exercise_title": "Концептуальное понимание Backpropagation",
          "exercise_instructions": "После вычисления ошибки с помощью функции потерь, алгоритм обратного распространения вычисляет градиенты. Ответьте на вопросы: 1) Что показывает градиент функции потерь по отношению к конкретному весу в сети? 2) Как эта информация используется для обновления весов? 3) Почему этот алгоритм более эффективен, чем наивный подбор всех весов? Сформулируйте ответ своими словами."
        }
      ]
    }
  ]
}