{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Эта секция знакомит с фундаментальными принципами работы искусственных нейронных сетей. Вы изучите базовую архитектуру и основные компоненты, а также освоите процесс обучения сети на простом примере.",
  "learning_objectives": [
    "Объяснить структуру и функции искусственного нейрона.",
    "Реализовать прямой проход (forward pass) для однослойной нейронной сети.",
    "Вычислить функцию потерь для оценки качества предсказаний модели.",
    "Применить алгоритм обратного распространения ошибки (backpropagation) для обновления весов на простом примере."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон и активационные функции",
      "lesson_objective": "Построить функцию для вычисления выхода искусственного нейрона с различными активационными функциями.",
      "key_topics": [
        "Биологический прототип и искусственная модель",
        "Входы, веса, смещение (bias) и сумматор",
        "Пороговая функция активации",
        "Сигмоида и гиперболический тангенс (Tanh)",
        "Линейный выпрямитель (ReLU)",
        "Выбор активационной функции"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "1. Напишите функцию на Python, которая принимает список входных значений, список весов и значение смещения. 2. Вычислите взвешенную сумму. 3. Добавьте к сумме смещение. 4. Примените сигмоидальную функцию активации к результату. 5. Верните итоговое значение."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура и прямой проход в полносвязной сети",
      "lesson_objective": "Реализовать прямой проход (forward pass) для простой полносвязной нейронной сети с одним скрытым слоем.",
      "key_topics": [
        "Слои нейронной сети: входной, скрытый, выходной",
        "Полносвязные слои (Dense Layers)",
        "Преобразование входных данных в скрытое представление",
        "Преобразование скрытого представления в выходное",
        "Векторизация вычислений для эффективности"
      ],
      "exercises": [
        {
          "exercise_title": "Прямой проход для сети 2-3-1",
          "exercise_instructions": "1. Создайте матрицы весов для связей между входным и скрытым слоем (2 входа, 3 нейрона) и между скрытым и выходным слоем (3 входа, 1 нейрон). Инициализируйте их случайными значениями. 2. Напишите функцию, которая принимает входной вектор из двух элементов. 3. Вычислите выход скрытого слоя, применив функцию активации ReLU. 4. Вычислите итоговый выход сети, применив сигмоиду к результату скрытого слоя. 5. Верните выходное значение."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Функции потерь и основы градиентного спуска",
      "lesson_objective": "Реализовать вычисление функции среднеквадратичной ошибки (MSE) и понять принцип градиентного спуска.",
      "key_topics": [
        "Назначение функции потерь (Loss Function)",
        "Среднеквадратичная ошибка (Mean Squared Error)",
        "Функция кросс-энтропии (Cross-Entropy)",
        "Интуиция градиентного спуска: поиск минимума",
        "Понятие скорости обучения (Learning Rate)",
        "Градиент как направление наискорейшего роста"
      ],
      "exercises": [
        {
          "exercise_title": "Вычисление MSE и градиента",
          "exercise_instructions": "1. Даны два списка: список предсказаний модели и список истинных значений. 2. Напишите функцию, которая вычисляет и возвращает среднеквадратичную ошибку между ними. 3. Рассчитайте градиент функции потерь по предсказанию вручную для одной пары (предсказание, истинное значение), используя производную. 4. Напишите код, который обновляет вес, используя этот градиент и заданную скорость обучения."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Алгоритм обратного распространения ошибки (Backpropagation)",
      "lesson_objective": "Применить один шаг алгоритма обратного распространения ошибки для обновления весов в простой сети.",
      "key_topics": [
        "Цепное правило для вычисления производных",
        "Ошибка выходного слоя",
        "Распространение ошибки назад по слоям",
        "Вычисление градиентов для весов каждого слоя",
        "Обновление весов с использованием градиентного спуска",
        "Интуиция: как сеть учится на своих ошибках"
      ],
      "exercises": [
        {
          "exercise_title": "Один шаг Backpropagation для сети 1-1",
          "exercise_instructions": "1. Возьмите простую сеть с одним входом, одним выходом и одним весом. 2. Задайте входное значение, истинное значение и начальный вес. 3. Выполните прямой проход и вычислите ошибку (MSE). 4. Используя цепное правило, вычислите градиент ошибки по весу. 5. Обновите вес, используя градиент и скорость обучения. 6. Выполните еще один прямой проход с новым весом и убедитесь, что ошибка уменьшилась."
        }
      ]
    }
  ]
}