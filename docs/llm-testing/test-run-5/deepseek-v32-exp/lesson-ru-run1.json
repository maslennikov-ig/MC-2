{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "В этой секции вы познакомитесь с фундаментальными принципами работы искусственных нейронных сетей. Вы узнаете о структуре нейрона, построении архитектур и процессе обучения сети для решения задач.",
  "learning_objectives": [
    "Объяснить структуру искусственного нейрона и функцию активации.",
    "Построить архитектуру простой полносвязной нейронной сети.",
    "Реализовать алгоритм обратного распространения ошибки для обучения модели.",
    "Обучить простую нейронную сеть для решения задачи классификации."
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Искусственный нейрон и функции активации",
      "lesson_objective": "По окончании урока вы сможете описать математическую модель искусственного нейрона и выбрать подходящую функцию активации для задачи бинарной классификации.",
      "key_topics": [
        "Биологический прототип и искусственная модель нейрона",
        "Входные сигналы, веса и смещение (bias)",
        "Сумматор и вычисление взвешенной суммы",
        "Понятие функции активации",
        "Обзор функций активации: сигмоида, гиперболический тангенс, ReLU",
        "Пороговые и непрерывные функции",
        "Применение сигмоиды для задач бинарной классификации"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет выхода нейрона",
          "exercise_instructions": "1. Даны три входа: x1=0.5, x2=-1.2, x3=0.8. 2. Задайте случайные веса: w1=0.7, w2=-0.3, w3=0.2 и смещение b=0.1. 3. Рассчитайте взвешенную сумму z. 4. Примените сигмоидальную функцию активации σ(z) = 1/(1+e^{-z}) к полученной сумме. 5. Запишите итоговый выход нейрона."
        },
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "1. Для входного значения z=0.5 рассчитайте выходное значение, используя сигмоиду. 2. Для того же значения z=0.5 рассчитайте выходное значение, используя гиперболический тангенс. 3. Для z=-1.0 рассчитайте выход, используя функцию ReLU. 4. Сравните полученные результаты и сделайте вывод о поведении каждой функции."
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Архитектура нейронных сетей",
      "lesson_objective": "По окончании урока вы сможете спроектировать и графически изобразить архитектуру полносвязной нейронной сети с заданным количеством слоев и нейронов.",
      "key_topics": [
        "Понятие слоя: входной, скрытый, выходной",
        "Полносвязные (Fully Connected) слои",
        "Прямое распространение (Forward Pass)",
        "Выбор количества скрытых слоев и нейронов в них",
        "Влияние глубины и ширины сети на ее возможности",
        "Интерпретация выходного слоя для задач классификации и регрессии",
        "Пример архитектуры для распознавания рукописных цифр (MNIST)"
      ],
      "exercises": [
        {
          "exercise_title": "Проектирование архитектуры сети",
          "exercise_instructions": "1. Представьте задачу классификации изображений 28x28 пикселей на 10 классов. 2. Спроектируйте архитектуру нейронной сети для этой задачи. Укажите: количество нейронов во входном слое, количество и размеры скрытых слоев (минимум один), количество нейронов в выходном слое. 3. Обоснуйте свой выбор количества выходных нейронов. 4. Нарисуйте схематичное изображение полученной архитектуры."
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение нейронной сети: обратное распространение ошибки",
      "lesson_objective": "По окончании урока вы сможете выполнить одну итерацию алгоритма обратного распространения ошибки для простой сети, рассчитав градиенты для обновления весов.",
      "key_topics": [
        "Функция потерь (Loss Function) как мера ошибки",
        "Минимизация функции потерь",
        "Интуиция градиентного спуска",
        "Цепное правило для вычисления производных",
        "Алгоритм обратного распространения ошибки (Backpropagation)",
        "Расчет градиентов для каждого веса сети",
        "Обновление весов с использованием скорости обучения (Learning Rate)"
      ],
      "exercises": [
        {
          "exercise_title": "Шаг прямого и обратного распространения",
          "exercise_instructions": "1. Рассмотрите сеть с одним нейроном (x -> w -> y_pred). Даны: вход x=2, истинная метка y_true=1, начальный вес w=0.5, скорость обучения η=0.1. 2. Выполните прямой проход и рассчитайте y_pred и значение функции потерь L = (y_pred - y_true)^2. 3. Вручную рассчитайте градиент dL/dw, используя цепное правило. 4. Обновите вес w, сделав шаг градиентного спуска: w_new = w_old - η * (dL/dw)."
        },
        {
          "exercise_title": "Анализ влияния скорости обучения",
          "exercise_instructions": "1. Используя модель из предыдущего упражнения, выполните два шага обновления веса с очень маленькой скоростью обучения (η=0.01). Запишите новые значения веса и потерь. 2. Сбросьте вес до начального значения (w=0.5). Выполните два шага обновления с очень большой скоростью обучения (η=1.0). Запишите новые значения. 3. Сравните результаты и опишите, как скорость обучения влияет на процесс сходимости."
        }
      ]
    },
    {
      "lesson_number": 4,
      "lesson_title": "Практика: Создание и обучение своей первой нейронной сети",
      "lesson_objective": "По окончании урока вы сможете, используя библиотеку Python (Keras/TensorFlow или PyTorch), создать, скомпилировать и обучить простую нейронную сеть на датасете MNIST для распознавания рукописных цифр.",
      "key_topics": [
        "Обзор фреймворков для глубокого обучения (Keras, PyTorch)",
        "Загрузка и предварительная обработка датасета MNIST",
        "Создание модели Sequential",
        "Добавление слоев Dense, Dropout",
        "Компиляция модели: выбор оптимизатора, функции потерь и метрик",
        "Запуск процесса обучения с использованием model.fit()",
        "Валидация и оценка точности модели на тестовых данных",
        "Визуализация процесса обучения (loss/accuracy curves)"
      ],
      "exercises": [
        {
          "exercise_title": "Построение и обучение модели на MNIST",
          "exercise_instructions": "1. Используя выбранный фреймворк, загрузите датасет MNIST и выполните нормализацию данных. 2. Создайте последовательную модель с одним скрытым слоем из 128 нейронов с активацией ReLU и выходным слоем из 10 нейронов с активацией softmax. 3. Скомпилируйте модель, используя оптимизатор 'adam', функцию потерь 'sparse_categorical_crossentropy' и метрику 'accuracy'. 4. Обучите модель на тренировочных данных в течение 5 эпох, используя 20% данных для валидации. 5. Оцените точность модели на тестовом наборе данных."
        }
      ]
    }
  ]
}