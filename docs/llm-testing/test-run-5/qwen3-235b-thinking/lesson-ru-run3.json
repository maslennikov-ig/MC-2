{
  "section_number": 1,
  "section_title": "Основы нейронных сетей",
  "section_description": "Эта секция познакомит вас с архитектурой и принципами работы искусственных нейронных сетей. Вы изучите ключевые компоненты, математические основы и этапы обучения моделей. По завершении вы сможете создавать и интерпретировать простые нейросетевые архитектуры.",
  "learning_objectives": [
    "Объяснить структуру искусственного нейрона и взаимодействие слоев в нейросети",
    "Применять математические операции для вычисления взвешенных сумм и активаций",
    "Реализовывать простую нейронную сеть с помощью библиотеки TensorFlow/Keras",
    "Интерпретировать результаты обучения через функции потерь и метрики качества"
  ],
  "lessons": [
    {
      "lesson_number": 1,
      "lesson_title": "Архитектура искусственных нейронных сетей",
      "lesson_objective": "Построить схему нейронной сети и рассчитать выходные значения для заданных входов",
      "key_topics": [
        "Биологические аналогии и искусственные нейроны",
        "Входные, скрытые и выходные слои",
        "Взвешенные суммы и смещения",
        "Прямое распространение сигнала",
        "Матричные операции в нейросетях"
      ],
      "exercises": [
        {
          "exercise_title": "Схема нейронной сети",
          "exercise_instructions": "Нарисуйте архитектуру сети с 3 входами, 4 нейронами в скрытом слое и 2 выходами. Подпишите все веса и смещения обозначениями w_ij и b_j"
        },
        {
          "exercise_title": "Расчет выходного значения",
          "exercise_instructions": "Для нейрона с входами [0.5, -1.2, 0.8], весами [0.6, -0.3, 1.5] и смещением -0.2 рассчитайте взвешенную сумму и примените линейную активацию"
        }
      ]
    },
    {
      "lesson_number": 2,
      "lesson_title": "Функции активации и их свойства",
      "lesson_objective": "Выбрать подходящую функцию активации для задачи и реализовать её математическую модель",
      "key_topics": [
        "Нелинейность в нейросетях",
        "Sigmoid и гиперболический тангенс",
        "ReLU и его модификации",
        "Softmax для классификации",
        "Проблема затухающих градиентов"
      ],
      "exercises": [
        {
          "exercise_title": "Сравнение функций активации",
          "exercise_instructions": "Постройте графики Sigmoid, Tanh и ReLU на одном графике в диапазоне [-5, 5] с использованием Python (matplotlib). Укажите области насыщения для каждой функции"
        },
        {
          "exercise_title": "Реализация Softmax",
          "exercise_instructions": "Напишите функцию на Python, которая принимает вектор оценок [2.1, -1.0, 0.5] и возвращает вероятности классов через Softmax. Проверьте сумму результатов"
        }
      ]
    },
    {
      "lesson_number": 3,
      "lesson_title": "Обучение нейронных сетей: обратное распространение",
      "lesson_objective": "Выполнить ручной расчет градиентов для однослойной сети и интерпретировать процесс оптимизации",
      "key_topics": [
        "Функции потерь (MSE, кросс-энтропия)",
        "Цепное правило дифференцирования",
        "Алгоритм обратного распространения ошибки",
        "Скорость обучения и регуляризация",
        "Эпохи и пакетная обработка"
      ],
      "exercises": [
        {
          "exercise_title": "Расчет градиента",
          "exercise_instructions": "Для нейрона с функцией активации ReLU и MSE loss, входом x=2, весом w=0.5, смещением b=0.1 и целевым значением y=1.5 рассчитайте градиенты dL/dw и dL/db"
        },
        {
          "exercise_title": "Симуляция обучения",
          "exercise_instructions": "Используя данные из предыдущего упражнения, выполните один шаг градиентного спуска с lr=0.01. Обновите вес и смещение, сравните новое значение потерь с исходным"
        }
      ]
    }
  ]
}