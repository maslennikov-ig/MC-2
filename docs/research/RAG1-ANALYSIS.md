# –ê–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: Optimal Chunking Strategies for RAG Systems

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: 2025-01-14
**–ò—Å—Ö–æ–¥–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ**: `/docs/research/RAG1.md`
**–ê–Ω–∞–ª–∏—Ç–∏–∫**: Claude Code

---

## üìä –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

### üöÄ Breakthrough Techniques (2024-2025)

**1. Late Chunking (Jina AI, —Å–µ–Ω—Ç—è–±—Ä—å 2024)**
- **–£–ª—É—á—à–µ–Ω–∏–µ**: 35-49% reduction in retrieval failures
- **–°—Ç–æ–∏–º–æ—Å—Ç—å**: $0 (–≤–∫–ª—é—á–µ–Ω–æ –≤ Jina-v3)
- **–†–µ–∞–ª–∏–∑–∞—Ü–∏—è**: –û–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `late_chunking: true`
- **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç**: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ 8,192 —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ transformer encoder, –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç mean pooling –∫ –≥—Ä–∞–Ω–∏—Ü–∞–º —á–∞–Ω–∫–æ–≤
- **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å**: –≠—Ñ—Ñ–µ–∫—Ç –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –¥–ª–∏–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —É—á–µ–±–Ω–∏–∫–æ–≤ –∏ –ª–µ–∫—Ü–∏–π)

**2. Hierarchical Chunking**
- **–£–ª—É—á—à–µ–Ω–∏–µ**: 20-30% retrieval accuracy improvement
- **–°—Ç–æ–∏–º–æ—Å—Ç—å**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è (storage overhead ~30%)
- **–ü–∞—Ç—Ç–µ—Ä–Ω**: –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (400 tokens), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à–∏–µ (1,500 tokens)
- **–†–µ—à–∞–µ—Ç –¥–∏–ª–µ–º–º—É**: Precision (–º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏) vs Context (–±–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏)

**3. Contextual Enrichment (Anthropic)**
- **–£–ª—É—á—à–µ–Ω–∏–µ**: 67% improvement —Å hybrid search + reranking
- **–°—Ç–æ–∏–º–æ—Å—Ç—å**: $1.02 per 1M document tokens (–¥–æ—Ä–æ–≥–æ!)
- **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: Accuracy requirements > 95% –∏–ª–∏ –º–Ω–æ–≥–æ cross-references

---

## üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞

### Token Economics –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
- **Russian token premium**: 1.4-1.8x –±–æ–ª—å—à–µ —á–µ–º English
- **–ü—Ä–∏—á–∏–Ω–∞**: Jina-v3 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 2.5 chars/token –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ (vs 4-5 –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)
- **–†–∞–Ω—å—à–µ –±—ã–ª–æ**: 2x premium (—É–ª—É—á—à–µ–Ω–∏–µ!)

### –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | Tokens | Characters (Russian) | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|----------|--------|---------------------|-----------|
| Child chunk | 400-500 | ~1,000-1,250 | Precision retrieval |
| Parent chunk | 1,500-2,000 | ~3,750-5,000 | Context for LLM |
| Overlap | 50-80 | ~125-200 | Boundary continuity |
| Max context | 7,500 | ~18,750 | Leave 700 for query |

### Boundaries
- **Preferred**: Sentence boundaries (Razdel: 98.73% precision)
- **Structure**: H2/H3 headings –¥–ª—è major splits
- **Never split**: Code blocks, formulas, tables (atomic units)

---

## üîç –ü—Ä–æ–±–ª–µ–º—ã —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (n8n baseline)

### –ß—Ç–æ –Ω–µ —Ç–∞–∫ —Å–µ–π—á–∞—Å:

```javascript
// n8n: RecursiveCharacterTextSplitter
{
  chunkSize: 2000,        // ‚ùå Characters, not tokens!
  chunkOverlap: 300,      // ‚ùå 15% overlap (low)
  separators: ['\n\n', '\n', ' ', '']
}

// Metadata (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è)
{
  chunk_position: 1,
  total_chunks: 15,
  source_file: "lecture-01.pdf",  // ‚ùå No page number!
  language: "ru"
}
```

**–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
1. ‚ùå **Character-based chunking** ‚Üí –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (—Ä—É—Å—Å–∫–∏–π 2.5 chars/token)
2. ‚ùå **No semantic boundaries** ‚Üí —Ä–µ–∂–µ—Ç mid-sentence
3. ‚ùå **No document structure** ‚Üí —Ç–µ—Ä—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç heading hierarchy
4. ‚ùå **No source linking** ‚Üí –Ω–µ–ª—å–∑—è —Å–¥–µ–ª–∞—Ç—å clickable link –Ω–∞ PDF page
5. ‚ùå **Low overlap** (15%) ‚Üí —Ç–µ—Ä—è–µ—Ç context –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö

---

## üìà Expected Improvements

### Baseline vs Optimized

| Metric | Current (n8n) | Optimized (Late + Hierarchical) | Delta |
|--------|---------------|--------------------------------|-------|
| Retrieval failure rate | 5-6% | <2% | **-60-67%** |
| Precision@5 | ~70% | ~85-90% | **+15-20pp** |
| Context sufficiency | ~75% | ~92% | **+17pp** |
| Citation accuracy | ~40% | ~95% | **+55pp** |
| Cost per 1M tokens | $0.02 | $0.02-0.025 | **+0-25%** |

**ROI**: Massive improvements –∑–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å!

---

## üß© Metadata Schema Requirements

### Comprehensive Metadata (–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è)

```json
{
  "chunk_id": "doc_lec01_sec02_para03_chunk01",  // Stable ID
  "document_id": "lecture-01",
  "document_version": "2.1.0",
  "version_hash": "sha256:abc123...",

  "hierarchy": {
    "chapter": "Chapter 1: Fundamentals",
    "section": "1.2 Supervised Learning",
    "subsection": "1.2.3 Neural Networks",
    "heading_path": ["Ch1", "Supervised", "Neural Nets"],
    "parent_chunk_id": "doc_lec01_sec02",  // Parent-child link
    "sibling_chunk_ids": ["..._chunk00", "..._chunk02"]
  },

  "source_location": {
    "file_type": "pdf",
    "page_number": 23,
    "page_range": [23, 24],
    "line_numbers": [12, 18]
  },

  "linking": {
    "clickable_url": "https://viewer.example.com/lecture-01.pdf#page=23",
    "anchor_id": "section-1-2-3"
  },

  "content_metadata": {
    "text": "Neural networks consist of...",
    "token_count": 418,
    "parent_text": "Full section context...",  // For LLM generation
    "has_code": false,
    "has_formulas": true
  },

  "filtering": {
    "organization_id": "org_msu",
    "course_id": "ML101",
    "document_type": "lecture_notes",
    "topic_tags": ["neural_networks", "backpropagation"]
  },

  "chunking_metadata": {
    "chunk_strategy": "hierarchical_late",
    "chunk_size_tokens": 418,
    "overlap_tokens": 52,
    "is_parent": false,
    "child_count": 0
  },

  "embedding_metadata": {
    "model": "jina-embeddings-v3",
    "late_chunking": true,
    "embedding_timestamp": "2025-10-14T10:31:15Z"
  }
}
```

---

## üõ†Ô∏è Implementation Options: 4 –í–∞—Ä–∏–∞–Ω—Ç–∞

–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –ø—Ä–µ–¥–ª–∞–≥–∞—é **4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏** —Å —Ä–∞–∑–Ω—ã–º–∏ trade-offs –º–µ–∂–¥—É complexity, cost, –∏ improvement:

---

## –í–∞—Ä–∏–∞–Ω—Ç 1: "Quick Win" (Late Chunking Only)

### üìù –û–ø–∏—Å–∞–Ω–∏–µ
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ + –≤–∫–ª—é—á–µ–Ω–∏–µ late chunking –≤ Jina API.

### ‚úÖ –ü–ª—é—Å—ã
- **Fastest implementation**: 2-4 —á–∞—Å–∞ —Ä–∞–±–æ—Ç—ã
- **Zero additional cost**: $0.02/1M tokens (–∫–∞–∫ —Å–µ–π—á–∞—Å)
- **Immediate 35% improvement**: Proven in BeIR benchmarks
- **No breaking changes**: –°–æ–≤–º–µ—Å—Ç–∏–º–æ —Å —Ç–µ–∫—É—â–µ–π n8n —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π
- **Low risk**: –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ - API –ø–∞—Ä–∞–º–µ—Ç—Ä

### ‚ùå –ú–∏–Ω—É—Å—ã
- **No hierarchical context**: –í—Å–µ –µ—â–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º flat chunks
- **No source linking**: –ù–µ–ª—å–∑—è —Å–æ–∑–¥–∞—Ç—å clickable PDF links
- **Character-based**: –ù–µ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É token-aware chunking
- **Limited metadata**: –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Ç–µ–∫—É—â–∞—è minimal schema
- **Sub-optimal chunk sizes**: 2000 chars = ~800 tokens (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ)

### üîß –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è
```diff
// Jina API call
{
  model: 'jina-embeddings-v3',
  input: chunks,
  task: 'retrieval.passage',
  dimensions: 768,
+ late_chunking: true  // ‚Üê –ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï!
}
```

### üí∞ Cost
- **Development**: 2-4 hours
- **Runtime**: $0.02/1M tokens (unchanged)

### üìä Expected Improvement
- Retrieval failures: 5-6% ‚Üí 3-4% (**-35% failures**)
- Precision@5: 70% ‚Üí 78-80% (**+8-10pp**)
- Context quality: Moderate improvement

### üéØ Use Case
- **Temporary solution** –ø–æ–∫–∞ –¥–µ–ª–∞–µ–º –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é
- **A/B testing baseline** –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ late chunking —ç—Ñ—Ñ–µ–∫—Ç–∞
- **Low-risk production deployment**

---

## –í–∞—Ä–∏–∞–Ω—Ç 2: "Balanced" (Late Chunking + Token-Aware + Basic Hierarchy)

### üìù –û–ø–∏—Å–∞–Ω–∏–µ
Late chunking + token-based sizing + –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è (parent-child) + —É–ª—É—á—à–µ–Ω–Ω–∞—è metadata.

### ‚úÖ –ü–ª—é—Å—ã
- **Solid improvement**: 20-30% retrieval accuracy gain
- **Token-aware**: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ (400/1,500 tokens)
- **Hierarchical retrieval**: Precision (child) + Context (parent)
- **Better metadata**: Page numbers, chapter/section hierarchy
- **Production-ready**: All patterns proven in research
- **Reasonable complexity**: Implementable in 1-2 weeks
- **Incremental updates**: SHA-256 hashing –¥–ª—è change detection

### ‚ùå –ú–∏–Ω—É—Å—ã
- **No clickable links yet**: Source linking requires additional work
- **No advanced boundaries**: –ò—Å–ø–æ–ª—å–∑—É–µ–º LangChain splitters (–Ω–µ Razdel)
- **Storage overhead**: ~30% increase (parent + child chunks)
- **Migration required**: –ù—É–∂–Ω–æ re-index —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
- **Moderate cost**: $0.02-0.025/1M tokens (+0-25%)

### üîß –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è
```typescript
// Hierarchical splitting
const parentSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1500,  // tokens (not chars!)
  chunkOverlap: 100,
  separators: ['\n\n', '\n', '. ', ' ']
});

const childSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 400,
  chunkOverlap: 50,
  separators: ['\n\n', '\n', '. ', ' ']
});

// Metadata enrichment
metadata: {
  document_id, document_version, version_hash,
  hierarchy: { chapter, section, parent_chunk_id },
  source_location: { page_number, page_range },
  content_metadata: { token_count, parent_text },
  chunking_metadata: { chunk_strategy: 'hierarchical_late' }
}

// Late chunking embedding
await jinaClient.embedDocuments(groupedChunks, {
  late_chunking: true
});
```

### üí∞ Cost
- **Development**: 1-2 weeks (40-80 hours)
- **Runtime**: $0.02-0.025/1M tokens (+0-25%)
- **Storage**: +30% (parent chunks stored)

### üìä Expected Improvement
- Retrieval failures: 5-6% ‚Üí <2% (**-67% failures**)
- Precision@5: 70% ‚Üí 85-88% (**+15-18pp**)
- Context sufficiency: 75% ‚Üí 90% (**+15pp**)
- Citation accuracy: 40% ‚Üí 70% (**+30pp**, page numbers only)

### üéØ Use Case
- **Recommended for most teams**: Best balance complexity/improvement
- **Production deployment**: Proven patterns from research
- **Scalable to 1,000+ documents**

---

## –í–∞—Ä–∏–∞–Ω—Ç 3: "Production-Grade" (All Features + Source Linking)

### üìù –û–ø–∏—Å–∞–Ω–∏–µ
–í–∞—Ä–∏–∞–Ω—Ç 2 + clickable source links (PDF/HTML/DOCX) + document structure awareness + Razdel sentence boundaries + comprehensive metadata.

### ‚úÖ –ü–ª—é—Å—ã
- **Maximum retrieval quality**: <2% failure rate
- **Perfect source attribution**: Clickable links to PDF pages, HTML anchors
- **Document structure preservation**: Heading-based boundaries
- **Russian-optimized**: Razdel sentence segmentation (98.73% precision)
- **Production-ready monitoring**: Full metadata for debugging
- **Incremental updates**: Efficient re-indexing with change detection
- **Multi-document deduplication**: Semantic similarity detection
- **Comprehensive evaluation**: RAGAS metrics integrated

### ‚ùå –ú–∏–Ω—É—Å—ã
- **High complexity**: 3-4 weeks development
- **Python dependency**: Razdel —Ç—Ä–µ–±—É–µ—Ç Python microservice (–∏–ª–∏ port to JS)
- **Storage overhead**: ~40% increase (rich metadata)
- **Migration complexity**: Requires custom parsers for PDF/DOCX structure
- **Moderate cost increase**: $0.025-0.03/1M tokens (+25-50%)
- **Maintenance burden**: More moving parts

### üîß –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è
```typescript
// Document structure parsing
import { extractPDFStructure } from './pdf-parser';
import { extractHTMLHeadings } from './html-parser';

const structure = await extractPDFStructure(pdfBuffer);
// ‚Üí { headings: [...], pages: [...], links: [...] }

// Razdel sentence boundaries (Python microservice)
const sentences = await razdel.sentencize(russianText);

// Heading-based boundaries
for (const section of structure.headings) {
  const parentChunks = await splitByHeading(section, 1500);
  for (const parent of parentChunks) {
    const childChunks = await splitWithSentences(parent, 400);
    // ...
  }
}

// Clickable source linking
metadata: {
  linking: {
    clickable_url: `https://viewer.com/lecture-01.pdf#page=23`,
    anchor_id: "section-1-2-3",
    office365_url: `https://sharepoint.com/doc.docx#bookmark=sec_1_2_3`
  }
}

// Comprehensive metadata (full schema from research)
```

### üí∞ Cost
- **Development**: 3-4 weeks (120-160 hours)
- **Runtime**: $0.025-0.03/1M tokens (+25-50%)
- **Storage**: +40% (comprehensive metadata)
- **Infrastructure**: Python microservice for Razdel (+$10-20/month)

### üìä Expected Improvement
- Retrieval failures: 5-6% ‚Üí <1.5% (**-75% failures**)
- Precision@5: 70% ‚Üí 88-92% (**+18-22pp**)
- Context sufficiency: 75% ‚Üí 92-95% (**+17-20pp**)
- Citation accuracy: 40% ‚Üí 95%+ (**+55pp**, clickable links!)

### üéØ Use Case
- **Enterprise deployment**: High accuracy requirements
- **Educational platforms**: Source attribution critical
- **Content-heavy applications**: 1,000+ documents
- **When budget allows**: High ROI for user trust

---

## –í–∞—Ä–∏–∞–Ω—Ç 4: "Enterprise Maximum" (All Features + Contextual Enrichment)

### üìù –û–ø–∏—Å–∞–Ω–∏–µ
–í–∞—Ä–∏–∞–Ω—Ç 3 + Anthropic Contextual Retrieval + BM25 hybrid search + reranking.

### ‚úÖ –ü–ª—é—Å—ã
- **Maximum possible accuracy**: 67% improvement from baseline
- **Handles cross-references**: LLM-generated context for each chunk
- **Hybrid search**: Semantic (embeddings) + Lexical (BM25)
- **Reranking**: Secondary model for result ordering
- **Ultimate user experience**: Near-perfect retrieval
- **Future-proof**: State-of-art techniques

### ‚ùå –ú–∏–Ω—É—Å—ã
- **Very high cost**: $1.02/1M document tokens (50x increase!)
- **Slow indexing**: LLM calls for context generation
- **Complex architecture**: Multiple systems (embeddings, BM25, reranker, LLM)
- **Long development**: 4-6 weeks
- **Overkill for most use cases**: <95% accuracy requirement = waste
- **Infrastructure complexity**: BM25 index + vector store + LLM API

### üîß –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è
```typescript
// Contextual enrichment (LLM-generated)
const context = await llm.generate({
  prompt: `Document: ${documentSummary}\n\nChunk: ${chunkText}\n\nProvide 50-100 token context situating this chunk.`,
  model: 'claude-haiku',
  cache: true  // Prompt caching reduces cost
});

const enrichedChunk = `${context}\n\n${chunkText}`;

// Hybrid search (semantic + BM25)
const semanticResults = await qdrant.search(queryEmbedding);
const lexicalResults = await bm25Index.search(queryTokens);
const combined = mergeResults(semanticResults, lexicalResults);

// Reranking
const reranked = await reranker.rerank(query, combined);
```

### üí∞ Cost
- **Development**: 4-6 weeks (160-240 hours)
- **Indexing**: $1.02/1M document tokens (50x increase!)
- **Querying**: $0.05-0.10 per query (reranking + LLM)
- **Storage**: +50% (contextualized chunks)
- **Infrastructure**: BM25 index + reranker API (+$50-100/month)

### üìä Expected Improvement
- Retrieval failures: 5-6% ‚Üí <1% (**-83% failures**)
- Precision@5: 70% ‚Üí 92-95% (**+22-25pp**)
- Context sufficiency: 75% ‚Üí 95-98% (**+20-23pp**)
- Citation accuracy: 40% ‚Üí 98%+ (**+58pp**)

### üéØ Use Case
- **Only if accuracy >95% required**: Medical, legal, compliance
- **Budget is not a constraint**: Enterprise with dedicated budget
- **Cross-referential content**: Lots of "see Section X.Y" references
- **Premium product**: Competitive advantage through accuracy

---

## üìä Comparison Matrix

| Aspect | Variant 1<br>Quick Win | Variant 2<br>Balanced | Variant 3<br>Production | Variant 4<br>Maximum |
|--------|---------------------|-------------------|---------------------|-------------------|
| **Development Time** | 2-4 hours | 1-2 weeks | 3-4 weeks | 4-6 weeks |
| **Complexity** | Very Low | Medium | High | Very High |
| **Cost/1M tokens** | $0.02 | $0.02-0.025 | $0.025-0.03 | $1.02+ |
| **Retrieval Failures** | -35% | -67% | -75% | -83% |
| **Citation Accuracy** | No change | +30pp | +55pp | +58pp |
| **Source Linking** | ‚ùå No | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes |
| **Hierarchical** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| **Token-Aware** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| **Russian Optimized** | ‚ùå No | Partial | ‚úÖ Yes | ‚úÖ Yes |
| **Storage Overhead** | 0% | +30% | +40% | +50% |
| **Risk** | Very Low | Low | Medium | High |

---

## üéØ Recommendation

### –î–ª—è –≤–∞—à–µ–≥–æ —Å–ª—É—á–∞—è (Stage 0 Foundation): **–í–∞—Ä–∏–∞–Ω—Ç 2 "Balanced"**

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ**:
1. ‚úÖ **Best ROI**: 20-30% improvement –∑–∞ 1-2 –Ω–µ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç—ã
2. ‚úÖ **Production-ready**: –í—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã proven in research
3. ‚úÖ **Scalable**: –õ–µ–≥–∫–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–æ Variant 3 –ø–æ–∑–∂–µ
4. ‚úÖ **Token-aware**: –†–µ—à–∞–µ—Ç –≥–ª–∞–≤–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É (Russian token economics)
5. ‚úÖ **Hierarchical**: Precision + Context –≤ –æ–¥–Ω–æ–º —Ä–µ—à–µ–Ω–∏–∏
6. ‚úÖ **Low risk**: Incremental migration —Å rollback capability

### Phased Rollout Strategy

**Phase 1** (Week 1-2): Implement Variant 2
- Late chunking + hierarchical + token-aware
- Basic metadata with page numbers
- A/B test vs baseline

**Phase 2** (Week 3-4): Add source linking (upgrade to Variant 3)
- PDF/HTML clickable links
- Enhanced metadata schema
- Full RAGAS evaluation

**Phase 3** (Optional, Month 2-3): Contextual enrichment (Variant 4)
- **Only if**: Budget allows AND accuracy <95% after Phase 2

---

## üìù Implementation Priorities (Variant 2)

### Must-Have (Week 1)
1. ‚úÖ Token-based chunking (400/1,500 tokens)
2. ‚úÖ Hierarchical parent-child structure
3. ‚úÖ Late chunking enabled
4. ‚úÖ Basic metadata (page numbers, hierarchy)
5. ‚úÖ Incremental updates (SHA-256 hashing)

### Nice-to-Have (Week 2)
1. ‚≠ê Document structure extraction (headings)
2. ‚≠ê Sentence boundary refinement
3. ‚≠ê Multi-document deduplication
4. ‚≠ê A/B testing framework
5. ‚≠ê RAGAS evaluation

### Future Enhancements (Month 2+)
1. üöÄ Clickable source links (Variant 3)
2. üöÄ Razdel integration for Russian
3. üöÄ Contextual enrichment (Variant 4, optional)
4. üöÄ Hybrid BM25 + semantic search

---

## ‚úÖ Action Items

### Immediate (Today)
- [ ] Review this analysis with team
- [ ] Decide on variant (recommend: Variant 2)
- [ ] Approve development timeline
- [ ] Allocate resources (1 developer, 1-2 weeks)

### Week 1
- [ ] Implement token-based chunking
- [ ] Setup late chunking with Jina API
- [ ] Create hierarchical splitting logic
- [ ] Design metadata schema
- [ ] Implement change detection

### Week 2
- [ ] Integrate with existing pipeline
- [ ] A/B testing setup (20% traffic)
- [ ] Monitor metrics (retrieval, latency, cost)
- [ ] Document implementation

### Week 3-4 (If proceeding to Variant 3)
- [ ] Add source linking (PDF/HTML)
- [ ] Enhance metadata schema
- [ ] Deploy to production (canary ‚Üí full)

---

## üìö References from Research

Key papers and resources to reference during implementation:
- Jina AI Late Chunking: arXiv:2409.04701
- Anthropic Contextual Retrieval: Blog post Sept 2024
- LangChain RecursiveCharacterTextSplitter: js.langchain.com
- Qdrant payload filtering: qdrant.tech/documentation
- RAGAS evaluation: github.com/explodinggradients/ragas

---

**Next Step**: –°–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É T075 —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —ç—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
