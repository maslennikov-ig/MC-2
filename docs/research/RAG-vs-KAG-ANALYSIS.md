# RAG vs KAG: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: 2025-01-25
**–ü—Ä–æ–µ–∫—Ç**: MegaCampus2 - Stage 0 Foundation
**–ö–æ–Ω—Ç–µ–∫—Å—Ç**: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è RAG-—Å–∏—Å—Ç–µ–º—ã –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
**–ê–Ω–∞–ª–∏—Ç–∏–∫**: Claude Code

---

## üìã Executive Summary

### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

**üéØ –ì–ª–∞–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é RAG-—Å–∏—Å—Ç–µ–º—É (—Ñ–∞–∑–∞ 1-2 –º–µ—Å), –∑–∞—Ç–µ–º –ø—Ä–∏–Ω—è—Ç—å data-driven —Ä–µ—à–µ–Ω–∏–µ –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ KAG-—Ñ—É–Ω–∫—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.

**–ü–æ—á–µ–º—É –ù–ï –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ KAG —Å–µ–π—á–∞—Å:**
- ‚ùå 5-10x –≤—ã—à–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å ($0.02 vs $1-2 –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)
- ‚ùå 3-6x –¥–æ–ª—å—à–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ (1-2 –Ω–µ–¥–µ–ª–∏ vs 6-12 –Ω–µ–¥–µ–ª—å)
- ‚ùå –°–∏—Å—Ç–µ–º–∞ –Ω–µ–∑—Ä–µ–ª–∞—è (v0.8.0, —Ä–∞–Ω–Ω–∏–π —Ä–µ–ª–∏–∑ 2025)
- ‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
- ‚ùå 80% –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º RAG

**–ß—Ç–æ –ú–û–ñ–ù–û –ø–æ–∑–∞–∏–º—Å—Ç–≤–æ–≤–∞—Ç—å –∏–∑ KAG:**
- ‚úÖ Logical form-guided retrieval (–ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–æ–≤)
- ‚úÖ Hybrid retrieval (vector + BM25 + exact match)
- ‚úÖ Multi-hop query decomposition (—Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
- ‚úÖ Bidirectional indexing (entity ‚Üî chunks)

### –ë—ã—Å—Ç—Ä–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

| –ö—Ä–∏—Ç–µ—Ä–∏–π | Current RAG (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) | KAG (–ø–æ–ª–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è) | Hybrid Approach |
|----------|-------------------------------|----------------------|-----------------|
| **–¢–æ—á–Ω–æ—Å—Ç—å (–ø—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã)** | 85-90% | 85-90% | 85-90% |
| **–¢–æ—á–Ω–æ—Å—Ç—å (—Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)** | 70-75% | 90-95% | 85-90% |
| **–í—Ä–µ–º—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏** | 1-2 –Ω–µ–¥–µ–ª–∏ | 6-12 –Ω–µ–¥–µ–ª—å | 4-8 –Ω–µ–¥–µ–ª—å |
| **–°—Ç–æ–∏–º–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏** | $0.02/1M tokens | $1-2/1M tokens | $0.05-0.10/1M tokens |
| **–°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞** | $0.0001 | $0.001-0.005 | $0.0003-0.0008 |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏** | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω—è—è |
| **–ó—Ä–µ–ª–æ—Å—Ç—å —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã** | –í—ã—Å–æ–∫–∞—è | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–∞—è |
| **–°–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞** | <500ms | 1-5s | 500ms-2s |
| **–†–∏—Å–∫** | –ù–∏–∑–∫–∏–π | –í—ã—Å–æ–∫–∏–π | –°—Ä–µ–¥–Ω–∏–π |
| **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è** | ‚úÖ **–ù–∞—á–∞—Ç—å –∑–¥–µ—Å—å** | ‚ö†Ô∏è –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ <85% satisfaction | ‚úÖ –§–∞–∑–∞ 3 (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) |

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç–µ–∫—É—â–µ–π RAG-—Å–∏—Å—Ç–µ–º—ã

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    User Query (Russian)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Query Embedding (Jina-v3)                       ‚îÇ
‚îÇ  ‚Ä¢ Model: jina-embeddings-v3                                ‚îÇ
‚îÇ  ‚Ä¢ Task: retrieval.query                                     ‚îÇ
‚îÇ  ‚Ä¢ Dimensions: 768                                           ‚îÇ
‚îÇ  ‚Ä¢ Russian optimized: 2.5 chars/token                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Vector Search (Qdrant)                              ‚îÇ
‚îÇ  ‚Ä¢ HNSW index: O(log n) performance                         ‚îÇ
‚îÇ  ‚Ä¢ Filter by: org_id, course_id, document_type              ‚îÇ
‚îÇ  ‚Ä¢ Retrieve top-K child chunks (K=10)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Parent Chunk Retrieval                                ‚îÇ
‚îÇ  ‚Ä¢ Deduplicate by parent_id                                 ‚îÇ
‚îÇ  ‚Ä¢ Fetch parent contexts (1,500 tokens)                      ‚îÇ
‚îÇ  ‚Ä¢ Return top-5 unique parents                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              LLM Generation                                  ‚îÇ
‚îÇ  ‚Ä¢ Context: Parent chunks (full context)                     ‚îÇ
‚îÇ  ‚Ä¢ Citations: Child chunk IDs (precise attribution)          ‚îÇ
‚îÇ  ‚Ä¢ Source links: PDF page numbers, HTML anchors              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Chunking Strategy (Hierarchical Late Chunking)

**–î–æ–∫—É–º–µ–Ω—Ç** ‚Üí **–°–µ–∫—Ü–∏–∏ (–ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º)** ‚Üí **Parent chunks** ‚Üí **Child chunks**

```typescript
// Parent chunks: 1,500 tokens (~3,750 chars Russian)
const parentSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1500,      // tokens
  chunkOverlap: 100,    // ~7% overlap
  separators: ['\n\n', '\n', '. ', ' ']
});

// Child chunks: 400 tokens (~1,000 chars Russian)
const childSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 400,       // tokens
  chunkOverlap: 50,     // ~12.5% overlap
  separators: ['\n\n', '\n', '. ', ' ']
});

// Late chunking: –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–æ 8,192 —Ç–æ–∫–µ–Ω–æ–≤
const embeddings = await jinaClient.embed(groupedChunks, {
  late_chunking: true  // 35-49% improvement!
});
```

### Metadata Schema

```json
{
  "chunk_id": "doc_lec01_sec02_p03_c01",
  "document_id": "lecture-01",
  "version_hash": "sha256:abc123...",

  "hierarchy": {
    "chapter": "–ì–ª–∞–≤–∞ 1: –û—Å–Ω–æ–≤—ã",
    "section": "1.2 –û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º",
    "parent_chunk_id": "doc_lec01_sec02_p03"
  },

  "source_location": {
    "page_number": 23,
    "page_range": [23, 24]
  },

  "content_metadata": {
    "text": "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Å–æ—Å—Ç–æ—è—Ç –∏–∑...",
    "token_count": 418,
    "parent_text": "–ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ–∫—Ü–∏–∏...",
    "language": "ru"
  },

  "filtering": {
    "organization_id": "org_msu",
    "course_id": "ML101",
    "document_type": "lecture_notes"
  }
}
```

### –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã —Ç–µ–∫—É—â–µ–π —Å–∏—Å—Ç–µ–º—ã

‚úÖ **Late Chunking**: 35-49% reduction in retrieval failures (–¥–æ–∫–∞–∑–∞–Ω–æ BeIR benchmarks)
‚úÖ **Hierarchical Structure**: –†–µ—à–∞–µ—Ç –¥–∏–ª–µ–º–º—É precision vs context
‚úÖ **Token-Aware**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ (1.4-1.8x English, –Ω–µ 2x)
‚úÖ **Rich Metadata**: Page numbers, hierarchy, parent-child links
‚úÖ **Incremental Updates**: SHA-256 hashing –¥–ª—è change detection
‚úÖ **Production-Ready**: Mature ecosystem (LangChain, Qdrant, Jina-v3)
‚úÖ **Scalable**: 1,000+ documents, <500ms query latency
‚úÖ **Cost-Effective**: $0.02-0.025 per 1M tokens

### –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã —Ç–µ–∫—É—â–µ–π —Å–∏—Å—Ç–µ–º—ã

‚ùå **Pure Vector Similarity**: Ambiguity –≤ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö
‚ùå **No Symbolic Reasoning**: –ù–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π
‚ùå **Limited Multi-Hop**: –ü–ª–æ—Ö–æ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ —Ç–∏–ø–∞ "To understand A, need B and C"
‚ùå **No Concept Relationships**: –ù–µ –∑–Ω–∞–µ—Ç "X is prerequisite for Y"
‚ùå **Comparative Queries**: Struggles with "Compare X vs Y across dimensions"
‚ùå **No Numerical Reasoning**: –ù–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏

### Expected Performance (–ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)

| –ú–µ—Ç—Ä–∏–∫–∞ | Current (baseline) | Optimized (Variant 2) | Target |
|---------|-------------------|-----------------------|--------|
| Retrieval failure rate | 5-6% | <2% | <2% |
| Precision@5 | ~70% | 85-88% | >85% |
| Context sufficiency | ~75% | 90% | >90% |
| Citation accuracy | ~40% | 70% | >95% (–Ω—É–∂–µ–Ω Variant 3) |
| Query latency P95 | ~800ms | <500ms | <500ms |
| Cost per 1M tokens | $0.02 | $0.02-0.025 | <$0.05 |

---

## üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ KAG-—Å–∏—Å—Ç–µ–º—ã

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    User Query (Natural Language)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Query Understanding (kg-solver)                     ‚îÇ
‚îÇ  ‚Ä¢ Parse to logical form                                     ‚îÇ
‚îÇ  ‚Ä¢ Identify entities, relationships, intent                  ‚îÇ
‚îÇ  ‚Ä¢ Generate execution plan                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                   ‚îÇ          ‚îÇ           ‚îÇ
        ‚ñº                   ‚ñº          ‚ñº           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Exact Match ‚îÇ   ‚îÇ Text Search  ‚îÇ ‚îÇ KG Walk ‚îÇ ‚îÇ Semantic ‚îÇ
‚îÇ  Retrieval  ‚îÇ   ‚îÇ   (BM25)     ‚îÇ ‚îÇ(graph)  ‚îÇ ‚îÇ (Vector) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                   ‚îÇ          ‚îÇ           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Hybrid Reasoning Engine                             ‚îÇ
‚îÇ  ‚Ä¢ Combine results from all operators                        ‚îÇ
‚îÇ  ‚Ä¢ Graph traversal for multi-hop                             ‚îÇ
‚îÇ  ‚Ä¢ Numerical computation (if needed)                         ‚îÇ
‚îÇ  ‚Ä¢ Logical inference                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Knowledge Graph (OpenSPG)                           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Entities: [Concept A] ‚îÄ‚îÄ‚îÄ‚îÄ [Concept B]                     ‚îÇ
‚îÇ               ‚îÇ    is_prerequisite_for   ‚îÇ                   ‚îÇ
‚îÇ               ‚îÇ                          ‚îÇ                   ‚îÇ
‚îÇ         appears_in                  appears_in              ‚îÇ
‚îÇ               ‚îÇ                          ‚îÇ                   ‚îÇ
‚îÇ               ‚ñº                          ‚ñº                   ‚îÇ
‚îÇ         [Chunk 1] ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [Chunk 5]                ‚îÇ
‚îÇ         bidirectional_index                                 ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  DIKW Hierarchy:                                             ‚îÇ
‚îÇ  ‚Ä¢ Data: Raw text chunks                                     ‚îÇ
‚îÇ  ‚Ä¢ Information: Extracted entities                           ‚îÇ
‚îÇ  ‚Ä¢ Knowledge: Relationships, rules                           ‚îÇ
‚îÇ  ‚Ä¢ Wisdom: Inference patterns                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Answer Generation                               ‚îÇ
‚îÇ  ‚Ä¢ Context: Multi-hop reasoning results                      ‚îÇ
‚îÇ  ‚Ä¢ Citations: Entity-linked chunks                           ‚îÇ
‚îÇ  ‚Ä¢ Explanations: Reasoning trace                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Knowledge Graph Construction

```python
# Pseudo-code for KAG indexing pipeline

# 1. Document chunking (similar to RAG)
chunks = hierarchical_chunking(document, child_size=400, parent_size=1500)

# 2. Entity extraction (LLM-based)
for chunk in chunks:
    entities = llm.extract_entities(chunk.text, schema=domain_ontology)
    # Cost: ~$0.50-1.00 per 1M tokens

# 3. Relationship extraction (LLM-based)
    relationships = llm.extract_relationships(chunk.text, entities)
    # Cost: ~$0.50-1.00 per 1M tokens

# 4. Graph construction
    knowledge_graph.add_nodes(entities)
    knowledge_graph.add_edges(relationships)

# 5. Bidirectional indexing
    for entity in entities:
        entity.link_to_chunk(chunk.id)
        chunk.link_to_entity(entity.id)

# 6. Vector embedding (still needed!)
    vector = embed(chunk.text)
    vector_store.add(chunk.id, vector)

# Total indexing cost: $1-2 per 1M tokens (5-10x higher than RAG)
```

### –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã KAG

‚úÖ **Symbolic Reasoning**: –ü–æ–Ω–∏–º–∞–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
‚úÖ **Multi-Hop Queries**: –û—Ç–ª–∏—á–Ω–æ –¥–ª—è "–ß—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å A, —Å–Ω–∞—á–∞–ª–∞ –∏–∑—É—á–∏ B –∏ C"
‚úÖ **Reduced Ambiguity**: Logical forms —Å–Ω–∏–∂–∞—é—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
‚úÖ **Concept Relationships**: –ó–Ω–∞–µ—Ç "X is prerequisite for Y", "A contradicts B"
‚úÖ **Comparative Analysis**: Naturally handles "Compare A vs B vs C"
‚úÖ **Numerical Integration**: –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
‚úÖ **Hybrid Retrieval**: Exact + Text + Semantic + Graph –≤ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
‚úÖ **Professional Domains**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π

### –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã KAG

‚ùå **High Complexity**: –¢—Ä–µ–±—É–µ—Ç OpenSPG engine, graph database, vector store
‚ùå **Expensive Indexing**: $1-2 per 1M tokens (50-100x –¥–æ—Ä–æ–∂–µ RAG)
‚ùå **Slow Queries**: 1-5s –¥–ª—è multi-hop (vs <500ms –¥–ª—è RAG)
‚ùå **Immature Ecosystem**: v0.8.0, –º–∞–ª–æ–µ community, limited docs
‚ùå **Unknown Russian Support**: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º Chinese/English
‚ùå **KG Quality Dependency**: –ü–ª–æ—Ö–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è ‚Üí –ø–ª–æ—Ö–æ–π reasoning
‚ùå **Steep Learning Curve**: –ù—É–∂–Ω–æ –∑–Ω–∞—Ç—å graph concepts, OpenSPG, logical forms
‚ùå **Vendor Lock-In**: OpenSPG engine (–Ω–µ open standards)
‚ùå **Overkill for Simple Queries**: 80% educational queries –Ω–µ –Ω—É–∂–µ–Ω KAG

### Expected Performance (KAG)

| –ú–µ—Ç—Ä–∏–∫–∞ | KAG (full implementation) | Current RAG (optimized) |
|---------|---------------------------|-------------------------|
| Retrieval accuracy (simple queries) | 85-90% | 85-90% |
| Retrieval accuracy (complex queries) | **90-95%** | 70-75% |
| Query latency | 1-5s | <500ms |
| Indexing speed | 20-50 docs/hour | 100+ docs/hour |
| Cost per 1M tokens (indexing) | **$1-2** | $0.02-0.025 |
| Cost per query | **$0.001-0.005** | $0.0001 |
| Development time | **6-12 weeks** | 1-2 weeks |
| Maintenance burden | High | Low |

---

## üìä –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: 6 –∫–ª—é—á–µ–≤—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π

### 1. Retrieval Quality & Accuracy

#### –¢–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞ | –ü—Ä–∏–º–µ—Ä | RAG (optimized) | KAG | –ü–æ–±–µ–¥–∏—Ç–µ–ª—å |
|-------------|--------|-----------------|-----|------------|
| **Factual** | "–ß—Ç–æ —Ç–∞–∫–æ–µ backpropagation?" | 90-95% | 90-95% | **Tie** |
| **Definitional** | "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ gradient descent" | 90-95% | 90-95% | **Tie** |
| **Procedural** | "–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å CNN –Ω–∞ Python?" | 85-90% | 85-90% | **Tie** |
| **Conceptual** | "–û–±—ä—è—Å–Ω–∏ —Å–≤—è–∑—å –º–µ–∂–¥—É X –∏ Y" | 70-75% | **90-95%** | **KAG** |
| **Comparative** | "–°—Ä–∞–≤–Ω–∏ SGD, Adam, RMSprop" | 65-70% | **90-95%** | **KAG** |
| **Multi-hop** | "–î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è A –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å B –∏ C. –û–±—ä—è—Å–Ω–∏" | 60-70% | **90-95%** | **KAG** |
| **Prerequisite** | "–ö–∞–∫–∏–µ –∑–Ω–∞–Ω–∏—è –Ω—É–∂–Ω—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è X?" | 50-60% | **85-90%** | **KAG** |

#### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ (—Ç–∏–ø–∏—á–Ω–æ–µ)

```
Factual/Definitional: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 60%
Procedural:           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 20%
Conceptual:           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 15%
Comparative:          ‚ñà‚ñà 5%
```

**–í—ã–≤–æ–¥**: 80% –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç —Å RAG, —Ç–æ–ª—å–∫–æ 20% –ø–æ–ª—É—á–∞—é—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø–æ–ª—å–∑—É –æ—Ç KAG.

### 2. Implementation Complexity

#### RAG (Optimized)

```typescript
// Complexity: LOW-MEDIUM
// Libraries: LangChain, Jina-v3, Qdrant (–≤—Å–µ mature)

import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters';
import { JinaEmbeddings } from '@langchain/community/embeddings/jina';
import { QdrantClient } from '@qdrant/js-client-rest';

// 1. Setup (15 minutes)
const embeddings = new JinaEmbeddings({
  apiKey: process.env.JINA_API_KEY,
  model: 'jina-embeddings-v3'
});

const qdrant = new QdrantClient({
  url: process.env.QDRANT_URL
});

// 2. Chunking (1 hour implementation)
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 400,
  chunkOverlap: 50
});

// 3. Indexing (2 hours implementation)
const chunks = await splitter.splitText(document);
const vectors = await embeddings.embedDocuments(
  chunks.map(c => c.text),
  { late_chunking: true }  // ‚Üê Magic sauce!
);
await qdrant.upsert('docs', { points: vectors });

// 4. Retrieval (1 hour implementation)
const results = await qdrant.search({
  collection: 'docs',
  vector: queryEmbedding,
  filter: { organization_id: 'org_msu' },
  limit: 10
});

// Total development: 1-2 weeks (includes testing, optimization)
```

#### KAG (Full Implementation)

```python
# Complexity: HIGH
# Libraries: OpenSPG (new), Neo4j/TigerGraph (graph DB), embeddings, LLM APIs

from kag.builder import KGBuilder
from kag.solver import KGSolver
from openspg import OpenSPGEngine

# 1. Setup (1-2 days)
# - Install OpenSPG engine (Docker setup)
# - Configure graph database
# - Setup vector store
# - Configure LLM APIs for extraction

spg_engine = OpenSPGEngine(config)
kg_builder = KGBuilder(engine=spg_engine)
kg_solver = KGSolver(engine=spg_engine)

# 2. Domain Ontology Design (1-2 weeks!)
# - Define entity types (Concept, Topic, Formula, Example, etc.)
# - Define relationship types (prerequisite_of, similar_to, contradicts, etc.)
# - Create extraction prompts for each entity/relationship type
domain_schema = {
  "entities": ["Concept", "Algorithm", "Formula", "Example"],
  "relationships": ["prerequisite_of", "similar_to", "part_of"]
}

# 3. Knowledge Extraction (2-3 weeks implementation)
for document in documents:
    # Entity extraction (LLM calls)
    entities = kg_builder.extract_entities(
        document,
        schema=domain_schema,
        llm_model="gpt-4"  # Expensive!
    )

    # Relationship extraction (more LLM calls)
    relationships = kg_builder.extract_relationships(
        document,
        entities=entities,
        schema=domain_schema
    )

    # Graph construction
    kg_builder.build_graph(entities, relationships)

    # Vector indexing (still need this!)
    kg_builder.index_vectors(document)

# 4. Query Processing (2-3 weeks implementation)
# - Query parsing to logical form
# - Execution planning
# - Multi-operator coordination
# - Result synthesis
results = kg_solver.solve(
    query="–û–±—ä—è—Å–Ω–∏ —Å–≤—è–∑—å –º–µ–∂–¥—É X –∏ Y",
    reasoning_mode="hybrid"  # Uses all operators
)

# Total development: 6-12 weeks (includes learning curve)
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏**:

| –ê—Å–ø–µ–∫—Ç | RAG | KAG | –†–∞–∑–Ω–∏—Ü–∞ |
|--------|-----|-----|---------|
| Setup time | 15 min | 1-2 days | **10-20x** |
| Schema design | None | 1-2 weeks | **N/A** |
| Indexing pipeline | 3-4 hours | 2-3 weeks | **40-60x** |
| Query pipeline | 1-2 hours | 2-3 weeks | **40-60x** |
| Learning curve | Low | Steep | **High** |
| Debugging difficulty | Easy | Hard | **Hard** |

### 3. Cost Analysis (–î–µ—Ç–∞–ª—å–Ω–∞—è)

#### Indexing Costs (100M tokens Russian educational content)

**RAG (Optimized)**:
```
Jina-v3 embeddings: $0.02 per 1M tokens
Late chunking: $0 (included)
Storage (Qdrant): $50-100/month for ~500K vectors

Total one-time indexing: $2 (100M √ó $0.02/1M)
Monthly storage: $50-100
Re-indexing (incremental): ~$0.20 per update (10M tokens changed)
```

**KAG**:
```
Entity extraction (LLM): $0.50-1.00 per 1M tokens
  100M tokens √ó $0.75/1M = $75

Relationship extraction (LLM): $0.50-1.00 per 1M tokens
  100M tokens √ó $0.75/1M = $75

Vector embeddings: $0.02 per 1M tokens (still need!)
  100M tokens √ó $0.02/1M = $2

Graph database storage: $100-300/month (Neo4j/TigerGraph)
Vector storage: $50-100/month

Total one-time indexing: $152 (75x more expensive!)
Monthly storage: $150-400
Re-indexing (incremental): ~$15 per update (10M tokens)
```

#### Query Costs (10,000 queries/month)

**RAG**:
```
Query embedding: $0.02 per 1M tokens
  10K queries √ó 50 tokens avg = 0.5M tokens
  0.5M √ó $0.02/1M = $0.01/month

Vector search (Qdrant): Included in hosting

Total: ~$1/month (mostly hosting overhead)
Cost per query: $0.0001
```

**KAG**:
```
Query parsing (LLM): ~50 tokens per query
  10K queries √ó 50 tokens √ó $1/1M tokens = $0.50/month

Graph traversal (compute): $10-20/month (depends on complexity)

Vector search: $0.01/month (same as RAG)

LLM reasoning calls (for complex queries): $5-10/month
  20% complex queries √ó 2K tokens √ó $1/1M tokens

Total: ~$16-31/month
Cost per query: $0.0016-0.0031 (16-31x more expensive)
```

#### Total Cost of Ownership (1 year, 1000 documents)

| Cost Component | RAG | KAG | Difference |
|----------------|-----|-----|------------|
| **Development** | $8,000 (2 weeks) | $48,000 (12 weeks) | **+$40,000** |
| **Initial indexing** | $20 | $1,500 | **+$1,480** |
| **Monthly hosting** | $100 | $350 | **+$250/mo** |
| **Yearly hosting** | $1,200 | $4,200 | **+$3,000** |
| **Query costs (120K/year)** | $12 | $192-372 | **+$180-360** |
| **Maintenance (yearly)** | $4,000 | $12,000 | **+$8,000** |
| **Total Year 1** | **$13,232** | **$66,072** | **+$52,840 (5x)** |

### 4. Use Case Fit (Educational Russian Content)

#### Query Analysis –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

**–¢–∏–ø–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Å—Ç—É–¥–µ–Ω—Ç–æ–≤**:

1. **Factual (40%)**:
   - "–ß—Ç–æ —Ç–∞–∫–æ–µ gradient descent?"
   - "–ö–∞–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è cross-entropy loss?"
   - "–í –∫–∞–∫–æ–º –≥–æ–¥—É –∏–∑–æ–±—Ä–µ–ª–∏ CNN?"
   - **Verdict**: RAG –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è (90-95% accuracy)

2. **Procedural (20%)**:
   - "–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å backpropagation –Ω–∞ Python?"
   - "–ü–æ–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è CNN"
   - "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å learning rate?"
   - **Verdict**: RAG –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è (85-90% accuracy)

3. **Definitional (20%)**:
   - "–û–±—ä—è—Å–Ω–∏ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É supervised –∏ unsupervised learning"
   - "–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç overfitting?"
   - **Verdict**: RAG —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è (85-90%)

4. **Conceptual (15%)**:
   - "–ü–æ—á–µ–º—É gradient descent –∑–∞—Å—Ç—Ä–µ–≤–∞–µ—Ç –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –º–∏–Ω–∏–º—É–º–µ?"
   - "–û–±—ä—è—Å–Ω–∏ —Å–≤—è–∑—å –º–µ–∂–¥—É bias –∏ variance"
   - "–ö–∞–∫ regularization –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overfitting?"
   - **Verdict**: RAG —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ (70-80%), KAG –ª—É—á—à–µ (90%)

5. **Comparative (5%)**:
   - "–°—Ä–∞–≤–Ω–∏ SGD, Adam, RMSprop"
   - "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É CNN –∏ RNN?"
   - **Verdict**: RAG –ø–ª–æ—Ö–æ (65-70%), KAG –æ—Ç–ª–∏—á–Ω–æ (90%)

**–í—ã–≤–æ–¥**: 80% –∑–∞–ø—Ä–æ—Å–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç –æ—Ç–ª–∏—á–Ω–æ —Å RAG, 15% —Ä–∞–±–æ—Ç–∞—é—Ç —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ, —Ç–æ–ª—å–∫–æ 5% –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ KAG.

#### Russian Language Support

**RAG (Proven)**:
```
‚úÖ Jina-v3: 96% of English performance on Russian tasks (tested)
‚úÖ Token efficiency: 1.4-1.8x English (improved from 2x)
‚úÖ Razdel: 98.73% precision for sentence segmentation
‚úÖ LangChain: Full UTF-8/Cyrillic support
‚úÖ Qdrant: Language-agnostic (vectors work for any language)
```

**KAG (Unknown)**:
```
‚ö†Ô∏è OpenSPG: Documentation mostly Chinese/English
‚ö†Ô∏è Entity extraction: Unknown Russian performance
‚ö†Ô∏è Relationship extraction: Unknown Russian quality
‚ö†Ô∏è Logical forms: May not handle Russian syntax well
‚ö†Ô∏è No published benchmarks for Russian
‚ùå Risk: Need extensive testing before production
```

### 5. Maturity & Ecosystem

#### Technology Maturity

| Component | RAG Stack | KAG Stack | Gap |
|-----------|-----------|-----------|-----|
| **Core technology** | Embeddings (2018+) | Knowledge Graphs (2010s) + LLMs | Both mature concepts |
| **Implementation** | Jina-v3 (2024, stable) | OpenSPG KAG (v0.8.0, early 2025) | **KAG is new** |
| **Community size** | Large (millions of users) | Small (thousands) | **100x smaller** |
| **Documentation** | Excellent (tutorials, examples, guides) | Limited (mainly Chinese) | **RAG much better** |
| **Stack Overflow** | 50K+ questions on RAG/embeddings | <100 on KAG/OpenSPG | **500x more support** |
| **Production examples** | Many (Pinecone, Weaviate, etc.) | Few (mostly research) | **RAG proven** |
| **Breaking changes risk** | Low (mature APIs) | High (v0.8 ‚Üí v1.0) | **KAG riskier** |

#### Developer Experience

**RAG**:
```typescript
// Clear error messages
Error: JINA_API_KEY not found in environment
  ‚Üí Solution: Add JINA_API_KEY to .env

// Extensive examples
GitHub: "langchain hierarchical chunking" ‚Üí 1,000+ results

// Active community
Discord/Slack: Response within hours

// Debugging tools
LangSmith: Full tracing and observability
```

**KAG**:
```python
# Cryptic errors (early ecosystem)
Error: SPG engine failed to initialize graph schema
  ‚Üí Solution: ??? (Google returns no results)

# Limited examples
GitHub: "openspg kag russian" ‚Üí 0 results

# Small community
Discord/Slack: May wait days for response

# Limited tooling
Debugging: Console logs, manual graph inspection
```

### 6. Performance & Scalability

#### Latency Benchmarks (typical educational query)

```
RAG (Optimized):
‚îú‚îÄ Query embedding: 50-100ms (Jina API)
‚îú‚îÄ Vector search: 20-50ms (Qdrant HNSW)
‚îú‚îÄ Parent retrieval: 10-20ms (Qdrant fetch)
‚îî‚îÄ Total: 80-170ms ‚Üí P95 <200ms ‚úÖ

KAG:
‚îú‚îÄ Query parsing: 200-500ms (LLM call)
‚îú‚îÄ Execution planning: 50-100ms
‚îú‚îÄ Entity lookup: 50-100ms (graph query)
‚îú‚îÄ Relationship traversal: 200-1000ms (multi-hop)
‚îú‚îÄ Vector search: 20-50ms (still needed!)
‚îú‚îÄ Result synthesis: 100-300ms (LLM call)
‚îî‚îÄ Total: 620-2050ms ‚Üí P95 ~2-3s ‚ùå
```

#### Scalability Characteristics

**RAG**:
```
Document count: 1K ‚Üí 10K ‚Üí 100K
  Query latency: 100ms ‚Üí 120ms ‚Üí 150ms (log scaling)
  Memory: 200MB ‚Üí 2GB ‚Üí 20GB (linear scaling)
  Indexing time: 10h ‚Üí 100h ‚Üí 1000h (linear)

Horizontal scaling: ‚úÖ Easy (multiple Qdrant nodes)
Concurrent users: ‚úÖ 100+ (vector search parallelizes well)
Bottleneck: API rate limits (embeddings)
```

**KAG**:
```
Document count: 1K ‚Üí 10K ‚Üí 100K
  Query latency: 1s ‚Üí 3s ‚Üí 10s+ (quadratic worst-case)
  Memory: 500MB ‚Üí 10GB ‚Üí 200GB (graph + vectors)
  Indexing time: 50h ‚Üí 1000h ‚Üí 20000h (LLM calls dominate)

Horizontal scaling: ‚ö†Ô∏è Difficult (graph partitioning complex)
Concurrent users: ‚ö†Ô∏è 20-50 (graph DB becomes bottleneck)
Bottleneck: Graph traversal complexity
```

**–í—ã–≤–æ–¥**: RAG –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

---

## üîÄ –ì–∏–±—Ä–∏–¥–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã: 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞

### –í–∞—Ä–∏–∞–Ω—Ç 1: "RAG + Lightweight KG" (–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –¥–ª—è —Ñ–∞–∑—ã 3)

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          User Query                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Query Enhancement Layer (NEW!)           ‚îÇ
‚îÇ  ‚Ä¢ Parse query for entities                  ‚îÇ
‚îÇ  ‚Ä¢ Expand with synonyms from mini-KG         ‚îÇ
‚îÇ  ‚Ä¢ Identify query intent                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Hybrid Retrieval                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ   Vector    ‚îÇ  ‚îÇ    BM25     ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ   (Jina-v3) ‚îÇ  ‚îÇ  (keyword)  ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                   ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                  ‚ñº                           ‚îÇ
‚îÇ         Result Fusion (RRF)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Lightweight KG Enhancement (NEW!)        ‚îÇ
‚îÇ  ‚Ä¢ Check if results mention key concepts     ‚îÇ
‚îÇ  ‚Ä¢ Add related concepts from mini-KG         ‚îÇ
‚îÇ  ‚Ä¢ Re-rank by concept relevance              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Standard RAG Generation             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è

```typescript
// 1. Mini-KG Construction (during indexing)
interface MiniKG {
  entities: Map<string, Entity>;     // Key concepts only
  relationships: Map<string, Rel[]>; // Core relationships
}

// Extract only core concepts (not all entities)
const coreEntities = await extractCoreEntities(document, {
  maxEntitiesPerDoc: 10,    // Limit to key concepts
  entityTypes: ['Algorithm', 'Concept', 'Formula']
});

// Extract only explicit relationships
const relationships = await extractExplicitRelationships(
  document,
  coreEntities,
  {
    relationshipTypes: ['prerequisite_of', 'similar_to', 'part_of']
  }
);

// Store in metadata (not separate graph DB!)
chunk.metadata.entities = coreEntities;
chunk.metadata.relationships = relationships;

// 2. Query Enhancement (at query time)
async function enhanceQuery(query: string): Promise<EnhancedQuery> {
  // Parse for entities (lightweight, no LLM)
  const entities = await simpleEntityExtraction(query);

  // Expand with synonyms from mini-KG
  const expanded = entities.flatMap(e =>
    miniKG.getSynonyms(e)
  );

  return {
    original: query,
    entities: entities,
    expanded: [...entities, ...expanded]
  };
}

// 3. Hybrid Retrieval
const vectorResults = await qdrant.search({
  vector: queryEmbedding,
  limit: 20
});

const bm25Results = await bm25Index.search(
  enhancedQuery.expanded,
  { limit: 20 }
);

const fused = reciprocalRankFusion([vectorResults, bm25Results]);

// 4. KG-based Re-ranking (NEW!)
const reranked = fused.map(result => {
  const conceptScore = calculateConceptRelevance(
    result.metadata.entities,
    enhancedQuery.entities,
    miniKG
  );

  return {
    ...result,
    score: result.score * 0.7 + conceptScore * 0.3
  };
}).sort((a, b) => b.score - a.score);
```

#### –ü–ª—é—Å—ã

‚úÖ **Low complexity**: No separate graph database (store in metadata)
‚úÖ **Low cost**: Only core concepts extracted (~10 per document)
‚úÖ **Fast queries**: No graph traversal (<100ms overhead)
‚úÖ **Incremental**: Can add gradually to existing RAG
‚úÖ **Better conceptual queries**: +10-15% accuracy on complex questions
‚úÖ **Hybrid search**: Best of both worlds (vector + keyword)
‚úÖ **Compatible with current stack**: No new infrastructure

#### –ú–∏–Ω—É—Å—ã

‚ùå **Limited multi-hop**: Still can't do complex reasoning
‚ùå **No deep relationships**: Only explicit, surface-level links
‚ùå **Manual schema design**: Need to define entity/relationship types
‚ùå **Extraction quality**: Depends on prompt engineering

#### Cost

- **Development**: 4-6 weeks
- **Indexing**: +$0.03-0.05 per 1M tokens (entity extraction)
- **Query**: +50-100ms latency
- **Storage**: +10% (entity metadata)
- **Total**: ~30% more than base RAG

#### When to use

- After optimizing base RAG (Variant 2)
- If conceptual/comparative queries <80% accuracy
- When budget allows modest increase
- As stepping stone before full KAG

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: "Dual-Path System"

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
                    User Query
                        ‚îÇ
                        ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Query Classifier     ‚îÇ
            ‚îÇ  (LLM-based)          ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                       ‚îÇ
        Simple                  Complex
       (80% traffic)          (20% traffic)
            ‚îÇ                       ‚îÇ
            ‚ñº                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Fast Path   ‚îÇ        ‚îÇ  Smart Path ‚îÇ
    ‚îÇ  (RAG only)  ‚îÇ        ‚îÇ  (KAG full) ‚îÇ
    ‚îÇ  <500ms      ‚îÇ        ‚îÇ  1-5s       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Query Classification

```typescript
async function classifyQuery(query: string): Promise<'simple' | 'complex'> {
  const signals = {
    // Simple signals
    startsWithWhat: query.startsWith('–ß—Ç–æ —Ç–∞–∫–æ–µ'),
    startsWithHow: query.match(/–ö–∞–∫ (—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å|–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)/),
    hasFormula: query.includes('—Ñ–æ—Ä–º—É–ª–∞'),

    // Complex signals
    hasCompare: query.match(/—Å—Ä–∞–≤–Ω–∏|—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É|–æ—Ç–ª–∏—á–∏–µ/i),
    hasMultipleConcepts: (query.match(/–∏|–∏–ª–∏/g) || []).length > 2,
    hasExplain: query.match(/–æ–±—ä—è—Å–Ω–∏ —Å–≤—è–∑—å|–ø–æ—á–µ–º—É|–∫–∞–∫ (—Å–≤—è–∑–∞–Ω—ã|–≤–ª–∏—è–µ—Ç)/i),
    hasPrerequisite: query.match(/–¥–ª—è (–ø–æ–Ω–∏–º–∞–Ω–∏—è|–∏–∑—É—á–µ–Ω–∏—è)/i)
  };

  const simpleScore = [
    signals.startsWithWhat,
    signals.startsWithHow,
    signals.hasFormula
  ].filter(Boolean).length;

  const complexScore = [
    signals.hasCompare,
    signals.hasMultipleConcepts,
    signals.hasExplain,
    signals.hasPrerequisite
  ].filter(Boolean).length;

  // Use LLM for ambiguous cases
  if (Math.abs(simpleScore - complexScore) < 2) {
    return await llmClassify(query);
  }

  return complexScore > simpleScore ? 'complex' : 'simple';
}

// Route accordingly
const path = await classifyQuery(userQuery);
if (path === 'simple') {
  return await ragRetrieval(userQuery);  // Fast path
} else {
  return await kagRetrieval(userQuery);  // Smart path
}
```

#### –ü–ª—é—Å—ã

‚úÖ **Optimized cost**: Pay for KAG only when needed (20% of queries)
‚úÖ **Fast for common queries**: 80% get <500ms response
‚úÖ **Best accuracy for complex**: 20% get full KAG capabilities
‚úÖ **User satisfaction**: Simple queries fast, complex queries accurate
‚úÖ **Cost control**: ~40% of full KAG cost (20% traffic √ó 2x cost/query)

#### –ú–∏–Ω—É—Å—ã

‚ùå **High complexity**: Maintain two full systems
‚ùå **Classification overhead**: 100-200ms LLM call for ambiguous queries
‚ùå **Misclassification risk**: Wrong path ‚Üí poor UX
‚ùå **Double infrastructure**: RAG + KAG both need hosting
‚ùå **Development burden**: Build and maintain both
‚ùå **Inconsistent citations**: Different formats from each path

#### Cost

- **Development**: 8-12 weeks (both systems + classifier)
- **Infrastructure**: Full RAG + Full KAG (~$450/month)
- **Query costs**: 80% √ó $0.0001 + 20% √ó $0.003 = $0.00068 avg
- **Total Year 1**: ~$45,000 (between RAG and KAG)

#### When to use

- Clear separation of query types
- High query volume (classifier overhead amortizes)
- Budget for both systems
- When 80/20 split is proven with data

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: "Selective KAG Enhancement"

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
Knowledge Structure:
                Core Concepts KG
                (200-300 nodes)
                      ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ         ‚îÇ         ‚îÇ
    [Algorithm]  [Concept]  [Formula]
         ‚îÇ           ‚îÇ          ‚îÇ
         ‚îÇ           ‚îÇ          ‚îÇ
    bidirectional links
         ‚îÇ           ‚îÇ          ‚îÇ
         ‚ñº           ‚ñº          ‚ñº
    [Chunk 1]   [Chunk 5]  [Chunk 12]  ‚Üê RAG chunks
    [Chunk 7]   [Chunk 8]  [Chunk 20]    (full collection)
    [Chunk 15]  [Chunk 22] [Chunk 31]

Query Flow:
1. Check if query mentions core concepts
2. If yes ‚Üí KG traversal for related concepts ‚Üí RAG chunks
3. If no ‚Üí Direct RAG retrieval
```

#### Implementation

```typescript
// 1. Identify core concepts (manual curation + LLM)
const coreConcepts = [
  'gradient_descent',
  'backpropagation',
  'neural_network',
  'overfitting',
  'regularization',
  // ... 200-300 total
];

// 2. Build mini-KG for core concepts only
const coreKG = await buildKnowledgeGraph({
  entities: coreConcepts,
  extractRelationships: true,
  extractPrerequisites: true,
  extractSimilarities: true
});

// 3. Bidirectional linking
for (const chunk of allChunks) {
  const mentionedConcepts = extractMentions(chunk.text, coreConcepts);

  // Link chunk ‚Üí concepts
  chunk.metadata.mentions = mentionedConcepts;

  // Link concepts ‚Üí chunk
  for (const concept of mentionedConcepts) {
    coreKG.addChunkReference(concept, chunk.id);
  }
}

// 4. Hybrid retrieval
async function selectiveKAGRetrieval(query: string) {
  const mentionedConcepts = extractMentions(query, coreConcepts);

  if (mentionedConcepts.length === 0) {
    // No core concepts ‚Üí standard RAG
    return await ragRetrieval(query);
  }

  // Core concepts found ‚Üí KG expansion
  const relatedConcepts = [];
  for (const concept of mentionedConcepts) {
    const neighbors = coreKG.getNeighbors(concept, maxHops=2);
    relatedConcepts.push(...neighbors);
  }

  // Retrieve chunks mentioning expanded concepts
  const candidateChunks = [];
  for (const concept of [...mentionedConcepts, ...relatedConcepts]) {
    const chunks = coreKG.getChunksForConcept(concept);
    candidateChunks.push(...chunks);
  }

  // Re-rank with vector similarity
  const reranked = await vectorRerank(query, candidateChunks);

  return reranked.slice(0, 5);
}
```

#### –ü–ª—é—Å—ã

‚úÖ **Scalable**: Only 200-300 nodes (not thousands)
‚úÖ **Fast**: Graph traversal on small graph (<50ms)
‚úÖ **Targeted**: Best concepts get KG treatment
‚úÖ **Fallback**: Non-core queries use standard RAG
‚úÖ **Moderate cost**: Only extract relationships for core concepts
‚úÖ **Better multi-hop**: Works for prerequisite chains

#### –ú–∏–Ω—É—Å—ã

‚ùå **Manual curation**: Need to identify core concepts (expert input)
‚ùå **Incomplete coverage**: Long-tail concepts not in KG
‚ùå **Boundary issues**: "Core" vs "non-core" is subjective
‚ùå **Maintenance**: Core concepts change as curriculum evolves

#### Cost

- **Development**: 6-8 weeks (KG construction + integration)
- **Indexing**: +$0.10-0.15 per 1M tokens (core concept extraction)
- **Infrastructure**: +$50/month (small graph DB)
- **Query**: +20-50ms latency
- **Total**: ~50% more than base RAG

#### When to use

- Domain has clear core concepts (e.g., ML, Math, Physics)
- Expert available to curate concept list
- Want multi-hop reasoning for key topics
- Budget for moderate increase

---

### –í–∞—Ä–∏–∞–Ω—Ç 4: "Progressive Enhancement"

#### Strategy

**Month 1-2**: Optimize base RAG
- Implement Late Chunking + Hierarchical
- Deploy to production
- Measure baseline metrics

**Month 3-4**: Add lightweight features
- BM25 hybrid search
- Query decomposition
- Basic entity extraction (metadata only)

**Month 5-6**: Mini-KG for top 50 concepts
- Identify most-queried concepts from logs
- Build small KG for those only
- A/B test impact

**Month 7-9**: Expand to top 200 concepts
- Gradually grow KG coverage
- Monitor cost vs improvement
- Kill if ROI is poor

**Month 10-12**: Evaluate full KAG
- If mini-KG shows clear value ‚Üí consider full KAG
- If mini-KG shows marginal value ‚Üí stop at hybrid
- Data-driven decision point

#### –ü–ª—é—Å—ã

‚úÖ **Low initial risk**: Start with proven RAG
‚úÖ **Gradual investment**: Spend only if seeing results
‚úÖ **Data-driven**: Decisions based on production metrics
‚úÖ **Flexible**: Can stop at any phase
‚úÖ **Learning curve spread**: Team learns incrementally
‚úÖ **Early value**: Users benefit from RAG optimization immediately

#### –ú–∏–Ω—É—Å—ã

‚ùå **Slow to full capability**: 12+ months to full KAG (if going there)
‚ùå **Constant migration**: System in flux for a year
‚ùå **May never complete**: Risk of perpetual "almost there"
‚ùå **Fragmented architecture**: Mixture of old and new

#### Cost

- **Month 1-2**: $13K (RAG optimization)
- **Month 3-6**: +$8K (hybrid features)
- **Month 7-12**: +$15K (mini-KG)
- **Decision point**: Full KAG or stop
- **Total**: $36K to decision point (less than full KAG upfront)

#### When to use

- **Uncertain about KAG value**: Need proof before big investment
- **Limited budget**: Spread costs over time
- **Agile team**: Comfortable with iterative development
- **Risk-averse**: Prefer safe, incremental approach

---

## üí° –ß—Ç–æ –º–æ–∂–Ω–æ –ø–æ–∑–∞–∏–º—Å—Ç–≤–æ–≤–∞—Ç—å –∏–∑ KAG (–±–µ–∑ –ø–æ–ª–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏)

### 1. Logical Form-Guided Retrieval ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**–ß—Ç–æ —ç—Ç–æ**: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ–æ—Ä–º—É –ø–µ—Ä–µ–¥ retrieval.

**–ü—Ä–∏–º–µ—Ä**:
```
User query: "–°—Ä–∞–≤–Ω–∏ gradient descent –∏ Adam optimizer"

Logical form:
{
  intent: "compare",
  entities: ["gradient_descent", "adam_optimizer"],
  aspects: ["algorithm", "performance", "use_cases"],
  operation: "contrast"
}

Enhanced retrieval:
- Retrieve docs about gradient_descent
- Retrieve docs about adam_optimizer
- Focus on comparative aspects
- Synthesize comparison table
```

**Implementation** (–ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ LLM):

```typescript
interface LogicalForm {
  intent: 'define' | 'compare' | 'explain' | 'how-to' | 'list';
  entities: string[];
  relationships?: string[];
  constraints?: string[];
}

function parseQuery(query: string): LogicalForm {
  const patterns = {
    compare: /—Å—Ä–∞–≤–Ω–∏|—Ä–∞–∑–Ω–∏—Ü–∞|–æ—Ç–ª–∏—á–∏–µ|vs/i,
    define: /—á—Ç–æ —Ç–∞–∫–æ–µ|–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ|—ç—Ç–æ|–æ–∑–Ω–∞—á–∞–µ—Ç/i,
    explain: /–æ–±—ä—è—Å–Ω–∏|–ø–æ—á–µ–º—É|–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç/i,
    howTo: /–∫–∞–∫ (—Å–¥–µ–ª–∞—Ç—å|—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å|–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)/i,
    list: /—Å–ø–∏—Å–æ–∫|–ø–µ—Ä–µ—á–∏—Å–ª–∏|–∫–∞–∫–∏–µ –µ—Å—Ç—å/i
  };

  // Detect intent
  let intent: LogicalForm['intent'] = 'define';
  for (const [key, pattern] of Object.entries(patterns)) {
    if (pattern.test(query)) {
      intent = key as any;
      break;
    }
  }

  // Extract entities (simple NER)
  const entities = extractEntities(query);

  return { intent, entities };
}

// Use logical form to improve retrieval
async function logicalFormRetrieval(query: string) {
  const form = parseQuery(query);

  if (form.intent === 'compare' && form.entities.length === 2) {
    // Special handling for comparison
    const [entity1, entity2] = form.entities;

    const results1 = await qdrant.search({
      vector: await embed(entity1),
      filter: { must: [{ key: 'mentions', match: entity1 }] },
      limit: 5
    });

    const results2 = await qdrant.search({
      vector: await embed(entity2),
      filter: { must: [{ key: 'mentions', match: entity2 }] },
      limit: 5
    });

    // Combine and instruct LLM to compare
    return {
      chunks: [...results1, ...results2],
      instruction: `Compare ${entity1} and ${entity2} across these aspects...`
    };
  }

  // Standard retrieval for other intents
  return await ragRetrieval(query);
}
```

**Benefits**:
- ‚úÖ +10-15% accuracy on complex queries
- ‚úÖ <100ms overhead (pattern matching)
- ‚úÖ No LLM cost (rule-based)
- ‚úÖ Easy to implement (1-2 days)

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (High impact, low cost)

---

### 2. Hybrid Retrieval (Vector + BM25) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**–ß—Ç–æ —ç—Ç–æ**: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ semantic search (vectors) –∏ keyword search (BM25).

**Why it helps**:
- Vector search: Good at semantic similarity ("car" ‚âà "automobile")
- BM25: Good at exact matches ("gradient descent" must contain both words)
- Hybrid: Best of both worlds

**Implementation**:

```typescript
import { BM25 } from 'bm25';

// 1. Build BM25 index (during indexing)
const bm25 = new BM25();
for (const chunk of chunks) {
  bm25.addDocument(chunk.id, chunk.text);
}

// 2. Hybrid search
async function hybridSearch(query: string, topK: number = 10) {
  // Semantic search (vector)
  const vectorResults = await qdrant.search({
    vector: await embed(query),
    limit: topK * 2
  });

  // Keyword search (BM25)
  const bm25Results = bm25.search(query, topK * 2);

  // Reciprocal Rank Fusion (RRF)
  const fused = reciprocalRankFusion(
    [vectorResults, bm25Results],
    { k: 60 }  // RRF parameter
  );

  return fused.slice(0, topK);
}

function reciprocalRankFusion(
  resultLists: any[][],
  { k = 60 }: { k?: number } = {}
): any[] {
  const scores = new Map<string, number>();

  for (const results of resultLists) {
    results.forEach((result, rank) => {
      const id = result.id;
      const rrfScore = 1 / (k + rank + 1);
      scores.set(id, (scores.get(id) || 0) + rrfScore);
    });
  }

  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .map(([id, score]) => ({ id, score }));
}
```

**Benefits**:
- ‚úÖ +5-10% recall (finds more relevant docs)
- ‚úÖ Better for rare terms (proper nouns, formulas)
- ‚úÖ Low cost (BM25 is cheap, <10ms)
- ‚úÖ Proven technique (used by major search engines)

**Cost**:
- Development: 2-3 days
- Storage: +10% (BM25 index)
- Query: +10-20ms

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (High impact, low cost)

---

### 3. Multi-Hop Query Decomposition ‚≠ê‚≠ê‚≠ê‚≠ê

**–ß—Ç–æ —ç—Ç–æ**: –†–∞–∑–±–∏–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–¥–≤–æ–ø—Ä–æ—Å—ã.

**Example**:
```
Complex query:
"–ß—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å backpropagation, –∫–∞–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å
 –∏ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ –∏—Ö –∏–∑—É—á–∞—Ç—å?"

Decomposition:
1. "–ß—Ç–æ —Ç–∞–∫–æ–µ backpropagation?"
2. "–ö–∞–∫–∏–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –Ω—É–∂–Ω—ã –¥–ª—è backpropagation?"
3. "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π"

Retrieval:
- Retrieve for each sub-question independently
- Combine results
- Synthesize coherent answer
```

**Implementation**:

```typescript
async function decomposeQuery(query: string): Promise<string[]> {
  // Use LLM to decompose
  const prompt = `
–†–∞–∑–±–µ–π —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–¥–≤–æ–ø—Ä–æ—Å—ã.

–í–æ–ø—Ä–æ—Å: ${query}

–ü–æ–¥–≤–æ–ø—Ä–æ—Å—ã (JSON array):`;

  const response = await llm.complete(prompt);
  return JSON.parse(response);
}

async function multiHopRetrieval(query: string) {
  // 1. Check if query is complex
  if (!isComplexQuery(query)) {
    return await standardRetrieval(query);
  }

  // 2. Decompose
  const subQueries = await decomposeQuery(query);

  // 3. Retrieve for each sub-query
  const allResults = [];
  for (const subQuery of subQueries) {
    const results = await qdrant.search({
      vector: await embed(subQuery),
      limit: 3
    });
    allResults.push({ subQuery, results });
  }

  // 4. Deduplicate and rank
  const uniqueChunks = deduplicateByParent(
    allResults.flatMap(r => r.results)
  );

  // 5. Return with context
  return {
    chunks: uniqueChunks.slice(0, 10),
    decomposition: subQueries,
    instruction: 'Answer the original question using these sub-answers...'
  };
}
```

**Benefits**:
- ‚úÖ +15-20% accuracy on multi-hop questions
- ‚úÖ Works with existing RAG (no KG needed)
- ‚úÖ Transparent reasoning (user sees sub-questions)

**Cost**:
- Development: 3-5 days
- LLM cost: ~200 tokens per complex query (~$0.0002 per query)
- Latency: +500-1000ms (LLM call + multiple retrievals)

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê (Good impact, moderate cost)

---

### 4. Bidirectional Indexing (Entity ‚Üî Chunks) ‚≠ê‚≠ê‚≠ê

**–ß—Ç–æ —ç—Ç–æ**: –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –æ—Ç entities –∫ chunks.

**Structure**:
```
Forward index (chunk ‚Üí entities):
  Chunk 1: ["gradient_descent", "learning_rate"]
  Chunk 5: ["gradient_descent", "momentum"]

Reverse index (entity ‚Üí chunks):
  "gradient_descent": [Chunk 1, Chunk 5, Chunk 12, ...]
  "learning_rate": [Chunk 1, Chunk 8, Chunk 15, ...]
```

**Implementation**:

```typescript
// 1. Build reverse index during indexing
const entityIndex = new Map<string, string[]>();

for (const chunk of chunks) {
  const entities = extractEntities(chunk.text);

  // Forward index (in chunk metadata)
  chunk.metadata.entities = entities;

  // Reverse index
  for (const entity of entities) {
    if (!entityIndex.has(entity)) {
      entityIndex.set(entity, []);
    }
    entityIndex.get(entity)!.push(chunk.id);
  }
}

// Store reverse index in Qdrant payload or separate store
await redis.set('entity_index', JSON.stringify(
  Object.fromEntries(entityIndex)
));

// 2. Use for faster exact lookups
async function entityAwareRetrieval(query: string) {
  const entities = extractEntities(query);

  if (entities.length > 0) {
    // Fast path: exact entity lookup
    const candidateChunkIds = new Set<string>();
    for (const entity of entities) {
      const chunkIds = entityIndex.get(entity) || [];
      chunkIds.forEach(id => candidateChunkIds.add(id));
    }

    // Fetch candidates and re-rank with vector similarity
    const candidates = await qdrant.retrieve(
      Array.from(candidateChunkIds)
    );

    const reranked = await vectorRerank(query, candidates);
    return reranked.slice(0, 10);
  }

  // Fallback: standard vector search
  return await vectorSearch(query);
}
```

**Benefits**:
- ‚úÖ Faster for entity-based queries (50-100ms saved)
- ‚úÖ Higher recall for rare entities
- ‚úÖ No LLM cost (extraction at index time)

**Cost**:
- Development: 2-3 days
- Storage: +5% (reverse index)
- Indexing: +$0.01-0.02 per 1M tokens (entity extraction)

**ROI**: ‚≠ê‚≠ê‚≠ê (Moderate impact, low cost)

---

### 5. Schema-Constrained Extraction ‚≠ê‚≠ê

**–ß—Ç–æ —ç—Ç–æ**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ entities/relationships –ø–æ –∑–∞—Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Å—Ö–µ–º–µ.

**Example Schema**:

```typescript
const educationalSchema = {
  entities: {
    Algorithm: {
      properties: ['name', 'complexity', 'use_cases'],
      examples: ['gradient_descent', 'backpropagation']
    },
    Concept: {
      properties: ['definition', 'prerequisites'],
      examples: ['supervised_learning', 'overfitting']
    },
    Formula: {
      properties: ['latex', 'variables'],
      examples: ['cross_entropy', 'softmax']
    }
  },
  relationships: {
    prerequisite_of: {
      source: ['Concept', 'Algorithm'],
      target: ['Concept', 'Algorithm']
    },
    similar_to: {
      source: '*',
      target: '*'
    },
    part_of: {
      source: '*',
      target: ['Concept']
    }
  }
};
```

**Benefits**:
- ‚úÖ Structured, queryable knowledge
- ‚úÖ Better extraction quality (schema guides LLM)
- ‚úÖ Enables precise filtering

**Cost**:
- Development: 1-2 weeks (schema design + extraction)
- Indexing: +$0.10-0.20 per 1M tokens (structured extraction)

**ROI**: ‚≠ê‚≠ê (Moderate impact, high cost)

---

## üìã Summary: –ß—Ç–æ –ø–æ–∑–∞–∏–º—Å—Ç–≤–æ–≤–∞—Ç—å

| Feature | Impact | Cost | Development | ROI | Recommend |
|---------|--------|------|-------------|-----|-----------|
| Logical Form Retrieval | +10-15% accuracy | $0 | 1-2 days | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Phase 2** |
| Hybrid (Vector+BM25) | +5-10% recall | Low | 2-3 days | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Phase 2** |
| Query Decomposition | +15-20% multi-hop | Medium | 3-5 days | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Phase 3** |
| Bidirectional Index | Faster lookups | Low | 2-3 days | ‚≠ê‚≠ê‚≠ê | ‚≠ê Phase 3 |
| Schema Extraction | Structured data | High | 1-2 weeks | ‚≠ê‚≠ê | ‚ö†Ô∏è Optional |

**Recommended borrowing order**:
1. **Phase 2** (Week 3-4): Hybrid search + Logical form parsing
2. **Phase 3** (Month 2): Query decomposition for complex questions
3. **Optional**: Bidirectional indexing if exact lookups are critical

---

## ‚ö†Ô∏è Risk Assessment

### –†–∏—Å–∫–∏ –ø–æ–ª–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ KAG

#### 1. Technology Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: OpenSPG KAG –Ω–µ–∑—Ä–µ–ª–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è (v0.8.0, early 2025)

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- –ß–∞—Å—Ç—ã–µ breaking changes
- Undocumented edge cases
- Bugs –≤ core functionality
- API changes between versions

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –í—ã—Å–æ–∫–∞—è (80%)
**–í–ª–∏—è–Ω–∏–µ**: –í—ã—Å–æ–∫–æ–µ (–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∫–æ–¥–∞, –ø—Ä–æ—Å—Ç–æ–∏)

**Mitigation**:
- ‚úÖ Wait for v1.0 stable release (6-12 months)
- ‚úÖ Start with Proof-of-Concept (–Ω–µ production)
- ‚úÖ Monitor GitHub issues/releases
- ‚ùå –ò–∑–±–µ–≥–∞—Ç—å –¥–ª—è critical production systems

---

#### 2. Russian Language Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- –ü–ª–æ—Ö–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ entities (cyrillic)
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ relationships (syntax differences)
- Logical forms –º–æ–≥—É—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è-–í—ã—Å–æ–∫–∞—è (60-70%)
**–í–ª–∏—è–Ω–∏–µ**: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ (–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è)

**Mitigation**:
- ‚úÖ Extensive testing –Ω–∞ —Ä—É—Å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (100+ docs)
- ‚úÖ Compare —Å known-good RAG baseline
- ‚úÖ Benchmark entity extraction accuracy
- ‚ùå –ù–ï –¥–µ–ø–ª–æ–∏—Ç—å –±–µ–∑ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**Test criteria**:
```
Entity extraction precision: >85% (vs human annotation)
Relationship extraction recall: >70%
Multi-hop reasoning accuracy: >80% (vs RAG)

If any metric fails ‚Üí STOP migration
```

---

#### 3. Performance Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è latency –æ—Ç graph traversal

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- Queries >3s –¥–ª—è multi-hop (vs <500ms –¥–ª—è RAG)
- Graph complexity —Ä–∞—Å—Ç–µ—Ç —Å —Ä–∞–∑–º–µ—Ä–æ–º collection
- Concurrent users bottleneck –Ω–∞ graph DB

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –í—ã—Å–æ–∫–∞—è (75%)
**–í–ª–∏—è–Ω–∏–µ**: –°—Ä–µ–¥–Ω–µ–µ (–ø–ª–æ—Ö–æ–π UX, –Ω–æ –Ω–µ critical)

**Mitigation**:
- ‚úÖ Set hard timeout (3s max query time)
- ‚úÖ Fallback to RAG –µ—Å–ª–∏ timeout
- ‚úÖ Cache frequent queries
- ‚úÖ Horizontal scaling –¥–ª—è graph DB (expensive!)

---

#### 4. Cost Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: Indexing costs 50-100x –≤—ã—à–µ

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- $150 –¥–ª—è 100M tokens (vs $2 –¥–ª—è RAG)
- Frequent re-indexing —Å—Ç–æ–∏—Ç –¥–æ—Ä–æ–≥–æ
- Budget overruns

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (90%)
**–í–ª–∏—è–Ω–∏–µ**: –°—Ä–µ–¥–Ω–µ–µ (—Ñ–∏–Ω–∞–Ω—Å—ã, –Ω–æ –Ω–µ technical failure)

**Mitigation**:
- ‚úÖ Set budget caps ($500/month indexing)
- ‚úÖ Incremental indexing (—Ç–æ–ª—å–∫–æ changed docs)
- ‚úÖ ROI tracking (improvement vs cost)
- ‚ùå Kill project –µ—Å–ª–∏ cost > 10x benefit

---

#### 5. Knowledge Graph Quality Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: –ü–ª–æ—Ö–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ ‚Üí –ø–ª–æ—Ö–æ–π KG ‚Üí –ø–ª–æ—Ö–æ–π reasoning

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- Missed entities (–Ω–∏–∑–∫–∏–π recall)
- Wrong relationships (–ª–æ–∂–Ω—ã–µ —Å–≤—è–∑–∏)
- Incorrect prerequisite chains
- Garbage in ‚Üí garbage out

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (85%)
**–í–ª–∏—è–Ω–∏–µ**: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ (KAG —Ö—É–∂–µ —á–µ–º RAG!)

**Mitigation**:
- ‚úÖ Manual validation (sample 100 entities/relationships)
- ‚úÖ Iterative prompt engineering –¥–ª—è extraction
- ‚úÖ Human-in-the-loop –¥–ª—è core concepts
- ‚úÖ Fallback to RAG –µ—Å–ª–∏ KG confidence < threshold

**Quality gates**:
```
Entity precision: >90% (vs gold standard)
Relationship precision: >85%
Prerequisite chain accuracy: >80%

If fails ‚Üí Use hybrid approach (KG only for validated concepts)
```

---

#### 6. Maintenance Risk ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**Risk**: –°–ª–æ–∂–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤

**–ü—Ä–æ—è–≤–ª–µ–Ω–∏—è**:
- Graph DB monitoring/tuning
- KG quality monitoring
- Complex debugging (where did reasoning fail?)
- Team training (new skills needed)

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**: –í—ã—Å–æ–∫–∞—è (80%)
**–í–ª–∏—è–Ω–∏–µ**: –°—Ä–µ–¥–Ω–µ–µ (ongoing cost)

**Mitigation**:
- ‚úÖ Allocate 1 FTE –¥–ª—è KAG maintenance
- ‚úÖ Build monitoring dashboard
- ‚úÖ Document reasoning traces
- ‚úÖ Team training (2-4 weeks)

---

### Risk Summary Matrix

| Risk | Probability | Impact | Severity | Mitigation |
|------|-------------|--------|----------|------------|
| Technology immaturity | 80% | High | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Wait 6-12mo |
| Russian language | 70% | Critical | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Test extensively |
| Performance | 75% | Medium | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Timeouts, fallback |
| Cost | 90% | Medium | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Budget caps |
| KG quality | 85% | Critical | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Validation, hybrid |
| Maintenance | 80% | Medium | ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è | Allocate resources |

**Overall Risk Level**: ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è **HIGH**

**Recommendation**: –ù–ï –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ full KAG –≤ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç. –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –¥–ª—è production —Å–∏—Å—Ç–µ–º—ã.

---

## üéØ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### 3-Phase Strategy (Data-Driven)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 1: Optimize RAG (Month 1-2)                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚úÖ Implement Late Chunking + Hierarchical                   ‚îÇ
‚îÇ  ‚úÖ Token-aware sizing (400/1500 tokens)                     ‚îÇ
‚îÇ  ‚úÖ Rich metadata (page numbers, hierarchy)                  ‚îÇ
‚îÇ  ‚úÖ Incremental updates (SHA-256)                            ‚îÇ
‚îÇ  ‚úÖ Deploy to production                                     ‚îÇ
‚îÇ  ‚úÖ Measure baseline:                                        ‚îÇ
‚îÇ     ‚Ä¢ Retrieval accuracy (target >85%)                       ‚îÇ
‚îÇ     ‚Ä¢ User satisfaction (surveys)                            ‚îÇ
‚îÇ     ‚Ä¢ Query complexity distribution                          ‚îÇ
‚îÇ     ‚Ä¢ Failure case analysis                                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cost: $13K development + $100/mo hosting                    ‚îÇ
‚îÇ  Timeline: 1-2 weeks                                         ‚îÇ
‚îÇ  Risk: LOW ‚úÖ                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2: Borrow KAG Concepts (Month 2-3)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚úÖ Add hybrid search (BM25 + Vector)                        ‚îÇ
‚îÇ  ‚úÖ Logical form-guided retrieval                            ‚îÇ
‚îÇ  ‚úÖ Query decomposition for multi-hop                        ‚îÇ
‚îÇ  ‚úÖ A/B test improvements                                    ‚îÇ
‚îÇ  ‚úÖ Measure impact:                                          ‚îÇ
‚îÇ     ‚Ä¢ Accuracy improvement (target +5-10%)                   ‚îÇ
‚îÇ     ‚Ä¢ Complex query performance                              ‚îÇ
‚îÇ     ‚Ä¢ Cost increase (should be <30%)                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cost: +$8K development + $30/mo hosting                     ‚îÇ
‚îÇ  Timeline: 2-4 weeks                                         ‚îÇ
‚îÇ  Risk: LOW-MEDIUM ‚úÖ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Decision Point       ‚îÇ
            ‚îÇ  (End of Month 3)      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Accuracy >90%?  ‚îÇ           ‚îÇ Accuracy <85%?   ‚îÇ
‚îÇ User satisfied? ‚îÇ           ‚îÇ Complex queries  ‚îÇ
‚îÇ                 ‚îÇ           ‚îÇ struggling?      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ YES                         ‚îÇ YES
         ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 3A: STOP (RAG is sufficient)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚úÖ Continue optimizing RAG                                  ‚îÇ
‚îÇ  ‚úÖ Add source linking (PDF/HTML)                            ‚îÇ
‚îÇ  ‚úÖ Focus on UX improvements                                 ‚îÇ
‚îÇ  ‚ùå NO KAG migration needed                                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cost: +$4K/year optimization                                ‚îÇ
‚îÇ  Risk: LOW ‚úÖ                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 3B: Add Lightweight KG (Month 4-6)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚≠ê Implement Hybrid Option 1 or 3                           ‚îÇ
‚îÇ  ‚≠ê Mini-KG for core concepts (200-300 entities)             ‚îÇ
‚îÇ  ‚≠ê Bidirectional indexing                                   ‚îÇ
‚îÇ  ‚≠ê Entity-aware retrieval                                   ‚îÇ
‚îÇ  ‚≠ê Measure impact:                                          ‚îÇ
‚îÇ     ‚Ä¢ Accuracy on complex queries (target 85-90%)            ‚îÇ
‚îÇ     ‚Ä¢ ROI: improvement vs cost                               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cost: +$15K development + $50/mo hosting                    ‚îÇ
‚îÇ  Timeline: 4-8 weeks                                         ‚îÇ
‚îÇ  Risk: MEDIUM ‚ö†Ô∏è                                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚ùå Do NOT proceed to full KAG unless:                       ‚îÇ
‚îÇ     ‚Ä¢ Mini-KG shows clear value (>10% improvement)           ‚îÇ
‚îÇ     ‚Ä¢ Budget allows (3x current cost)                        ‚îÇ
‚îÇ     ‚Ä¢ Team comfortable with complexity                       ‚îÇ
‚îÇ     ‚Ä¢ OpenSPG reaches v1.0 stable                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Decision Criteria

**Proceed to Phase 3B (Lightweight KG) if**:
```
‚úÖ Retrieval accuracy < 85% after Phase 2
‚úÖ >20% of queries are complex/multi-hop
‚úÖ User surveys show dissatisfaction with complex answers
‚úÖ Budget allows +30-50% cost increase
‚úÖ Team has 4-8 weeks for development
```

**Stay with optimized RAG if**:
```
‚úÖ Retrieval accuracy > 90% after Phase 2
‚úÖ <15% of queries are complex
‚úÖ User satisfaction > 80%
‚úÖ Budget is constrained
‚úÖ Team prefers simplicity
```

**Consider full KAG migration only if**:
```
‚ö†Ô∏è Lightweight KG shows >15% improvement AND
‚ö†Ô∏è Budget allows 5-10x cost increase AND
‚ö†Ô∏è OpenSPG reaches v1.0 stable AND
‚ö†Ô∏è Russian language performance validated AND
‚ö†Ô∏è Team trained on KG concepts AND
‚ö†Ô∏è 6-12 month timeline acceptable
```

---

## üìä Success Metrics

### Phase 1 (Optimized RAG) - KPIs

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| **Retrieval Accuracy** | 70% | >85% | Human eval (100 queries) |
| **Precision@5** | 65% | >80% | Automated eval |
| **User Satisfaction** | Unknown | >80% | Post-query surveys |
| **Query Latency P95** | ~800ms | <500ms | Monitoring |
| **Citation Accuracy** | 40% | >70% | Manual verification |
| **Cost per 1M tokens** | $0.02 | <$0.03 | Billing analysis |

### Phase 2 (Borrowed KAG Features) - KPIs

| Metric | Phase 1 | Target | Measurement |
|--------|---------|--------|-------------|
| **Complex Query Accuracy** | 70-75% | >80% | Human eval (complex subset) |
| **Multi-hop Success Rate** | 60% | >75% | Automated eval |
| **Hybrid Search Recall** | Baseline | +5-10% | A/B testing |
| **Query Latency** | <500ms | <700ms | Acceptable increase |
| **Cost increase** | Baseline | <30% | Budget tracking |

### Phase 3B (Lightweight KG) - KPIs

| Metric | Phase 2 | Target | Threshold to proceed |
|--------|---------|--------|---------------------|
| **Complex Query Accuracy** | 80% | >85% | Must improve >5% |
| **Conceptual Questions** | 75% | >85% | Must improve >10% |
| **Comparative Questions** | 70% | >85% | Must improve >15% |
| **Cost increase** | Baseline | <50% | Must stay under budget |
| **Development time** | N/A | <8 weeks | Must meet timeline |

### Kill Criteria (Stop KG development)

‚ùå **STOP if**:
- Phase 3B accuracy improvement < 5% (not worth cost)
- Cost increase > 50% (budget exceeded)
- Development > 10 weeks (timeline risk)
- User satisfaction decreases (worse UX)
- Maintenance burden unsustainable (team capacity)

---

## üí∞ Cost Summary (1 Year)

| Approach | Development | Indexing | Hosting | Queries | Maintenance | Total Year 1 |
|----------|-------------|----------|---------|---------|-------------|--------------|
| **Current RAG (baseline)** | $0 | $0 | $1,200 | $12 | $0 | **$1,212** |
| **Optimized RAG (Phase 1)** | $8,000 | $20 | $1,200 | $12 | $4,000 | **$13,232** |
| **+ KAG Features (Phase 2)** | +$8,000 | +$50 | +$360 | +$60 | +$2,000 | **$23,702** |
| **+ Lightweight KG (Phase 3B)** | +$15,000 | +$500 | +$600 | +$200 | +$4,000 | **$44,002** |
| **Full KAG (NOT recommended)** | $48,000 | $1,500 | $4,200 | $360 | $12,000 | **$66,060** |

**Recommended path cost**: $13K (Phase 1) ‚Üí $24K (Phase 2) ‚Üí Decision point

---

## üöÄ Next Steps

### Immediate Actions (Week 1)

1. **Review this analysis with team** ‚úÖ
   - Stakeholders: Engineering, Product, Finance
   - Decision: Approve Phase 1 implementation
   - Budget: Allocate $15K for Phase 1-2

2. **Setup development environment**
   - Jina-v3 API key
   - Qdrant instance (development)
   - LangChain.js setup

3. **Create implementation tickets**
   - T075: Implement hierarchical late chunking
   - T076: Add token-aware sizing
   - T077: Rich metadata schema
   - T078: Incremental updates

### Phase 1 Execution (Week 2-4)

**Week 2**:
- Implement parent-child chunking
- Setup late chunking with Jina API
- Create metadata schema
- Test on 10 sample documents

**Week 3**:
- Integrate with Qdrant
- Implement change detection
- Build indexing pipeline
- Test on 100 documents

**Week 4**:
- Deploy to staging
- A/B test vs baseline (20% traffic)
- Monitor metrics
- Fix issues

### Phase 2 Planning (Month 2)

**If Phase 1 successful** (accuracy >85%):
- Implement hybrid search (BM25 + Vector)
- Add logical form parsing
- Query decomposition for multi-hop
- A/B test improvements

**If Phase 1 insufficient** (<80% accuracy):
- Debug retrieval issues
- Analyze failure cases
- Iterate on chunking strategy
- Consider Phase 3B earlier

### Decision Point (End Month 3)

**Collect data**:
- 1000+ production queries
- User satisfaction surveys
- Failure case analysis
- Cost tracking

**Analyze**:
- Query complexity distribution
- Accuracy by query type
- ROI of Phase 2 improvements
- Team capacity for Phase 3

**Decide**:
- Continue with RAG only (if >90% satisfaction)
- Proceed to Phase 3B (if <85% on complex queries)
- Pause and investigate (if unclear)

---

## üìö References & Resources

### RAG Research
- Jina AI Late Chunking: [arXiv:2409.04701](https://arxiv.org/abs/2409.04701)
- Anthropic Contextual Retrieval: [Blog Post Sept 2024](https://www.anthropic.com/news/contextual-retrieval)
- LangChain Text Splitters: [js.langchain.com/docs/modules/data_connection/document_transformers](https://js.langchain.com/docs/modules/data_connection/document_transformers/)
- Qdrant Documentation: [qdrant.tech/documentation](https://qdrant.tech/documentation/)

### KAG Resources
- OpenSPG KAG GitHub: [github.com/OpenSPG/KAG](https://github.com/OpenSPG/KAG)
- KAG Technical Report: OpenAI SPG documentation
- Knowledge Graphs for RAG: Research papers on hybrid approaches

### Russian NLP
- Razdel: [github.com/natasha/razdel](https://github.com/natasha/rasdel)
- ruMTEB Benchmark: [arXiv:2408.12503](https://arxiv.org/abs/2408.12503)
- Russian SuperGLUE: [russiansuperglue.com](https://russiansuperglue.com)

### Evaluation Frameworks
- RAGAS: [github.com/explodinggradients/ragas](https://github.com/explodinggradients/ragas)
- LangSmith: [smith.langchain.com](https://smith.langchain.com)

---

## üéì Conclusion

### –ì–ª–∞–≤–Ω—ã–π –≤—ã–≤–æ–¥

**–ù–ï –º–∏–≥—Ä–∏—Ä—É–π—Ç–µ –Ω–∞ KAG —Å–µ–π—á–∞—Å**. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Ç–µ–∫—É—â—É—é RAG-—Å–∏—Å—Ç–µ–º—É (Phase 1-2), –∏–∑–º–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∑–∞—Ç–µ–º –ø—Ä–∏–º–∏—Ç–µ data-driven —Ä–µ—à–µ–Ω–∏–µ –æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ KG-—Ñ—É–Ω–∫—Ü–∏–π.

### –ü–æ—á–µ–º—É —ç—Ç–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞

1. **Low risk, high reward**: Phase 1 –¥–∞—Å—Ç 20-30% improvement –∑–∞ 1-2 –Ω–µ–¥–µ–ª–∏
2. **Proven technology**: RAG stack –∑—Ä–µ–ª—ã–π, stable, well-documented
3. **Cost-effective**: $13K vs $66K –¥–ª—è full KAG
4. **Russian-optimized**: Jina-v3 –ø—Ä–æ–≤–µ—Ä–µ–Ω –Ω–∞ —Ä—É—Å—Å–∫–æ–º (96% parity)
5. **Incremental path**: –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å KG features –ø–æ–∑–∂–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
6. **Data-driven**: –†–µ—à–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö, –Ω–µ –≥–∏–ø–æ—Ç–µ–∑–∞—Ö

### –ö–æ–≥–¥–∞ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ—à–µ–Ω–∏–µ

–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ KAG/KG features –µ—Å–ª–∏:
- ‚úÖ Phase 2 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç <85% accuracy on complex queries
- ‚úÖ >20% queries are multi-hop/comparative
- ‚úÖ OpenSPG –¥–æ—Å—Ç–∏–≥–∞–µ—Ç v1.0 stable (6-12 months)
- ‚úÖ Russian language benchmarks —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –¥–æ—Å—Ç—É–ø–Ω—ã
- ‚úÖ Budget –ø–æ–∑–≤–æ–ª—è–µ—Ç 3-5x cost increase
- ‚úÖ Team comfortable —Å graph concepts

### Final Recommendation

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   RECOMMENDED PATH                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚úÖ Month 1-2: Optimize RAG (Late Chunking + Hierarchical) ‚îÇ
‚îÇ  ‚úÖ Month 2-3: Add KAG concepts (Hybrid search + Logical)  ‚îÇ
‚îÇ  üìä Month 3: Measure & decide based on data                ‚îÇ
‚îÇ  ‚≠ê Month 4-6: Lightweight KG if needed (NOT full KAG)     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Total cost: $13-44K (vs $66K for full KAG)                ‚îÇ
‚îÇ  Total risk: LOW-MEDIUM (vs HIGH for KAG)                  ‚îÇ
‚îÇ  Expected accuracy: 85-90% (vs 90-95% for KAG)             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ROI: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (80% of benefit at 20% of cost)              ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ù–∞—á–Ω–∏—Ç–µ —Å Phase 1 —Å–µ–π—á–∞—Å. –û—Å—Ç–∞–ª—å–Ω–æ–µ —Ä–µ—à–∏—Ç–µ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.**

---

**–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω**: 2025-01-25
**–í–µ—Ä—Å–∏—è**: 1.0
**–°–ª–µ–¥—É—é—â–∏–π review**: –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Phase 1 (Month 2)
